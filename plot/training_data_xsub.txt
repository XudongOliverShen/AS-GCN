[08.20.19|07:52:23] Training epoch: 0
[08.20.19|07:52:37] 	Iter 0 Done. | loss2: 5610.4072 | loss_nll: 5568.8931 | loss_kl: 41.5140 | lr: 0.000500
[08.20.19|07:55:33] 	Iter 100 Done. | loss2: 85.6105 | loss_nll: 76.0727 | loss_kl: 9.5378 | lr: 0.000500
[08.20.19|07:58:31] 	Iter 200 Done. | loss2: 222.4295 | loss_nll: 218.1427 | loss_kl: 4.2869 | lr: 0.000500
[08.20.19|08:01:31] 	Iter 300 Done. | loss2: 104.9091 | loss_nll: 102.2612 | loss_kl: 2.6479 | lr: 0.000500
[08.20.19|08:04:27] 	Iter 400 Done. | loss2: 156.0354 | loss_nll: 154.7116 | loss_kl: 1.3238 | lr: 0.000500
[08.20.19|08:07:26] 	Iter 500 Done. | loss2: 526.1555 | loss_nll: 525.5672 | loss_kl: 0.5882 | lr: 0.000500
[08.20.19|08:10:19] 	Iter 600 Done. | loss2: 128.1974 | loss_nll: 127.4979 | loss_kl: 0.6995 | lr: 0.000500
[08.20.19|08:13:08] 	Iter 700 Done. | loss2: 156.2867 | loss_nll: 155.7166 | loss_kl: 0.5700 | lr: 0.000500
[08.20.19|08:16:02] 	Iter 800 Done. | loss2: 894.6773 | loss_nll: 894.1829 | loss_kl: 0.4945 | lr: 0.000500
[08.20.19|08:19:04] 	Iter 900 Done. | loss2: 83.9538 | loss_nll: 83.6892 | loss_kl: 0.2646 | lr: 0.000500
[08.20.19|08:21:57] 	Iter 1000 Done. | loss2: 58.2879 | loss_nll: 58.0575 | loss_kl: 0.2305 | lr: 0.000500
[08.20.19|08:24:49] 	Iter 1100 Done. | loss2: 226.0717 | loss_nll: 225.9153 | loss_kl: 0.1564 | lr: 0.000500
[08.20.19|08:27:41] 	Iter 1200 Done. | loss2: 83.1238 | loss_nll: 82.9590 | loss_kl: 0.1648 | lr: 0.000500
[08.20.19|08:29:10] 	mean_loss2: 182.84496451795292
[08.20.19|08:29:10] 	mean_loss_nll: 179.95273203438464
[08.20.19|08:29:10] 	mean_loss_kl: 2.892232289882942
[08.20.19|08:29:10] Time consumption:
[08.20.19|08:29:10] Done.
[08.20.19|08:29:10] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch0_model1.pt.
[08.20.19|08:29:10] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch0_model2.pt.
[08.20.19|08:29:10] Training epoch: 1
[08.20.19|08:30:37] 	Iter 1300 Done. | loss2: 87.6611 | loss_nll: 87.5237 | loss_kl: 0.1374 | lr: 0.000500
[08.20.19|08:33:24] 	Iter 1400 Done. | loss2: 95.7915 | loss_nll: 95.6605 | loss_kl: 0.1310 | lr: 0.000500
[08.20.19|08:36:13] 	Iter 1500 Done. | loss2: 83.6148 | loss_nll: 83.4974 | loss_kl: 0.1174 | lr: 0.000500
[08.20.19|08:39:07] 	Iter 1600 Done. | loss2: 89.5698 | loss_nll: 89.5008 | loss_kl: 0.0690 | lr: 0.000500
[08.20.19|08:41:59] 	Iter 1700 Done. | loss2: 857.4405 | loss_nll: 857.3831 | loss_kl: 0.0574 | lr: 0.000500
[08.20.19|08:45:00] 	Iter 1800 Done. | loss2: 558.6193 | loss_nll: 558.5935 | loss_kl: 0.0258 | lr: 0.000500
[08.20.19|08:47:57] 	Iter 1900 Done. | loss2: 745.0168 | loss_nll: 744.9831 | loss_kl: 0.0337 | lr: 0.000500
[08.20.19|08:50:57] 	Iter 2000 Done. | loss2: 62.9850 | loss_nll: 62.9611 | loss_kl: 0.0239 | lr: 0.000500
[08.20.19|08:54:05] 	Iter 2100 Done. | loss2: 176.5660 | loss_nll: 176.5267 | loss_kl: 0.0393 | lr: 0.000500
[08.20.19|08:57:12] 	Iter 2200 Done. | loss2: 693.7024 | loss_nll: 693.6839 | loss_kl: 0.0185 | lr: 0.000500
[08.20.19|09:00:16] 	Iter 2300 Done. | loss2: 81.0428 | loss_nll: 81.0208 | loss_kl: 0.0220 | lr: 0.000500
[08.20.19|09:03:18] 	Iter 2400 Done. | loss2: 779.3105 | loss_nll: 779.2864 | loss_kl: 0.0242 | lr: 0.000500
[08.20.19|09:06:15] 	Iter 2500 Done. | loss2: 301.8507 | loss_nll: 301.8277 | loss_kl: 0.0230 | lr: 0.000500
[08.20.19|09:06:21] 	mean_loss2: 176.62218464677707
[08.20.19|09:06:21] 	mean_loss_nll: 176.56037019845397
[08.20.19|09:06:21] 	mean_loss_kl: 0.0618148671586614
[08.20.19|09:06:21] Time consumption:
[08.20.19|09:06:21] Done.
[08.20.19|09:06:21] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch1_model1.pt.
[08.20.19|09:06:21] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch1_model2.pt.
[08.20.19|09:06:21] Training epoch: 2
[08.20.19|09:09:09] 	Iter 2600 Done. | loss2: 76.4746 | loss_nll: 76.4572 | loss_kl: 0.0174 | lr: 0.000500
[08.20.19|09:12:05] 	Iter 2700 Done. | loss2: 89.3993 | loss_nll: 89.3806 | loss_kl: 0.0187 | lr: 0.000500
[08.20.19|09:15:05] 	Iter 2800 Done. | loss2: 73.9371 | loss_nll: 73.9119 | loss_kl: 0.0253 | lr: 0.000500
[08.20.19|09:18:10] 	Iter 2900 Done. | loss2: 84.4552 | loss_nll: 84.4165 | loss_kl: 0.0388 | lr: 0.000500
[08.20.19|09:21:10] 	Iter 3000 Done. | loss2: 151.4326 | loss_nll: 151.4096 | loss_kl: 0.0230 | lr: 0.000500
[08.20.19|09:24:08] 	Iter 3100 Done. | loss2: 90.9205 | loss_nll: 90.8821 | loss_kl: 0.0384 | lr: 0.000500
[08.20.19|09:27:09] 	Iter 3200 Done. | loss2: 241.7908 | loss_nll: 241.7552 | loss_kl: 0.0357 | lr: 0.000500
[08.20.19|09:30:07] 	Iter 3300 Done. | loss2: 160.9522 | loss_nll: 160.9122 | loss_kl: 0.0399 | lr: 0.000500
[08.20.19|09:33:03] 	Iter 3400 Done. | loss2: 98.7363 | loss_nll: 98.6267 | loss_kl: 0.1096 | lr: 0.000500
[08.20.19|09:35:56] 	Iter 3500 Done. | loss2: 66.7012 | loss_nll: 66.6863 | loss_kl: 0.0149 | lr: 0.000500
[08.20.19|09:38:49] 	Iter 3600 Done. | loss2: 83.7161 | loss_nll: 83.7004 | loss_kl: 0.0158 | lr: 0.000500
[08.20.19|09:41:38] 	Iter 3700 Done. | loss2: 97.6790 | loss_nll: 97.6661 | loss_kl: 0.0129 | lr: 0.000500
[08.20.19|09:43:13] 	mean_loss2: 174.95735212027455
[08.20.19|09:43:13] 	mean_loss_nll: 174.9253372887072
[08.20.19|09:43:13] 	mean_loss_kl: 0.032015332607730936
[08.20.19|09:43:13] Time consumption:
[08.20.19|09:43:13] Done.
[08.20.19|09:43:13] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch2_model1.pt.
[08.20.19|09:43:13] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch2_model2.pt.
[08.20.19|09:43:13] Training epoch: 3
[08.20.19|09:44:31] 	Iter 3800 Done. | loss2: 103.0811 | loss_nll: 103.0597 | loss_kl: 0.0214 | lr: 0.000500
[08.20.19|09:47:24] 	Iter 3900 Done. | loss2: 407.9981 | loss_nll: 407.9239 | loss_kl: 0.0742 | lr: 0.000500
[08.20.19|09:50:16] 	Iter 4000 Done. | loss2: 96.5908 | loss_nll: 96.5739 | loss_kl: 0.0169 | lr: 0.000500
[08.20.19|09:53:10] 	Iter 4100 Done. | loss2: 108.7054 | loss_nll: 108.6837 | loss_kl: 0.0217 | lr: 0.000500
[08.20.19|09:56:02] 	Iter 4200 Done. | loss2: 289.3285 | loss_nll: 289.1587 | loss_kl: 0.1698 | lr: 0.000500
[08.20.19|09:58:52] 	Iter 4300 Done. | loss2: 109.1517 | loss_nll: 108.9888 | loss_kl: 0.1629 | lr: 0.000500
[08.20.19|10:01:41] 	Iter 4400 Done. | loss2: 124.2541 | loss_nll: 123.9731 | loss_kl: 0.2811 | lr: 0.000500
[08.20.19|10:04:34] 	Iter 4500 Done. | loss2: 458.2318 | loss_nll: 458.1304 | loss_kl: 0.1014 | lr: 0.000500
[08.20.19|10:07:22] 	Iter 4600 Done. | loss2: 62.7696 | loss_nll: 62.6406 | loss_kl: 0.1290 | lr: 0.000500
[08.20.19|10:10:18] 	Iter 4700 Done. | loss2: 139.7030 | loss_nll: 139.5689 | loss_kl: 0.1341 | lr: 0.000500
[08.20.19|10:13:14] 	Iter 4800 Done. | loss2: 342.0580 | loss_nll: 341.9039 | loss_kl: 0.1540 | lr: 0.000500
[08.20.19|10:16:12] 	Iter 4900 Done. | loss2: 91.8981 | loss_nll: 91.8278 | loss_kl: 0.0703 | lr: 0.000500
[08.20.19|10:19:07] 	Iter 5000 Done. | loss2: 116.5169 | loss_nll: 116.2846 | loss_kl: 0.2323 | lr: 0.000500
[08.20.19|10:19:22] 	mean_loss2: 176.4234458478495
[08.20.19|10:19:22] 	mean_loss_nll: 176.26948780145128
[08.20.19|10:19:22] 	mean_loss_kl: 0.1539581634599668
[08.20.19|10:19:22] Time consumption:
[08.20.19|10:19:22] Done.
[08.20.19|10:19:22] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch3_model1.pt.
[08.20.19|10:19:22] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch3_model2.pt.
[08.20.19|10:19:22] Training epoch: 4
[08.20.19|10:22:20] 	Iter 5100 Done. | loss2: 220.2505 | loss_nll: 220.1393 | loss_kl: 0.1112 | lr: 0.000500
[08.20.19|10:25:30] 	Iter 5200 Done. | loss2: 94.7003 | loss_nll: 94.5781 | loss_kl: 0.1222 | lr: 0.000500
[08.20.19|10:28:41] 	Iter 5300 Done. | loss2: 83.1377 | loss_nll: 83.0960 | loss_kl: 0.0418 | lr: 0.000500
[08.20.19|10:31:53] 	Iter 5400 Done. | loss2: 123.9944 | loss_nll: 123.9425 | loss_kl: 0.0519 | lr: 0.000500
[08.20.19|10:35:05] 	Iter 5500 Done. | loss2: 74.3309 | loss_nll: 74.2959 | loss_kl: 0.0350 | lr: 0.000500
[08.20.19|10:37:58] 	Iter 5600 Done. | loss2: 50.1318 | loss_nll: 49.9863 | loss_kl: 0.1455 | lr: 0.000500
[08.20.19|10:40:51] 	Iter 5700 Done. | loss2: 106.3270 | loss_nll: 106.2904 | loss_kl: 0.0366 | lr: 0.000500
[08.20.19|10:43:50] 	Iter 5800 Done. | loss2: 265.6847 | loss_nll: 265.6634 | loss_kl: 0.0213 | lr: 0.000500
[08.20.19|10:46:46] 	Iter 5900 Done. | loss2: 492.4170 | loss_nll: 492.0175 | loss_kl: 0.3995 | lr: 0.000500
[08.20.19|10:49:47] 	Iter 6000 Done. | loss2: 190.1802 | loss_nll: 190.0879 | loss_kl: 0.0923 | lr: 0.000500
[08.20.19|10:52:49] 	Iter 6100 Done. | loss2: 80.1607 | loss_nll: 80.1251 | loss_kl: 0.0356 | lr: 0.000500
[08.20.19|10:55:43] 	Iter 6200 Done. | loss2: 107.9631 | loss_nll: 107.9245 | loss_kl: 0.0386 | lr: 0.000500
[08.20.19|10:57:31] 	mean_loss2: 174.20721931579394
[08.20.19|10:57:31] 	mean_loss_nll: 174.09884131069
[08.20.19|10:57:31] 	mean_loss_kl: 0.10837844154238106
[08.20.19|10:57:31] Time consumption:
[08.20.19|10:57:31] Done.
[08.20.19|10:57:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch4_model1.pt.
[08.20.19|10:57:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch4_model2.pt.
[08.20.19|10:57:32] Eval epoch: 4
[08.20.19|11:09:24] 	mean_loss2: 188.1979139830715
[08.20.19|11:09:24] 	mean_loss_nll: 188.19330585834592
[08.20.19|11:09:24] 	mean_loss_kl: 0.0046072398301560515
[08.20.19|11:09:24] Done.
[08.20.19|11:09:24] Training epoch: 5
[08.20.19|11:10:39] 	Iter 6300 Done. | loss2: 81.9202 | loss_nll: 81.9035 | loss_kl: 0.0167 | lr: 0.000500
[08.20.19|11:13:34] 	Iter 6400 Done. | loss2: 337.5417 | loss_nll: 337.4995 | loss_kl: 0.0422 | lr: 0.000500
[08.20.19|11:16:31] 	Iter 6500 Done. | loss2: 691.2859 | loss_nll: 690.8876 | loss_kl: 0.3983 | lr: 0.000500
[08.20.19|11:19:30] 	Iter 6600 Done. | loss2: 113.6538 | loss_nll: 113.4475 | loss_kl: 0.2063 | lr: 0.000500
[08.20.19|11:22:24] 	Iter 6700 Done. | loss2: 243.6418 | loss_nll: 243.1483 | loss_kl: 0.4935 | lr: 0.000500
[08.20.19|11:25:16] 	Iter 6800 Done. | loss2: 245.7928 | loss_nll: 245.6060 | loss_kl: 0.1869 | lr: 0.000500
[08.20.19|11:28:10] 	Iter 6900 Done. | loss2: 227.5506 | loss_nll: 227.3161 | loss_kl: 0.2345 | lr: 0.000500
[08.20.19|11:31:03] 	Iter 7000 Done. | loss2: 525.5094 | loss_nll: 525.4556 | loss_kl: 0.0538 | lr: 0.000500
[08.20.19|11:33:57] 	Iter 7100 Done. | loss2: 246.3811 | loss_nll: 246.3216 | loss_kl: 0.0595 | lr: 0.000500
[08.20.19|11:36:57] 	Iter 7200 Done. | loss2: 217.8870 | loss_nll: 217.8422 | loss_kl: 0.0448 | lr: 0.000500
[08.20.19|11:39:51] 	Iter 7300 Done. | loss2: 244.0265 | loss_nll: 243.9913 | loss_kl: 0.0351 | lr: 0.000500
[08.20.19|11:42:47] 	Iter 7400 Done. | loss2: 84.7251 | loss_nll: 84.5610 | loss_kl: 0.1641 | lr: 0.000500
[08.20.19|11:45:47] 	Iter 7500 Done. | loss2: 81.9001 | loss_nll: 81.8465 | loss_kl: 0.0536 | lr: 0.000500
[08.20.19|11:46:06] 	mean_loss2: 173.26913772680507
[08.20.19|11:46:06] 	mean_loss_nll: 173.12666778747266
[08.20.19|11:46:06] 	mean_loss_kl: 0.1424700885322302
[08.20.19|11:46:06] Time consumption:
[08.20.19|11:46:06] Done.
[08.20.19|11:46:07] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch5_model1.pt.
[08.20.19|11:46:07] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch5_model2.pt.
[08.20.19|11:46:07] Training epoch: 6
[08.20.19|11:48:45] 	Iter 7600 Done. | loss2: 77.8561 | loss_nll: 77.8228 | loss_kl: 0.0332 | lr: 0.000500
[08.20.19|11:51:44] 	Iter 7700 Done. | loss2: 89.1559 | loss_nll: 88.0609 | loss_kl: 1.0950 | lr: 0.000500
[08.20.19|11:54:52] 	Iter 7800 Done. | loss2: 80.5659 | loss_nll: 80.2249 | loss_kl: 0.3410 | lr: 0.000500
[08.20.19|11:57:56] 	Iter 7900 Done. | loss2: 2308.5928 | loss_nll: 2308.4775 | loss_kl: 0.1152 | lr: 0.000500
[08.20.19|12:00:57] 	Iter 8000 Done. | loss2: 302.2871 | loss_nll: 302.0925 | loss_kl: 0.1946 | lr: 0.000500
[08.20.19|12:04:01] 	Iter 8100 Done. | loss2: 98.0722 | loss_nll: 97.9584 | loss_kl: 0.1138 | lr: 0.000500
[08.20.19|12:06:57] 	Iter 8200 Done. | loss2: 104.9339 | loss_nll: 104.7839 | loss_kl: 0.1499 | lr: 0.000500
[08.20.19|12:09:57] 	Iter 8300 Done. | loss2: 76.0510 | loss_nll: 75.6687 | loss_kl: 0.3824 | lr: 0.000500
[08.20.19|12:12:53] 	Iter 8400 Done. | loss2: 101.1416 | loss_nll: 100.8790 | loss_kl: 0.2626 | lr: 0.000500
[08.20.19|12:15:50] 	Iter 8500 Done. | loss2: 84.8038 | loss_nll: 84.5063 | loss_kl: 0.2975 | lr: 0.000500
[08.20.19|12:18:41] 	Iter 8600 Done. | loss2: 141.3824 | loss_nll: 141.1899 | loss_kl: 0.1925 | lr: 0.000500
[08.20.19|12:21:37] 	Iter 8700 Done. | loss2: 308.0398 | loss_nll: 307.9194 | loss_kl: 0.1204 | lr: 0.000500
[08.20.19|12:23:28] 	mean_loss2: 174.5742828381328
[08.20.19|12:23:28] 	mean_loss_nll: 174.304945939646
[08.20.19|12:23:28] 	mean_loss_kl: 0.26933693972984535
[08.20.19|12:23:28] Time consumption:
[08.20.19|12:23:28] Done.
[08.20.19|12:23:28] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch6_model1.pt.
[08.20.19|12:23:28] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch6_model2.pt.
[08.20.19|12:23:28] Training epoch: 7
[08.20.19|12:24:35] 	Iter 8800 Done. | loss2: 174.3419 | loss_nll: 174.2492 | loss_kl: 0.0927 | lr: 0.000500
[08.20.19|12:27:36] 	Iter 8900 Done. | loss2: 124.7150 | loss_nll: 124.6109 | loss_kl: 0.1041 | lr: 0.000500
[08.20.19|12:30:31] 	Iter 9000 Done. | loss2: 98.3791 | loss_nll: 98.0104 | loss_kl: 0.3687 | lr: 0.000500
[08.20.19|12:33:30] 	Iter 9100 Done. | loss2: 401.2418 | loss_nll: 400.6156 | loss_kl: 0.6262 | lr: 0.000500
[08.20.19|12:36:23] 	Iter 9200 Done. | loss2: 366.7925 | loss_nll: 366.2720 | loss_kl: 0.5206 | lr: 0.000500
[08.20.19|12:39:20] 	Iter 9300 Done. | loss2: 146.0577 | loss_nll: 145.9084 | loss_kl: 0.1493 | lr: 0.000500
[08.20.19|12:42:20] 	Iter 9400 Done. | loss2: 83.0475 | loss_nll: 82.6861 | loss_kl: 0.3615 | lr: 0.000500
[08.20.19|12:45:19] 	Iter 9500 Done. | loss2: 188.9565 | loss_nll: 188.8000 | loss_kl: 0.1565 | lr: 0.000500
[08.20.19|12:48:16] 	Iter 9600 Done. | loss2: 61.5116 | loss_nll: 61.2018 | loss_kl: 0.3098 | lr: 0.000500
[08.20.19|12:51:12] 	Iter 9700 Done. | loss2: 81.2804 | loss_nll: 81.1036 | loss_kl: 0.1768 | lr: 0.000500
[08.20.19|12:53:59] 	Iter 9800 Done. | loss2: 93.4401 | loss_nll: 93.3208 | loss_kl: 0.1193 | lr: 0.000500
[08.20.19|12:56:50] 	Iter 9900 Done. | loss2: 117.2246 | loss_nll: 116.9870 | loss_kl: 0.2376 | lr: 0.000500
[08.20.19|12:59:42] 	Iter 10000 Done. | loss2: 241.1882 | loss_nll: 240.7644 | loss_kl: 0.4238 | lr: 0.000500
[08.20.19|13:00:07] 	mean_loss2: 174.18958840659633
[08.20.19|13:00:07] 	mean_loss_nll: 173.84968259464057
[08.20.19|13:00:07] 	mean_loss_kl: 0.3399056946805205
[08.20.19|13:00:07] Time consumption:
[08.20.19|13:00:07] Done.
[08.20.19|13:00:07] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch7_model1.pt.
[08.20.19|13:00:07] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch7_model2.pt.
[08.20.19|13:00:07] Training epoch: 8
[08.20.19|13:02:35] 	Iter 10100 Done. | loss2: 91.3338 | loss_nll: 90.1008 | loss_kl: 1.2330 | lr: 0.000500
[08.20.19|13:05:23] 	Iter 10200 Done. | loss2: 73.0456 | loss_nll: 72.7961 | loss_kl: 0.2495 | lr: 0.000500
[08.20.19|13:08:15] 	Iter 10300 Done. | loss2: 99.9869 | loss_nll: 99.8312 | loss_kl: 0.1558 | lr: 0.000500
[08.20.19|13:11:05] 	Iter 10400 Done. | loss2: 84.2923 | loss_nll: 84.1965 | loss_kl: 0.0958 | lr: 0.000500
[08.20.19|13:14:02] 	Iter 10500 Done. | loss2: 91.8575 | loss_nll: 91.6939 | loss_kl: 0.1637 | lr: 0.000500
[08.20.19|13:16:59] 	Iter 10600 Done. | loss2: 83.5014 | loss_nll: 83.3326 | loss_kl: 0.1689 | lr: 0.000500
[08.20.19|13:19:57] 	Iter 10700 Done. | loss2: 117.5052 | loss_nll: 116.6500 | loss_kl: 0.8552 | lr: 0.000500
[08.20.19|13:23:04] 	Iter 10800 Done. | loss2: 65.6985 | loss_nll: 65.3320 | loss_kl: 0.3665 | lr: 0.000500
[08.20.19|13:26:14] 	Iter 10900 Done. | loss2: 308.8944 | loss_nll: 308.7237 | loss_kl: 0.1707 | lr: 0.000500
[08.20.19|13:29:24] 	Iter 11000 Done. | loss2: 77.4558 | loss_nll: 76.9027 | loss_kl: 0.5530 | lr: 0.000500
[08.20.19|13:32:29] 	Iter 11100 Done. | loss2: 104.6350 | loss_nll: 104.5100 | loss_kl: 0.1250 | lr: 0.000500
[08.20.19|13:35:35] 	Iter 11200 Done. | loss2: 641.1190 | loss_nll: 640.7819 | loss_kl: 0.3371 | lr: 0.000500
[08.20.19|13:37:32] 	mean_loss2: 172.6292681374108
[08.20.19|13:37:32] 	mean_loss_nll: 172.2712690213237
[08.20.19|13:37:32] 	mean_loss_kl: 0.35799959552483246
[08.20.19|13:37:32] Time consumption:
[08.20.19|13:37:32] Done.
[08.20.19|13:37:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch8_model1.pt.
[08.20.19|13:37:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch8_model2.pt.
[08.20.19|13:37:32] Training epoch: 9
[08.20.19|13:38:31] 	Iter 11300 Done. | loss2: 148.6020 | loss_nll: 148.2598 | loss_kl: 0.3423 | lr: 0.000500
[08.20.19|13:41:29] 	Iter 11400 Done. | loss2: 144.2196 | loss_nll: 143.8035 | loss_kl: 0.4161 | lr: 0.000500
[08.20.19|13:44:28] 	Iter 11500 Done. | loss2: 54.5547 | loss_nll: 54.4904 | loss_kl: 0.0643 | lr: 0.000500
[08.20.19|13:47:27] 	Iter 11600 Done. | loss2: 97.3774 | loss_nll: 97.1307 | loss_kl: 0.2468 | lr: 0.000500
[08.20.19|13:50:25] 	Iter 11700 Done. | loss2: 245.5229 | loss_nll: 245.0220 | loss_kl: 0.5009 | lr: 0.000500
[08.20.19|13:53:27] 	Iter 11800 Done. | loss2: 153.7580 | loss_nll: 153.5301 | loss_kl: 0.2279 | lr: 0.000500
[08.20.19|13:56:29] 	Iter 11900 Done. | loss2: 88.8222 | loss_nll: 88.6358 | loss_kl: 0.1864 | lr: 0.000500
[08.20.19|13:59:26] 	Iter 12000 Done. | loss2: 78.2259 | loss_nll: 77.1770 | loss_kl: 1.0489 | lr: 0.000500
[08.20.19|14:02:23] 	Iter 12100 Done. | loss2: 92.4290 | loss_nll: 92.3199 | loss_kl: 0.1091 | lr: 0.000500
[08.20.19|14:05:24] 	Iter 12200 Done. | loss2: 81.6575 | loss_nll: 80.9763 | loss_kl: 0.6812 | lr: 0.000500
[08.20.19|14:08:28] 	Iter 12300 Done. | loss2: 100.8718 | loss_nll: 100.6532 | loss_kl: 0.2186 | lr: 0.000500
[08.20.19|14:11:27] 	Iter 12400 Done. | loss2: 541.3583 | loss_nll: 541.0748 | loss_kl: 0.2835 | lr: 0.000500
[08.20.19|14:14:27] 	Iter 12500 Done. | loss2: 128.9193 | loss_nll: 128.5837 | loss_kl: 0.3357 | lr: 0.000500
[08.20.19|14:15:02] 	mean_loss2: 172.17940808561283
[08.20.19|14:15:02] 	mean_loss_nll: 171.87683651774836
[08.20.19|14:15:02] 	mean_loss_kl: 0.3025714795732984
[08.20.19|14:15:02] Time consumption:
[08.20.19|14:15:02] Done.
[08.20.19|14:15:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch9_model1.pt.
[08.20.19|14:15:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch9_model2.pt.
[08.20.19|14:15:03] Eval epoch: 9
[08.20.19|14:26:38] 	Eval_mean_loss2: 186.89352963321892
[08.20.19|14:26:38] 	Eval_mean_loss_nll: 186.73172386672147
[08.20.19|14:26:38] 	Eval_mean_loss_kl: 0.16180536592769068
[08.20.19|14:26:38] Done.

[08.21.19|07:29:02] Training epoch: 10
[08.21.19|07:29:21] 	Iter 0 Done. | loss1: 4.2127 | loss_class: 4.2079 | loss_recon: 0.0048 | lr: 0.100000
[08.21.19|07:32:14] 	Iter 100 Done. | loss1: 4.1803 | loss_class: 4.1763 | loss_recon: 0.0040 | lr: 0.100000
[08.21.19|07:35:16] 	Iter 200 Done. | loss1: 3.8958 | loss_class: 3.8946 | loss_recon: 0.0012 | lr: 0.100000
[08.21.19|07:38:20] 	Iter 300 Done. | loss1: 3.9065 | loss_class: 3.8976 | loss_recon: 0.0089 | lr: 0.100000
[08.21.19|07:41:19] 	Iter 400 Done. | loss1: 3.8030 | loss_class: 3.8017 | loss_recon: 0.0013 | lr: 0.100000
[08.21.19|07:44:20] 	Iter 500 Done. | loss1: 3.5660 | loss_class: 3.5650 | loss_recon: 0.0011 | lr: 0.100000
[08.21.19|07:49:33] 	Iter 600 Done. | loss1: 3.4680 | loss_class: 3.4670 | loss_recon: 0.0010 | lr: 0.100000
[08.21.19|07:54:52] 	Iter 700 Done. | loss1: 3.3283 | loss_class: 3.3273 | loss_recon: 0.0010 | lr: 0.100000
[08.21.19|08:00:29] 	Iter 800 Done. | loss1: 3.2047 | loss_class: 3.2038 | loss_recon: 0.0009 | lr: 0.100000
[08.21.19|08:05:58] 	Iter 900 Done. | loss1: 3.3611 | loss_class: 3.3602 | loss_recon: 0.0009 | lr: 0.100000
[08.21.19|08:11:19] 	Iter 1000 Done. | loss1: 2.6674 | loss_class: 2.6665 | loss_recon: 0.0009 | lr: 0.100000
[08.21.19|08:16:27] 	Iter 1100 Done. | loss1: 2.7553 | loss_class: 2.7545 | loss_recon: 0.0009 | lr: 0.100000
[08.21.19|08:21:47] 	Iter 1200 Done. | loss1: 3.0783 | loss_class: 3.0775 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|08:24:22] 	mean_loss1: 3.4773317565933204
[08.21.19|08:24:22] 	mean_loss_class: 3.4748513540520833
[08.21.19|08:24:22] 	mean_loss_recon: 0.002480405221184412
[08.21.19|08:24:22] Time consumption:
[08.21.19|08:24:22] Done.
[08.21.19|08:24:22] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch10_model1.pt.
[08.21.19|08:24:22] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch10_model2.pt.
[08.21.19|08:24:22] Training epoch: 11
[08.21.19|08:27:03] 	Iter 1300 Done. | loss1: 2.5500 | loss_class: 2.5491 | loss_recon: 0.0009 | lr: 0.100000
[08.21.19|08:32:17] 	Iter 1400 Done. | loss1: 2.7858 | loss_class: 2.7850 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|08:37:32] 	Iter 1500 Done. | loss1: 2.6252 | loss_class: 2.6244 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|08:42:49] 	Iter 1600 Done. | loss1: 2.4146 | loss_class: 2.4138 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|08:48:19] 	Iter 1700 Done. | loss1: 2.6818 | loss_class: 2.6810 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|08:53:33] 	Iter 1800 Done. | loss1: 1.7945 | loss_class: 1.7938 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|08:58:44] 	Iter 1900 Done. | loss1: 2.0643 | loss_class: 2.0635 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|09:04:03] 	Iter 2000 Done. | loss1: 2.1000 | loss_class: 2.0992 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|09:09:20] 	Iter 2100 Done. | loss1: 2.0961 | loss_class: 2.0954 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|09:14:42] 	Iter 2200 Done. | loss1: 2.2064 | loss_class: 2.2056 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|09:19:57] 	Iter 2300 Done. | loss1: 2.0648 | loss_class: 2.0641 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|09:25:09] 	Iter 2400 Done. | loss1: 2.2072 | loss_class: 2.2065 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|09:30:21] 	Iter 2500 Done. | loss1: 1.8489 | loss_class: 1.8481 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|09:30:30] 	mean_loss1: 2.1994713960935512
[08.21.19|09:30:30] 	mean_loss_class: 2.198684902998586
[08.21.19|09:30:30] 	mean_loss_recon: 0.0007864953187136605
[08.21.19|09:30:30] Time consumption:
[08.21.19|09:30:30] Done.
[08.21.19|09:30:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch11_model1.pt.
[08.21.19|09:30:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch11_model2.pt.
[08.21.19|09:30:30] Training epoch: 12
[08.21.19|09:35:39] 	Iter 2600 Done. | loss1: 1.9749 | loss_class: 1.9742 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|09:40:53] 	Iter 2700 Done. | loss1: 1.9374 | loss_class: 1.9367 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|09:45:59] 	Iter 2800 Done. | loss1: 1.5908 | loss_class: 1.5901 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|09:51:13] 	Iter 2900 Done. | loss1: 1.8707 | loss_class: 1.8700 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|09:56:31] 	Iter 3000 Done. | loss1: 1.7630 | loss_class: 1.7623 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|10:02:01] 	Iter 3100 Done. | loss1: 1.3833 | loss_class: 1.3826 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|10:07:07] 	Iter 3200 Done. | loss1: 1.5439 | loss_class: 1.5432 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|10:12:37] 	Iter 3300 Done. | loss1: 1.5324 | loss_class: 1.5317 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|10:17:50] 	Iter 3400 Done. | loss1: 1.9345 | loss_class: 1.9338 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|10:22:56] 	Iter 3500 Done. | loss1: 1.6295 | loss_class: 1.6289 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|10:28:13] 	Iter 3600 Done. | loss1: 1.5530 | loss_class: 1.5523 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|10:33:34] 	Iter 3700 Done. | loss1: 1.7007 | loss_class: 1.6999 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|10:36:23] 	mean_loss1: 1.6497656318326346
[08.21.19|10:36:23] 	mean_loss_class: 1.6490542057413644
[08.21.19|10:36:23] 	mean_loss_recon: 0.000711425882154189
[08.21.19|10:36:23] Time consumption:
[08.21.19|10:36:23] Done.
[08.21.19|10:36:23] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch12_model1.pt.
[08.21.19|10:36:23] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch12_model2.pt.
[08.21.19|10:36:23] Training epoch: 13
[08.21.19|10:38:49] 	Iter 3800 Done. | loss1: 2.2439 | loss_class: 2.2432 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|10:44:12] 	Iter 3900 Done. | loss1: 1.1880 | loss_class: 1.1874 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|10:49:29] 	Iter 4000 Done. | loss1: 1.3579 | loss_class: 1.3571 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|10:54:46] 	Iter 4100 Done. | loss1: 1.0070 | loss_class: 1.0063 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:00:03] 	Iter 4200 Done. | loss1: 1.1067 | loss_class: 1.1060 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:05:06] 	Iter 4300 Done. | loss1: 1.5470 | loss_class: 1.5463 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:10:28] 	Iter 4400 Done. | loss1: 1.1424 | loss_class: 1.1417 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:15:48] 	Iter 4500 Done. | loss1: 1.4869 | loss_class: 1.4862 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:20:50] 	Iter 4600 Done. | loss1: 1.1829 | loss_class: 1.1822 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:26:04] 	Iter 4700 Done. | loss1: 1.1296 | loss_class: 1.1287 | loss_recon: 0.0009 | lr: 0.100000
[08.21.19|11:31:23] 	Iter 4800 Done. | loss1: 1.4653 | loss_class: 1.4646 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:36:45] 	Iter 4900 Done. | loss1: 1.1162 | loss_class: 1.1155 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:42:04] 	Iter 5000 Done. | loss1: 1.2445 | loss_class: 1.2437 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|11:42:27] 	mean_loss1: 1.3474991042821551
[08.21.19|11:42:27] 	mean_loss_class: 1.3468242622554873
[08.21.19|11:42:27] 	mean_loss_recon: 0.0006748427058787295
[08.21.19|11:42:27] Time consumption:
[08.21.19|11:42:27] Done.
[08.21.19|11:42:27] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch13_model1.pt.
[08.21.19|11:42:27] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch13_model2.pt.
[08.21.19|11:42:27] Training epoch: 14
[08.21.19|11:47:22] 	Iter 5100 Done. | loss1: 1.0589 | loss_class: 1.0582 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|11:52:28] 	Iter 5200 Done. | loss1: 1.9136 | loss_class: 1.9130 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|11:57:51] 	Iter 5300 Done. | loss1: 0.7470 | loss_class: 0.7463 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|12:03:09] 	Iter 5400 Done. | loss1: 1.1075 | loss_class: 1.1069 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|12:08:15] 	Iter 5500 Done. | loss1: 1.7865 | loss_class: 1.7859 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|12:13:26] 	Iter 5600 Done. | loss1: 0.9885 | loss_class: 0.9879 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|12:18:51] 	Iter 5700 Done. | loss1: 1.1701 | loss_class: 1.1695 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|12:24:06] 	Iter 5800 Done. | loss1: 1.0765 | loss_class: 1.0758 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|12:29:32] 	Iter 5900 Done. | loss1: 1.2625 | loss_class: 1.2618 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|12:34:37] 	Iter 6000 Done. | loss1: 1.4324 | loss_class: 1.4318 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|12:39:56] 	Iter 6100 Done. | loss1: 0.6267 | loss_class: 0.6260 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|12:45:25] 	Iter 6200 Done. | loss1: 1.1591 | loss_class: 1.1585 | loss_recon: 0.0005 | lr: 0.100000
[08.21.19|12:48:31] 	mean_loss1: 1.1745159333220685
[08.21.19|12:48:31] 	mean_loss_class: 1.173865645195539
[08.21.19|12:48:31] 	mean_loss_recon: 0.0006502876794054961
[08.21.19|12:48:31] Time consumption:
[08.21.19|12:48:31] Done.
[08.21.19|12:48:31] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch14_model1.pt.
[08.21.19|12:48:31] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch14_model2.pt.
[08.21.19|12:48:31] Eval epoch: 14
[08.21.19|13:12:29] 	Eval_mean_loss1: 1.7001106750595478
[08.21.19|13:12:29] 	Eval_mean_loss_class: 1.6997647160707519
[08.21.19|13:12:29] 	Eval_mean_loss_recon: 0.034596203071924375
[08.21.19|13:12:29] 

[08.21.19|13:12:29] 	Top1: 52.09%
[08.21.19|13:12:30] 

[08.21.19|13:12:30] 	Top5: 84.61%
[08.21.19|13:12:30] Done.
[08.21.19|13:12:30] Training epoch: 15
[08.21.19|13:15:07] 	Iter 6300 Done. | loss1: 0.8394 | loss_class: 0.8388 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|13:21:20] 	Iter 6400 Done. | loss1: 0.7308 | loss_class: 0.7302 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|13:27:19] 	Iter 6500 Done. | loss1: 0.5847 | loss_class: 0.5840 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|13:32:39] 	Iter 6600 Done. | loss1: 1.4895 | loss_class: 1.4888 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|13:37:59] 	Iter 6700 Done. | loss1: 1.3732 | loss_class: 1.3725 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|13:43:34] 	Iter 6800 Done. | loss1: 1.1133 | loss_class: 1.1126 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|13:48:57] 	Iter 6900 Done. | loss1: 0.8987 | loss_class: 0.8980 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|13:54:28] 	Iter 7000 Done. | loss1: 1.4768 | loss_class: 1.4762 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|13:59:49] 	Iter 7100 Done. | loss1: 1.3817 | loss_class: 1.3811 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|14:05:10] 	Iter 7200 Done. | loss1: 0.5750 | loss_class: 0.5744 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|14:10:38] 	Iter 7300 Done. | loss1: 1.7160 | loss_class: 1.7154 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|14:15:58] 	Iter 7400 Done. | loss1: 1.0260 | loss_class: 1.0253 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|14:21:25] 	Iter 7500 Done. | loss1: 0.9895 | loss_class: 0.9889 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|14:22:03] 	mean_loss1: 1.051296186166259
[08.21.19|14:22:03] 	mean_loss_class: 1.0506524140604387
[08.21.19|14:22:03] 	mean_loss_recon: 0.000643771790360776
[08.21.19|14:22:03] Time consumption:
[08.21.19|14:22:03] Done.
[08.21.19|14:22:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch15_model1.pt.
[08.21.19|14:22:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch15_model2.pt.
[08.21.19|14:22:03] Training epoch: 16
[08.21.19|14:27:04] 	Iter 7600 Done. | loss1: 0.8749 | loss_class: 0.8742 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|14:32:29] 	Iter 7700 Done. | loss1: 0.6715 | loss_class: 0.6708 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|14:37:45] 	Iter 7800 Done. | loss1: 0.9908 | loss_class: 0.9901 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|14:43:11] 	Iter 7900 Done. | loss1: 1.0574 | loss_class: 1.0567 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|14:48:29] 	Iter 8000 Done. | loss1: 0.7930 | loss_class: 0.7925 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|14:53:41] 	Iter 8100 Done. | loss1: 1.0839 | loss_class: 1.0831 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|14:59:04] 	Iter 8200 Done. | loss1: 0.8047 | loss_class: 0.8041 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|15:04:36] 	Iter 8300 Done. | loss1: 1.4003 | loss_class: 1.3996 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|15:09:46] 	Iter 8400 Done. | loss1: 0.9691 | loss_class: 0.9684 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|15:15:08] 	Iter 8500 Done. | loss1: 0.6713 | loss_class: 0.6707 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|15:20:25] 	Iter 8600 Done. | loss1: 1.1776 | loss_class: 1.1769 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|15:25:40] 	Iter 8700 Done. | loss1: 1.0094 | loss_class: 1.0089 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|15:29:07] 	mean_loss1: 0.9732271434304813
[08.21.19|15:29:07] 	mean_loss_class: 0.9725882956823602
[08.21.19|15:29:07] 	mean_loss_recon: 0.0006388467058432273
[08.21.19|15:29:07] Time consumption:
[08.21.19|15:29:07] Done.
[08.21.19|15:29:07] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch16_model1.pt.
[08.21.19|15:29:07] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch16_model2.pt.
[08.21.19|15:29:07] Training epoch: 17
[08.21.19|15:31:01] 	Iter 8800 Done. | loss1: 1.2488 | loss_class: 1.2482 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|15:36:25] 	Iter 8900 Done. | loss1: 1.0122 | loss_class: 1.0116 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|15:41:35] 	Iter 9000 Done. | loss1: 1.1600 | loss_class: 1.1593 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|15:46:47] 	Iter 9100 Done. | loss1: 0.6608 | loss_class: 0.6601 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|15:51:55] 	Iter 9200 Done. | loss1: 0.9599 | loss_class: 0.9592 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|15:56:59] 	Iter 9300 Done. | loss1: 0.5081 | loss_class: 0.5074 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|16:02:19] 	Iter 9400 Done. | loss1: 0.9931 | loss_class: 0.9925 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|16:07:30] 	Iter 9500 Done. | loss1: 0.6011 | loss_class: 0.6005 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|16:12:48] 	Iter 9600 Done. | loss1: 0.9141 | loss_class: 0.9134 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|16:17:53] 	Iter 9700 Done. | loss1: 0.6854 | loss_class: 0.6848 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|16:22:58] 	Iter 9800 Done. | loss1: 0.8014 | loss_class: 0.8008 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|16:28:02] 	Iter 9900 Done. | loss1: 0.8281 | loss_class: 0.8274 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|16:32:56] 	Iter 10000 Done. | loss1: 0.7814 | loss_class: 0.7807 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|16:33:38] 	mean_loss1: 0.9039336021144551
[08.21.19|16:33:38] 	mean_loss_class: 0.9032960483631768
[08.21.19|16:33:38] 	mean_loss_recon: 0.0006375542912072839
[08.21.19|16:33:38] Time consumption:
[08.21.19|16:33:38] Done.
[08.21.19|16:33:38] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch17_model1.pt.
[08.21.19|16:33:38] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch17_model2.pt.
[08.21.19|16:33:38] Training epoch: 18
[08.21.19|16:38:04] 	Iter 10100 Done. | loss1: 0.7847 | loss_class: 0.7841 | loss_recon: 0.0005 | lr: 0.100000
[08.21.19|16:43:11] 	Iter 10200 Done. | loss1: 0.8678 | loss_class: 0.8672 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|16:48:20] 	Iter 10300 Done. | loss1: 0.8403 | loss_class: 0.8396 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|16:53:21] 	Iter 10400 Done. | loss1: 1.0202 | loss_class: 1.0196 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|16:58:23] 	Iter 10500 Done. | loss1: 0.6893 | loss_class: 0.6887 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|17:03:37] 	Iter 10600 Done. | loss1: 0.7722 | loss_class: 0.7715 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|17:08:49] 	Iter 10700 Done. | loss1: 1.4360 | loss_class: 1.4354 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|17:13:55] 	Iter 10800 Done. | loss1: 0.9278 | loss_class: 0.9272 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|17:18:49] 	Iter 10900 Done. | loss1: 0.7757 | loss_class: 0.7750 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|17:23:57] 	Iter 11000 Done. | loss1: 1.4455 | loss_class: 1.4449 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|17:29:11] 	Iter 11100 Done. | loss1: 1.0027 | loss_class: 1.0019 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|17:34:15] 	Iter 11200 Done. | loss1: 1.3497 | loss_class: 1.3491 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|17:37:43] 	mean_loss1: 0.8486045136476477
[08.21.19|17:37:43] 	mean_loss_class: 0.8479730114816858
[08.21.19|17:37:43] 	mean_loss_recon: 0.0006315023009888471
[08.21.19|17:37:43] Time consumption:
[08.21.19|17:37:43] Done.
[08.21.19|17:37:43] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch18_model1.pt.
[08.21.19|17:37:43] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch18_model2.pt.
[08.21.19|17:37:43] Training epoch: 19
[08.21.19|17:39:27] 	Iter 11300 Done. | loss1: 0.6434 | loss_class: 0.6428 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|17:44:15] 	Iter 11400 Done. | loss1: 0.7719 | loss_class: 0.7713 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|17:49:11] 	Iter 11500 Done. | loss1: 0.8694 | loss_class: 0.8687 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|17:54:11] 	Iter 11600 Done. | loss1: 0.6534 | loss_class: 0.6527 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|17:59:01] 	Iter 11700 Done. | loss1: 1.0306 | loss_class: 1.0300 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|18:03:50] 	Iter 11800 Done. | loss1: 0.4945 | loss_class: 0.4939 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|18:08:41] 	Iter 11900 Done. | loss1: 1.1454 | loss_class: 1.1449 | loss_recon: 0.0005 | lr: 0.100000
[08.21.19|18:13:23] 	Iter 12000 Done. | loss1: 0.4682 | loss_class: 0.4676 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|18:18:17] 	Iter 12100 Done. | loss1: 0.5668 | loss_class: 0.5661 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|18:23:15] 	Iter 12200 Done. | loss1: 0.8588 | loss_class: 0.8582 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|18:28:13] 	Iter 12300 Done. | loss1: 0.8319 | loss_class: 0.8313 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|18:33:01] 	Iter 12400 Done. | loss1: 0.9714 | loss_class: 0.9708 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|18:38:06] 	Iter 12500 Done. | loss1: 0.7392 | loss_class: 0.7386 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|18:39:10] 	mean_loss1: 0.8055017716325701
[08.21.19|18:39:10] 	mean_loss_class: 0.8048698336433489
[08.21.19|18:39:10] 	mean_loss_recon: 0.0006319386236512432
[08.21.19|18:39:10] Time consumption:
[08.21.19|18:39:10] Done.
[08.21.19|18:39:10] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch19_model1.pt.
[08.21.19|18:39:10] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch19_model2.pt.
[08.21.19|18:39:10] Eval epoch: 19
[08.21.19|19:01:50] 	Eval_mean_loss1: 1.632688341445701
[08.21.19|19:01:50] 	Eval_mean_loss_class: 1.6323752092529638
[08.21.19|19:01:50] 	Eval_mean_loss_recon: 0.031313358416217706
[08.21.19|19:01:50] 

[08.21.19|19:01:50] 	Top1: 59.22%
[08.21.19|19:01:50] 

[08.21.19|19:01:50] 	Top5: 88.37%
[08.21.19|19:01:50] Done.
[08.21.19|19:01:50] Training epoch: 20
[08.21.19|19:05:59] 	Iter 12600 Done. | loss1: 0.7250 | loss_class: 0.7243 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|19:10:52] 	Iter 12700 Done. | loss1: 0.8334 | loss_class: 0.8329 | loss_recon: 0.0005 | lr: 0.100000
[08.21.19|19:15:59] 	Iter 12800 Done. | loss1: 1.1333 | loss_class: 1.1327 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|19:20:52] 	Iter 12900 Done. | loss1: 0.8422 | loss_class: 0.8414 | loss_recon: 0.0008 | lr: 0.100000
[08.21.19|19:25:53] 	Iter 13000 Done. | loss1: 0.8069 | loss_class: 0.8062 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|19:30:57] 	Iter 13100 Done. | loss1: 0.6151 | loss_class: 0.6144 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|19:35:54] 	Iter 13200 Done. | loss1: 0.5921 | loss_class: 0.5915 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|19:40:48] 	Iter 13300 Done. | loss1: 0.7653 | loss_class: 0.7647 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|19:45:43] 	Iter 13400 Done. | loss1: 0.7416 | loss_class: 0.7410 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|19:50:40] 	Iter 13500 Done. | loss1: 0.7132 | loss_class: 0.7125 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|19:55:41] 	Iter 13600 Done. | loss1: 0.5169 | loss_class: 0.5163 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:00:32] 	Iter 13700 Done. | loss1: 1.0031 | loss_class: 1.0026 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:04:02] 	mean_loss1: 0.7742867002995631
[08.21.19|20:04:02] 	mean_loss_class: 0.773656969193738
[08.21.19|20:04:02] 	mean_loss_recon: 0.0006297308787965357
[08.21.19|20:04:02] Time consumption:
[08.21.19|20:04:02] Done.
[08.21.19|20:04:02] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch20_model1.pt.
[08.21.19|20:04:02] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch20_model2.pt.
[08.21.19|20:04:02] Training epoch: 21
[08.21.19|20:05:28] 	Iter 13800 Done. | loss1: 0.7578 | loss_class: 0.7572 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:10:18] 	Iter 13900 Done. | loss1: 0.5858 | loss_class: 0.5851 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:15:26] 	Iter 14000 Done. | loss1: 0.6903 | loss_class: 0.6897 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:20:26] 	Iter 14100 Done. | loss1: 0.7134 | loss_class: 0.7128 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:25:26] 	Iter 14200 Done. | loss1: 0.5657 | loss_class: 0.5651 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:30:23] 	Iter 14300 Done. | loss1: 0.7768 | loss_class: 0.7762 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:35:21] 	Iter 14400 Done. | loss1: 0.6044 | loss_class: 0.6038 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:40:24] 	Iter 14500 Done. | loss1: 1.2121 | loss_class: 1.2115 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:45:30] 	Iter 14600 Done. | loss1: 0.7621 | loss_class: 0.7615 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:50:30] 	Iter 14700 Done. | loss1: 0.6546 | loss_class: 0.6541 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|20:55:23] 	Iter 14800 Done. | loss1: 0.6612 | loss_class: 0.6606 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:00:20] 	Iter 14900 Done. | loss1: 0.5186 | loss_class: 0.5180 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:05:14] 	Iter 15000 Done. | loss1: 0.4334 | loss_class: 0.4326 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|21:06:19] 	mean_loss1: 0.7328026322796702
[08.21.19|21:06:19] 	mean_loss_class: 0.7321779845169367
[08.21.19|21:06:19] 	mean_loss_recon: 0.0006246484298937428
[08.21.19|21:06:19] Time consumption:
[08.21.19|21:06:19] Done.
[08.21.19|21:06:19] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch21_model1.pt.
[08.21.19|21:06:19] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch21_model2.pt.
[08.21.19|21:06:19] Training epoch: 22
[08.21.19|21:10:18] 	Iter 15100 Done. | loss1: 0.5026 | loss_class: 0.5020 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:15:23] 	Iter 15200 Done. | loss1: 1.0033 | loss_class: 1.0027 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:20:20] 	Iter 15300 Done. | loss1: 0.4424 | loss_class: 0.4417 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|21:25:01] 	Iter 15400 Done. | loss1: 0.4429 | loss_class: 0.4423 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|21:29:57] 	Iter 15500 Done. | loss1: 1.3575 | loss_class: 1.3568 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|21:34:50] 	Iter 15600 Done. | loss1: 0.4655 | loss_class: 0.4649 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:39:45] 	Iter 15700 Done. | loss1: 0.5273 | loss_class: 0.5267 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:44:51] 	Iter 15800 Done. | loss1: 0.3809 | loss_class: 0.3802 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:49:58] 	Iter 15900 Done. | loss1: 0.6542 | loss_class: 0.6536 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|21:55:04] 	Iter 16000 Done. | loss1: 0.5385 | loss_class: 0.5379 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:00:00] 	Iter 16100 Done. | loss1: 0.5150 | loss_class: 0.5144 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:04:56] 	Iter 16200 Done. | loss1: 0.8351 | loss_class: 0.8345 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:08:48] 	mean_loss1: 0.7101702793551901
[08.21.19|22:08:48] 	mean_loss_class: 0.7095493507889894
[08.21.19|22:08:48] 	mean_loss_recon: 0.0006209289363493172
[08.21.19|22:08:48] Time consumption:
[08.21.19|22:08:48] Done.
[08.21.19|22:08:48] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch22_model1.pt.
[08.21.19|22:08:48] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch22_model2.pt.
[08.21.19|22:08:48] Training epoch: 23
[08.21.19|22:10:04] 	Iter 16300 Done. | loss1: 0.4826 | loss_class: 0.4820 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:14:57] 	Iter 16400 Done. | loss1: 0.8292 | loss_class: 0.8285 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|22:19:44] 	Iter 16500 Done. | loss1: 0.7408 | loss_class: 0.7401 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:24:30] 	Iter 16600 Done. | loss1: 0.7570 | loss_class: 0.7564 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:29:32] 	Iter 16700 Done. | loss1: 0.8611 | loss_class: 0.8604 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:34:26] 	Iter 16800 Done. | loss1: 0.7712 | loss_class: 0.7705 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|22:39:26] 	Iter 16900 Done. | loss1: 0.7178 | loss_class: 0.7172 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:44:29] 	Iter 17000 Done. | loss1: 0.5818 | loss_class: 0.5812 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:49:22] 	Iter 17100 Done. | loss1: 0.5481 | loss_class: 0.5475 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:54:13] 	Iter 17200 Done. | loss1: 1.0943 | loss_class: 1.0937 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|22:58:58] 	Iter 17300 Done. | loss1: 0.6332 | loss_class: 0.6326 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:03:45] 	Iter 17400 Done. | loss1: 0.5854 | loss_class: 0.5848 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:08:27] 	Iter 17500 Done. | loss1: 0.5783 | loss_class: 0.5776 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:09:51] 	mean_loss1: 0.6819511476678018
[08.21.19|23:09:51] 	mean_loss_class: 0.6813315813914655
[08.21.19|23:09:51] 	mean_loss_recon: 0.000619566064780227
[08.21.19|23:09:51] Time consumption:
[08.21.19|23:09:51] Done.
[08.21.19|23:09:51] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch23_model1.pt.
[08.21.19|23:09:51] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch23_model2.pt.
[08.21.19|23:09:51] Training epoch: 24
[08.21.19|23:13:27] 	Iter 17600 Done. | loss1: 0.7304 | loss_class: 0.7298 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:18:29] 	Iter 17700 Done. | loss1: 0.7603 | loss_class: 0.7596 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:23:17] 	Iter 17800 Done. | loss1: 0.6352 | loss_class: 0.6346 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:27:55] 	Iter 17900 Done. | loss1: 0.6387 | loss_class: 0.6381 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:33:01] 	Iter 18000 Done. | loss1: 0.8996 | loss_class: 0.8989 | loss_recon: 0.0007 | lr: 0.100000
[08.21.19|23:37:54] 	Iter 18100 Done. | loss1: 0.6600 | loss_class: 0.6593 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:42:47] 	Iter 18200 Done. | loss1: 1.2135 | loss_class: 1.2129 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:47:35] 	Iter 18300 Done. | loss1: 0.4879 | loss_class: 0.4873 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:52:32] 	Iter 18400 Done. | loss1: 0.6609 | loss_class: 0.6603 | loss_recon: 0.0006 | lr: 0.100000
[08.21.19|23:57:49] 	Iter 18500 Done. | loss1: 0.5948 | loss_class: 0.5943 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|00:03:17] 	Iter 18600 Done. | loss1: 0.2698 | loss_class: 0.2692 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|00:08:51] 	Iter 18700 Done. | loss1: 0.5657 | loss_class: 0.5651 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|00:13:20] 	mean_loss1: 0.6575476708598792
[08.22.19|00:13:20] 	mean_loss_class: 0.6569279129155718
[08.22.19|00:13:20] 	mean_loss_recon: 0.0006197581639269385
[08.22.19|00:13:20] Time consumption:
[08.22.19|00:13:20] Done.
[08.22.19|00:13:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch24_model1.pt.
[08.22.19|00:13:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch24_model2.pt.
[08.22.19|00:13:20] Eval epoch: 24
[08.22.19|00:33:48] 	Eval_mean_loss1: 1.2071213431136554
[08.22.19|00:33:48] 	Eval_mean_loss_class: 1.2067853848254957
[08.22.19|00:33:48] 	Eval_mean_loss_recon: 0.03359569851742234
[08.22.19|00:33:48] 

[08.22.19|00:33:48] 	Top1: 68.58%
[08.22.19|00:33:49] 

[08.22.19|00:33:49] 	Top5: 91.96%
[08.22.19|00:33:49] Done.
[08.22.19|00:33:49] Training epoch: 25
[08.22.19|00:34:51] 	Iter 18800 Done. | loss1: 0.5142 | loss_class: 0.5136 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|00:39:49] 	Iter 18900 Done. | loss1: 0.6798 | loss_class: 0.6792 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|00:44:43] 	Iter 19000 Done. | loss1: 0.7652 | loss_class: 0.7645 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|00:49:32] 	Iter 19100 Done. | loss1: 0.5617 | loss_class: 0.5610 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|00:54:22] 	Iter 19200 Done. | loss1: 0.5582 | loss_class: 0.5575 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|00:59:24] 	Iter 19300 Done. | loss1: 0.7634 | loss_class: 0.7627 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|01:04:18] 	Iter 19400 Done. | loss1: 0.3562 | loss_class: 0.3555 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|01:09:12] 	Iter 19500 Done. | loss1: 0.5194 | loss_class: 0.5188 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|01:14:10] 	Iter 19600 Done. | loss1: 0.5361 | loss_class: 0.5354 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|01:18:56] 	Iter 19700 Done. | loss1: 0.3788 | loss_class: 0.3781 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|01:23:59] 	Iter 19800 Done. | loss1: 0.6514 | loss_class: 0.6508 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|01:28:47] 	Iter 19900 Done. | loss1: 0.6315 | loss_class: 0.6309 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|01:33:44] 	Iter 20000 Done. | loss1: 0.6632 | loss_class: 0.6625 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|01:35:16] 	mean_loss1: 0.6428697468897405
[08.22.19|01:35:16] 	mean_loss_class: 0.6422496952068882
[08.22.19|01:35:16] 	mean_loss_recon: 0.0006200519590355908
[08.22.19|01:35:16] Time consumption:
[08.22.19|01:35:16] Done.
[08.22.19|01:35:16] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch25_model1.pt.
[08.22.19|01:35:16] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch25_model2.pt.
[08.22.19|01:35:16] Training epoch: 26
[08.22.19|01:38:38] 	Iter 20100 Done. | loss1: 0.6059 | loss_class: 0.6053 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|01:43:34] 	Iter 20200 Done. | loss1: 0.4396 | loss_class: 0.4389 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|01:48:24] 	Iter 20300 Done. | loss1: 0.7252 | loss_class: 0.7246 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|01:53:01] 	Iter 20400 Done. | loss1: 0.8642 | loss_class: 0.8637 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|01:57:47] 	Iter 20500 Done. | loss1: 0.5667 | loss_class: 0.5660 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:02:42] 	Iter 20600 Done. | loss1: 0.5773 | loss_class: 0.5766 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:07:32] 	Iter 20700 Done. | loss1: 0.9396 | loss_class: 0.9390 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:12:26] 	Iter 20800 Done. | loss1: 0.7061 | loss_class: 0.7054 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|02:17:27] 	Iter 20900 Done. | loss1: 0.3594 | loss_class: 0.3588 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|02:22:27] 	Iter 21000 Done. | loss1: 0.7672 | loss_class: 0.7665 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:27:17] 	Iter 21100 Done. | loss1: 0.4185 | loss_class: 0.4179 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:32:04] 	Iter 21200 Done. | loss1: 0.9468 | loss_class: 0.9462 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:36:16] 	mean_loss1: 0.615585630218061
[08.22.19|02:36:16] 	mean_loss_class: 0.6149668197828931
[08.22.19|02:36:16] 	mean_loss_recon: 0.0006188099891447222
[08.22.19|02:36:16] Time consumption:
[08.22.19|02:36:16] Done.
[08.22.19|02:36:16] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch26_model1.pt.
[08.22.19|02:36:16] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch26_model2.pt.
[08.22.19|02:36:16] Training epoch: 27
[08.22.19|02:37:04] 	Iter 21300 Done. | loss1: 0.5923 | loss_class: 0.5916 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|02:42:07] 	Iter 21400 Done. | loss1: 0.5638 | loss_class: 0.5633 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:46:49] 	Iter 21500 Done. | loss1: 0.2726 | loss_class: 0.2720 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:51:38] 	Iter 21600 Done. | loss1: 0.9665 | loss_class: 0.9659 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|02:56:33] 	Iter 21700 Done. | loss1: 0.7005 | loss_class: 0.6999 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:01:33] 	Iter 21800 Done. | loss1: 0.2958 | loss_class: 0.2952 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:06:24] 	Iter 21900 Done. | loss1: 0.7792 | loss_class: 0.7786 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:11:04] 	Iter 22000 Done. | loss1: 0.3302 | loss_class: 0.3295 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|03:15:49] 	Iter 22100 Done. | loss1: 0.3778 | loss_class: 0.3772 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:20:48] 	Iter 22200 Done. | loss1: 1.0568 | loss_class: 1.0562 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|03:25:36] 	Iter 22300 Done. | loss1: 0.7795 | loss_class: 0.7789 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:30:44] 	Iter 22400 Done. | loss1: 1.0558 | loss_class: 1.0552 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:35:45] 	Iter 22500 Done. | loss1: 1.0744 | loss_class: 1.0738 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|03:37:31] 	mean_loss1: 0.5999092497764685
[08.22.19|03:37:31] 	mean_loss_class: 0.5992902029103364
[08.22.19|03:37:31] 	mean_loss_recon: 0.0006190479351296879
[08.22.19|03:37:31] Time consumption:
[08.22.19|03:37:31] Done.
[08.22.19|03:37:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch27_model1.pt.
[08.22.19|03:37:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch27_model2.pt.
[08.22.19|03:37:32] Training epoch: 28
[08.22.19|03:40:51] 	Iter 22600 Done. | loss1: 0.3734 | loss_class: 0.3727 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|03:45:36] 	Iter 22700 Done. | loss1: 0.5795 | loss_class: 0.5789 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:50:36] 	Iter 22800 Done. | loss1: 0.1939 | loss_class: 0.1934 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|03:55:34] 	Iter 22900 Done. | loss1: 0.5662 | loss_class: 0.5656 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:00:32] 	Iter 23000 Done. | loss1: 0.3278 | loss_class: 0.3273 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:05:27] 	Iter 23100 Done. | loss1: 0.7972 | loss_class: 0.7966 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:10:18] 	Iter 23200 Done. | loss1: 0.3866 | loss_class: 0.3860 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:15:11] 	Iter 23300 Done. | loss1: 0.2937 | loss_class: 0.2930 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:19:54] 	Iter 23400 Done. | loss1: 0.4158 | loss_class: 0.4151 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:25:01] 	Iter 23500 Done. | loss1: 0.6121 | loss_class: 0.6115 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:29:46] 	Iter 23600 Done. | loss1: 0.6037 | loss_class: 0.6032 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|04:34:40] 	Iter 23700 Done. | loss1: 0.5708 | loss_class: 0.5701 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:39:02] 	mean_loss1: 0.5888544670142495
[08.22.19|04:39:02] 	mean_loss_class: 0.5882355899523242
[08.22.19|04:39:02] 	mean_loss_recon: 0.0006188775345492668
[08.22.19|04:39:02] Time consumption:
[08.22.19|04:39:02] Done.
[08.22.19|04:39:02] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch28_model1.pt.
[08.22.19|04:39:02] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch28_model2.pt.
[08.22.19|04:39:02] Training epoch: 29
[08.22.19|04:39:41] 	Iter 23800 Done. | loss1: 0.5415 | loss_class: 0.5408 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:44:26] 	Iter 23900 Done. | loss1: 0.8644 | loss_class: 0.8637 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|04:49:10] 	Iter 24000 Done. | loss1: 0.7050 | loss_class: 0.7043 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|04:53:52] 	Iter 24100 Done. | loss1: 0.5111 | loss_class: 0.5104 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|04:58:38] 	Iter 24200 Done. | loss1: 0.3381 | loss_class: 0.3374 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|05:03:43] 	Iter 24300 Done. | loss1: 1.0223 | loss_class: 1.0216 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|05:08:39] 	Iter 24400 Done. | loss1: 0.8441 | loss_class: 0.8436 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|05:14:10] 	Iter 24500 Done. | loss1: 0.5922 | loss_class: 0.5915 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|05:19:34] 	Iter 24600 Done. | loss1: 0.3670 | loss_class: 0.3664 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|05:25:01] 	Iter 24700 Done. | loss1: 0.4793 | loss_class: 0.4787 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|05:30:23] 	Iter 24800 Done. | loss1: 0.3717 | loss_class: 0.3711 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|05:34:53] 	Iter 24900 Done. | loss1: 0.1592 | loss_class: 0.1586 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|05:39:54] 	Iter 25000 Done. | loss1: 0.8884 | loss_class: 0.8877 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|05:41:49] 	mean_loss1: 0.5672464450232138
[08.22.19|05:41:49] 	mean_loss_class: 0.5666261085520347
[08.22.19|05:41:49] 	mean_loss_recon: 0.0006203365646683561
[08.22.19|05:41:49] Time consumption:
[08.22.19|05:41:49] Done.
[08.22.19|05:41:49] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch29_model1.pt.
[08.22.19|05:41:49] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch29_model2.pt.
[08.22.19|05:41:49] Eval epoch: 29
[08.22.19|06:02:25] 	Eval_mean_loss1: 0.8742806173630001
[08.22.19|06:02:25] 	Eval_mean_loss_class: 0.8739335726686689
[08.22.19|06:02:25] 	Eval_mean_loss_recon: 0.034704438565919794
[08.22.19|06:02:25] 

[08.22.19|06:02:25] 	Top1: 75.88%
[08.22.19|06:02:25] 

[08.22.19|06:02:25] 	Top5: 94.75%
[08.22.19|06:02:25] Done.

[08.22.19|06:57:11] Training epoch: 30
[08.22.19|06:57:27] 	Iter 0 Done. | loss1: 0.8676 | loss_class: 0.8670 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:00:29] 	Iter 100 Done. | loss1: 0.5268 | loss_class: 0.5262 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|07:03:30] 	Iter 200 Done. | loss1: 0.6495 | loss_class: 0.6489 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:06:32] 	Iter 300 Done. | loss1: 0.4246 | loss_class: 0.4241 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|07:11:47] 	Iter 400 Done. | loss1: 0.7797 | loss_class: 0.7791 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:17:39] 	Iter 500 Done. | loss1: 0.6740 | loss_class: 0.6733 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:23:24] 	Iter 600 Done. | loss1: 0.5554 | loss_class: 0.5549 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:28:54] 	Iter 700 Done. | loss1: 0.7226 | loss_class: 0.7220 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:34:29] 	Iter 800 Done. | loss1: 0.7052 | loss_class: 0.7046 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:39:58] 	Iter 900 Done. | loss1: 0.5498 | loss_class: 0.5492 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|07:45:47] 	Iter 1000 Done. | loss1: 0.6192 | loss_class: 0.6185 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|07:51:12] 	Iter 1100 Done. | loss1: 0.7558 | loss_class: 0.7551 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|07:56:51] 	Iter 1200 Done. | loss1: 0.3844 | loss_class: 0.3838 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|07:59:30] 	mean_loss1: 0.551344680061308
[08.22.19|07:59:30] 	mean_loss_class: 0.5507252666706475
[08.22.19|07:59:30] 	mean_loss_recon: 0.00061941351360692
[08.22.19|07:59:30] Time consumption:
[08.22.19|07:59:30] Done.
[08.22.19|07:59:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch30_model1.pt.
[08.22.19|07:59:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch30_model2.pt.
[08.22.19|07:59:30] Training epoch: 31
[08.22.19|08:02:13] 	Iter 1300 Done. | loss1: 0.4300 | loss_class: 0.4293 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|08:07:33] 	Iter 1400 Done. | loss1: 0.2531 | loss_class: 0.2525 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:12:29] 	Iter 1500 Done. | loss1: 0.4981 | loss_class: 0.4975 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:15:25] 	Iter 1600 Done. | loss1: 0.8279 | loss_class: 0.8273 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:18:22] 	Iter 1700 Done. | loss1: 0.4410 | loss_class: 0.4404 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:21:18] 	Iter 1800 Done. | loss1: 0.4740 | loss_class: 0.4734 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:24:13] 	Iter 1900 Done. | loss1: 0.5223 | loss_class: 0.5217 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:27:08] 	Iter 2000 Done. | loss1: 0.7513 | loss_class: 0.7507 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:30:05] 	Iter 2100 Done. | loss1: 0.1857 | loss_class: 0.1851 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:33:00] 	Iter 2200 Done. | loss1: 0.6166 | loss_class: 0.6160 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:35:54] 	Iter 2300 Done. | loss1: 0.3854 | loss_class: 0.3848 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:38:49] 	Iter 2400 Done. | loss1: 0.4749 | loss_class: 0.4743 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|08:41:41] 	Iter 2500 Done. | loss1: 0.8148 | loss_class: 0.8142 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:41:47] 	mean_loss1: 0.5450822352089535
[08.22.19|08:41:47] 	mean_loss_class: 0.5444629779948403
[08.22.19|08:41:47] 	mean_loss_recon: 0.0006192563361110398
[08.22.19|08:41:47] Time consumption:
[08.22.19|08:41:47] Done.
[08.22.19|08:41:47] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch31_model1.pt.
[08.22.19|08:41:47] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch31_model2.pt.
[08.22.19|08:41:47] Training epoch: 32
[08.22.19|08:44:37] 	Iter 2600 Done. | loss1: 0.5134 | loss_class: 0.5127 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|08:47:32] 	Iter 2700 Done. | loss1: 0.2708 | loss_class: 0.2702 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:50:29] 	Iter 2800 Done. | loss1: 0.5687 | loss_class: 0.5681 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:53:26] 	Iter 2900 Done. | loss1: 0.5019 | loss_class: 0.5013 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|08:56:20] 	Iter 3000 Done. | loss1: 0.4554 | loss_class: 0.4547 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|08:59:11] 	Iter 3100 Done. | loss1: 0.5272 | loss_class: 0.5266 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:02:02] 	Iter 3200 Done. | loss1: 0.6293 | loss_class: 0.6287 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:04:53] 	Iter 3300 Done. | loss1: 0.4764 | loss_class: 0.4759 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|09:07:46] 	Iter 3400 Done. | loss1: 0.4217 | loss_class: 0.4210 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:10:39] 	Iter 3500 Done. | loss1: 0.6659 | loss_class: 0.6653 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:13:30] 	Iter 3600 Done. | loss1: 0.6025 | loss_class: 0.6019 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:16:22] 	Iter 3700 Done. | loss1: 0.6213 | loss_class: 0.6207 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:17:58] 	mean_loss1: 0.5313653931224023
[08.22.19|09:17:58] 	mean_loss_class: 0.5307448466007892
[08.22.19|09:17:58] 	mean_loss_recon: 0.0006205463903054548
[08.22.19|09:17:58] Time consumption:
[08.22.19|09:17:58] Done.
[08.22.19|09:17:59] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch32_model1.pt.
[08.22.19|09:17:59] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch32_model2.pt.
[08.22.19|09:17:59] Training epoch: 33
[08.22.19|09:19:17] 	Iter 3800 Done. | loss1: 0.6331 | loss_class: 0.6325 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:22:10] 	Iter 3900 Done. | loss1: 0.4477 | loss_class: 0.4471 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:25:02] 	Iter 4000 Done. | loss1: 0.2642 | loss_class: 0.2636 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:27:58] 	Iter 4100 Done. | loss1: 0.2733 | loss_class: 0.2726 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|09:30:51] 	Iter 4200 Done. | loss1: 0.2086 | loss_class: 0.2080 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:33:45] 	Iter 4300 Done. | loss1: 0.7644 | loss_class: 0.7638 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:36:35] 	Iter 4400 Done. | loss1: 0.8094 | loss_class: 0.8088 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:39:26] 	Iter 4500 Done. | loss1: 0.4797 | loss_class: 0.4791 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:42:17] 	Iter 4600 Done. | loss1: 0.3375 | loss_class: 0.3368 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:45:10] 	Iter 4700 Done. | loss1: 0.7455 | loss_class: 0.7449 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:48:00] 	Iter 4800 Done. | loss1: 0.4792 | loss_class: 0.4786 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:50:53] 	Iter 4900 Done. | loss1: 0.3863 | loss_class: 0.3857 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|09:55:13] 	Iter 5000 Done. | loss1: 0.5691 | loss_class: 0.5685 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|09:55:36] 	mean_loss1: 0.519146436575455
[08.22.19|09:55:36] 	mean_loss_class: 0.5185268195316243
[08.22.19|09:55:36] 	mean_loss_recon: 0.0006196170694197711
[08.22.19|09:55:36] Time consumption:
[08.22.19|09:55:36] Done.
[08.22.19|09:55:36] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch33_model1.pt.
[08.22.19|09:55:36] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch33_model2.pt.
[08.22.19|09:55:36] Training epoch: 34
[08.22.19|10:01:06] 	Iter 5100 Done. | loss1: 0.2998 | loss_class: 0.2992 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:06:58] 	Iter 5200 Done. | loss1: 0.4572 | loss_class: 0.4566 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:12:35] 	Iter 5300 Done. | loss1: 0.3350 | loss_class: 0.3344 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:18:06] 	Iter 5400 Done. | loss1: 0.6086 | loss_class: 0.6080 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:23:40] 	Iter 5500 Done. | loss1: 0.7016 | loss_class: 0.7009 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:29:16] 	Iter 5600 Done. | loss1: 0.6588 | loss_class: 0.6582 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:35:14] 	Iter 5700 Done. | loss1: 0.8382 | loss_class: 0.8376 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:40:51] 	Iter 5800 Done. | loss1: 0.3004 | loss_class: 0.2998 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:46:26] 	Iter 5900 Done. | loss1: 0.4907 | loss_class: 0.4901 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:51:49] 	Iter 6000 Done. | loss1: 0.2329 | loss_class: 0.2323 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|10:57:17] 	Iter 6100 Done. | loss1: 1.0571 | loss_class: 1.0565 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|11:02:31] 	Iter 6200 Done. | loss1: 0.4424 | loss_class: 0.4418 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|11:05:49] 	mean_loss1: 0.5156913391186502
[08.22.19|11:05:49] 	mean_loss_class: 0.5150703950621449
[08.22.19|11:05:49] 	mean_loss_recon: 0.0006209442150085783
[08.22.19|11:05:49] Time consumption:
[08.22.19|11:05:49] Done.
[08.22.19|11:05:50] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch34_model1.pt.
[08.22.19|11:05:50] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch34_model2.pt.
[08.22.19|11:05:50] Eval epoch: 34
[08.22.19|11:28:43] 	Eval_mean_loss1: 1.0893960761758246
[08.22.19|11:28:43] 	Eval_mean_loss_class: 1.0890606479473817
[08.22.19|11:28:43] 	Eval_mean_loss_recon: 0.033542602933048046
[08.22.19|11:28:43] 

[08.22.19|11:28:43] 	Top1: 73.33%
[08.22.19|11:28:43] 

[08.22.19|11:28:43] 	Top5: 93.77%
[08.22.19|11:28:43] Done.
[08.22.19|11:28:43] Training epoch: 35
[08.22.19|11:31:04] 	Iter 6300 Done. | loss1: 0.2495 | loss_class: 0.2489 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|11:36:42] 	Iter 6400 Done. | loss1: 0.3920 | loss_class: 0.3915 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|11:42:13] 	Iter 6500 Done. | loss1: 0.3227 | loss_class: 0.3221 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|11:47:43] 	Iter 6600 Done. | loss1: 0.7639 | loss_class: 0.7633 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|11:53:13] 	Iter 6700 Done. | loss1: 0.3773 | loss_class: 0.3768 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|11:58:58] 	Iter 6800 Done. | loss1: 0.5413 | loss_class: 0.5406 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|12:04:33] 	Iter 6900 Done. | loss1: 0.2679 | loss_class: 0.2672 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|12:10:12] 	Iter 7000 Done. | loss1: 0.6502 | loss_class: 0.6496 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|12:15:53] 	Iter 7100 Done. | loss1: 0.5170 | loss_class: 0.5165 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|12:21:21] 	Iter 7200 Done. | loss1: 0.2522 | loss_class: 0.2516 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|12:26:46] 	Iter 7300 Done. | loss1: 0.3665 | loss_class: 0.3659 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|12:31:58] 	Iter 7400 Done. | loss1: 0.4636 | loss_class: 0.4630 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|12:37:26] 	Iter 7500 Done. | loss1: 0.6397 | loss_class: 0.6391 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|12:38:04] 	mean_loss1: 0.49874443310304
[08.22.19|12:38:04] 	mean_loss_class: 0.49812315111628735
[08.22.19|12:38:04] 	mean_loss_recon: 0.0006212818741905519
[08.22.19|12:38:04] Time consumption:
[08.22.19|12:38:04] Done.
[08.22.19|12:38:05] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch35_model1.pt.
[08.22.19|12:38:05] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch35_model2.pt.
[08.22.19|12:38:05] Training epoch: 36
[08.22.19|12:42:58] 	Iter 7600 Done. | loss1: 0.5740 | loss_class: 0.5732 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|12:48:35] 	Iter 7700 Done. | loss1: 0.2402 | loss_class: 0.2395 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|12:53:54] 	Iter 7800 Done. | loss1: 0.4704 | loss_class: 0.4697 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|12:59:22] 	Iter 7900 Done. | loss1: 0.3700 | loss_class: 0.3694 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:04:43] 	Iter 8000 Done. | loss1: 0.4453 | loss_class: 0.4447 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:10:29] 	Iter 8100 Done. | loss1: 0.5168 | loss_class: 0.5162 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:16:43] 	Iter 8200 Done. | loss1: 0.3533 | loss_class: 0.3526 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:22:50] 	Iter 8300 Done. | loss1: 0.6522 | loss_class: 0.6516 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:29:02] 	Iter 8400 Done. | loss1: 0.4398 | loss_class: 0.4392 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:35:06] 	Iter 8500 Done. | loss1: 0.6051 | loss_class: 0.6044 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|13:40:24] 	Iter 8600 Done. | loss1: 0.5346 | loss_class: 0.5340 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:45:48] 	Iter 8700 Done. | loss1: 0.7147 | loss_class: 0.7141 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|13:49:24] 	mean_loss1: 0.49444284458486987
[08.22.19|13:49:24] 	mean_loss_class: 0.4938211515783883
[08.22.19|13:49:24] 	mean_loss_recon: 0.0006216930004116446
[08.22.19|13:49:24] Time consumption:
[08.22.19|13:49:24] Done.
[08.22.19|13:49:24] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch36_model1.pt.
[08.22.19|13:49:24] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch36_model2.pt.
[08.22.19|13:49:24] Training epoch: 37
[08.22.19|13:51:30] 	Iter 8800 Done. | loss1: 1.0486 | loss_class: 1.0480 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|13:57:04] 	Iter 8900 Done. | loss1: 0.4198 | loss_class: 0.4193 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|14:02:38] 	Iter 9000 Done. | loss1: 0.4661 | loss_class: 0.4655 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:08:10] 	Iter 9100 Done. | loss1: 0.2832 | loss_class: 0.2826 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:13:39] 	Iter 9200 Done. | loss1: 0.2952 | loss_class: 0.2946 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:18:52] 	Iter 9300 Done. | loss1: 0.4844 | loss_class: 0.4838 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:24:21] 	Iter 9400 Done. | loss1: 0.5774 | loss_class: 0.5768 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:30:01] 	Iter 9500 Done. | loss1: 0.5227 | loss_class: 0.5221 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|14:35:11] 	Iter 9600 Done. | loss1: 0.2304 | loss_class: 0.2299 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:40:51] 	Iter 9700 Done. | loss1: 0.5288 | loss_class: 0.5281 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|14:46:39] 	Iter 9800 Done. | loss1: 0.2117 | loss_class: 0.2111 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:52:11] 	Iter 9900 Done. | loss1: 0.7096 | loss_class: 0.7090 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:57:49] 	Iter 10000 Done. | loss1: 0.3546 | loss_class: 0.3540 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|14:58:40] 	mean_loss1: 0.48609072159225947
[08.22.19|14:58:40] 	mean_loss_class: 0.48546900679937566
[08.22.19|14:58:40] 	mean_loss_recon: 0.0006217145248533438
[08.22.19|14:58:40] Time consumption:
[08.22.19|14:58:40] Done.
[08.22.19|14:58:40] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch37_model1.pt.
[08.22.19|14:58:40] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch37_model2.pt.
[08.22.19|14:58:40] Training epoch: 38
[08.22.19|15:03:17] 	Iter 10100 Done. | loss1: 0.2100 | loss_class: 0.2094 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:08:43] 	Iter 10200 Done. | loss1: 0.4804 | loss_class: 0.4798 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:14:22] 	Iter 10300 Done. | loss1: 0.4263 | loss_class: 0.4257 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:20:00] 	Iter 10400 Done. | loss1: 0.5496 | loss_class: 0.5489 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:25:26] 	Iter 10500 Done. | loss1: 0.8349 | loss_class: 0.8343 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:30:49] 	Iter 10600 Done. | loss1: 0.3824 | loss_class: 0.3819 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|15:36:21] 	Iter 10700 Done. | loss1: 0.4651 | loss_class: 0.4646 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|15:42:01] 	Iter 10800 Done. | loss1: 0.5615 | loss_class: 0.5608 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:47:44] 	Iter 10900 Done. | loss1: 0.3691 | loss_class: 0.3684 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:53:31] 	Iter 11000 Done. | loss1: 0.6166 | loss_class: 0.6160 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|15:59:02] 	Iter 11100 Done. | loss1: 0.2345 | loss_class: 0.2338 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|16:04:36] 	Iter 11200 Done. | loss1: 0.4147 | loss_class: 0.4141 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|16:08:20] 	mean_loss1: 0.4790721988489929
[08.22.19|16:08:20] 	mean_loss_class: 0.47845048226487524
[08.22.19|16:08:20] 	mean_loss_recon: 0.0006217159197246209
[08.22.19|16:08:20] Time consumption:
[08.22.19|16:08:20] Done.
[08.22.19|16:08:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch38_model1.pt.
[08.22.19|16:08:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch38_model2.pt.
[08.22.19|16:08:20] Training epoch: 39
[08.22.19|16:10:10] 	Iter 11300 Done. | loss1: 0.1853 | loss_class: 0.1847 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|16:15:54] 	Iter 11400 Done. | loss1: 0.5572 | loss_class: 0.5566 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|16:21:30] 	Iter 11500 Done. | loss1: 0.4797 | loss_class: 0.4790 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|16:27:12] 	Iter 11600 Done. | loss1: 0.2396 | loss_class: 0.2390 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|16:32:49] 	Iter 11700 Done. | loss1: 0.3113 | loss_class: 0.3106 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|16:38:43] 	Iter 11800 Done. | loss1: 0.7316 | loss_class: 0.7309 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|16:44:14] 	Iter 11900 Done. | loss1: 0.3690 | loss_class: 0.3684 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|16:49:47] 	Iter 12000 Done. | loss1: 0.7947 | loss_class: 0.7941 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|16:55:17] 	Iter 12100 Done. | loss1: 0.5701 | loss_class: 0.5695 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|17:00:42] 	Iter 12200 Done. | loss1: 0.1958 | loss_class: 0.1952 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|17:06:26] 	Iter 12300 Done. | loss1: 0.2486 | loss_class: 0.2480 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|17:12:01] 	Iter 12400 Done. | loss1: 0.5800 | loss_class: 0.5793 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|17:17:42] 	Iter 12500 Done. | loss1: 0.3364 | loss_class: 0.3358 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|17:18:48] 	mean_loss1: 0.4731617910376848
[08.22.19|17:18:48] 	mean_loss_class: 0.4725392105551764
[08.22.19|17:18:48] 	mean_loss_recon: 0.0006225809062155671
[08.22.19|17:18:48] Time consumption:
[08.22.19|17:18:48] Done.
[08.22.19|17:18:49] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch39_model1.pt.
[08.22.19|17:18:49] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch39_model2.pt.
[08.22.19|17:18:49] Eval epoch: 39
[08.22.19|17:42:05] 	Eval_mean_loss1: 0.9032282049861527
[08.22.19|17:42:05] 	Eval_mean_loss_class: 0.9028751054244448
[08.22.19|17:42:05] 	Eval_mean_loss_recon: 0.03531007440905123
[08.22.19|17:42:06] 

[08.22.19|17:42:06] 	Top1: 76.58%
[08.22.19|17:42:06] 

[08.22.19|17:42:06] 	Top5: 94.60%
[08.22.19|17:42:06] Done.
[08.22.19|17:42:06] Training epoch: 40
[08.22.19|17:46:41] 	Iter 12600 Done. | loss1: 0.3148 | loss_class: 0.3142 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|17:52:27] 	Iter 12700 Done. | loss1: 0.2075 | loss_class: 0.2068 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|17:58:09] 	Iter 12800 Done. | loss1: 0.2972 | loss_class: 0.2965 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|18:03:58] 	Iter 12900 Done. | loss1: 0.4940 | loss_class: 0.4933 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|18:09:40] 	Iter 13000 Done. | loss1: 0.4125 | loss_class: 0.4119 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|18:15:14] 	Iter 13100 Done. | loss1: 0.3589 | loss_class: 0.3583 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|18:21:02] 	Iter 13200 Done. | loss1: 0.4253 | loss_class: 0.4247 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|18:26:35] 	Iter 13300 Done. | loss1: 0.3988 | loss_class: 0.3981 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|18:32:00] 	Iter 13400 Done. | loss1: 0.9718 | loss_class: 0.9713 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|18:37:50] 	Iter 13500 Done. | loss1: 0.6164 | loss_class: 0.6157 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|18:43:29] 	Iter 13600 Done. | loss1: 0.5549 | loss_class: 0.5543 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|18:49:07] 	Iter 13700 Done. | loss1: 0.6974 | loss_class: 0.6968 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|18:52:57] 	mean_loss1: 0.4598638504422225
[08.22.19|18:52:57] 	mean_loss_class: 0.4592389563283029
[08.22.19|18:52:57] 	mean_loss_recon: 0.0006248937419261604
[08.22.19|18:52:57] Time consumption:
[08.22.19|18:52:57] Done.
[08.22.19|18:52:57] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch40_model1.pt.
[08.22.19|18:52:57] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch40_model2.pt.
[08.22.19|18:52:57] Training epoch: 41
[08.22.19|18:54:41] 	Iter 13800 Done. | loss1: 0.6752 | loss_class: 0.6746 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|19:00:19] 	Iter 13900 Done. | loss1: 0.3838 | loss_class: 0.3832 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|19:06:02] 	Iter 14000 Done. | loss1: 0.3880 | loss_class: 0.3874 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|19:12:33] 	Iter 14100 Done. | loss1: 0.3548 | loss_class: 0.3541 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|19:18:59] 	Iter 14200 Done. | loss1: 0.3486 | loss_class: 0.3479 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|19:25:28] 	Iter 14300 Done. | loss1: 0.5382 | loss_class: 0.5376 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|19:31:46] 	Iter 14400 Done. | loss1: 0.6538 | loss_class: 0.6531 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|19:37:25] 	Iter 14500 Done. | loss1: 0.3900 | loss_class: 0.3894 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|19:42:44] 	Iter 14600 Done. | loss1: 0.6127 | loss_class: 0.6121 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|19:48:20] 	Iter 14700 Done. | loss1: 0.8564 | loss_class: 0.8558 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|19:53:36] 	Iter 14800 Done. | loss1: 0.2023 | loss_class: 0.2017 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|19:59:21] 	Iter 14900 Done. | loss1: 0.4614 | loss_class: 0.4608 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:04:42] 	Iter 15000 Done. | loss1: 0.5974 | loss_class: 0.5967 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:06:01] 	mean_loss1: 0.4529340574815393
[08.22.19|20:06:01] 	mean_loss_class: 0.45230887931423447
[08.22.19|20:06:01] 	mean_loss_recon: 0.0006251787706114614
[08.22.19|20:06:01] Time consumption:
[08.22.19|20:06:01] Done.
[08.22.19|20:06:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch41_model1.pt.
[08.22.19|20:06:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch41_model2.pt.
[08.22.19|20:06:01] Training epoch: 42
[08.22.19|20:10:16] 	Iter 15100 Done. | loss1: 0.2968 | loss_class: 0.2961 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:15:39] 	Iter 15200 Done. | loss1: 0.5412 | loss_class: 0.5406 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:21:12] 	Iter 15300 Done. | loss1: 0.7389 | loss_class: 0.7383 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:26:51] 	Iter 15400 Done. | loss1: 0.3700 | loss_class: 0.3694 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|20:32:21] 	Iter 15500 Done. | loss1: 0.1753 | loss_class: 0.1746 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|20:37:47] 	Iter 15600 Done. | loss1: 0.3278 | loss_class: 0.3272 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:43:14] 	Iter 15700 Done. | loss1: 0.2447 | loss_class: 0.2440 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|20:48:46] 	Iter 15800 Done. | loss1: 0.4010 | loss_class: 0.4003 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:54:06] 	Iter 15900 Done. | loss1: 0.6185 | loss_class: 0.6179 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|20:59:24] 	Iter 16000 Done. | loss1: 0.1729 | loss_class: 0.1722 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|21:04:33] 	Iter 16100 Done. | loss1: 0.4968 | loss_class: 0.4962 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|21:09:49] 	Iter 16200 Done. | loss1: 0.2451 | loss_class: 0.2445 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|21:13:50] 	mean_loss1: 0.4548776897366721
[08.22.19|21:13:50] 	mean_loss_class: 0.4542520590864431
[08.22.19|21:13:50] 	mean_loss_recon: 0.0006256315805696356
[08.22.19|21:13:50] Time consumption:
[08.22.19|21:13:50] Done.
[08.22.19|21:13:50] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch42_model1.pt.
[08.22.19|21:13:50] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch42_model2.pt.
[08.22.19|21:13:50] Training epoch: 43
[08.22.19|21:15:12] 	Iter 16300 Done. | loss1: 0.5281 | loss_class: 0.5275 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|21:20:25] 	Iter 16400 Done. | loss1: 0.3316 | loss_class: 0.3309 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|21:25:42] 	Iter 16500 Done. | loss1: 0.2680 | loss_class: 0.2673 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|21:31:12] 	Iter 16600 Done. | loss1: 0.1921 | loss_class: 0.1915 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|21:36:34] 	Iter 16700 Done. | loss1: 0.2171 | loss_class: 0.2165 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|21:41:36] 	Iter 16800 Done. | loss1: 0.3930 | loss_class: 0.3923 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|21:46:47] 	Iter 16900 Done. | loss1: 0.6248 | loss_class: 0.6241 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|21:52:00] 	Iter 17000 Done. | loss1: 0.6332 | loss_class: 0.6323 | loss_recon: 0.0008 | lr: 0.100000
[08.22.19|21:57:10] 	Iter 17100 Done. | loss1: 0.1617 | loss_class: 0.1611 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|22:02:28] 	Iter 17200 Done. | loss1: 0.2016 | loss_class: 0.2010 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:07:37] 	Iter 17300 Done. | loss1: 0.2576 | loss_class: 0.2570 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:13:06] 	Iter 17400 Done. | loss1: 0.5771 | loss_class: 0.5766 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|22:18:18] 	Iter 17500 Done. | loss1: 0.3517 | loss_class: 0.3510 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:19:42] 	mean_loss1: 0.45285449177621845
[08.22.19|22:19:42] 	mean_loss_class: 0.4522284810868696
[08.22.19|22:19:42] 	mean_loss_recon: 0.0006260103747224846
[08.22.19|22:19:42] Time consumption:
[08.22.19|22:19:42] Done.
[08.22.19|22:19:42] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch43_model1.pt.
[08.22.19|22:19:42] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch43_model2.pt.
[08.22.19|22:19:42] Training epoch: 44
[08.22.19|22:23:31] 	Iter 17600 Done. | loss1: 0.3210 | loss_class: 0.3204 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:28:41] 	Iter 17700 Done. | loss1: 0.7307 | loss_class: 0.7302 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:33:53] 	Iter 17800 Done. | loss1: 0.8748 | loss_class: 0.8742 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|22:39:02] 	Iter 17900 Done. | loss1: 0.3776 | loss_class: 0.3770 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:44:09] 	Iter 18000 Done. | loss1: 0.3725 | loss_class: 0.3719 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:49:31] 	Iter 18100 Done. | loss1: 0.5727 | loss_class: 0.5721 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|22:54:45] 	Iter 18200 Done. | loss1: 1.0973 | loss_class: 1.0967 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|23:00:05] 	Iter 18300 Done. | loss1: 0.3072 | loss_class: 0.3067 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|23:05:24] 	Iter 18400 Done. | loss1: 0.4373 | loss_class: 0.4367 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|23:10:36] 	Iter 18500 Done. | loss1: 0.1573 | loss_class: 0.1568 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|23:15:52] 	Iter 18600 Done. | loss1: 0.2905 | loss_class: 0.2899 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|23:20:57] 	Iter 18700 Done. | loss1: 0.2842 | loss_class: 0.2836 | loss_recon: 0.0007 | lr: 0.100000
[08.22.19|23:25:04] 	mean_loss1: 0.43712169438386306
[08.22.19|23:25:04] 	mean_loss_class: 0.43649572756486577
[08.22.19|23:25:04] 	mean_loss_recon: 0.0006259666721875103
[08.22.19|23:25:04] Time consumption:
[08.22.19|23:25:04] Done.
[08.22.19|23:25:04] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch44_model1.pt.
[08.22.19|23:25:04] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch44_model2.pt.
[08.22.19|23:25:04] Eval epoch: 44
[08.22.19|23:48:01] 	Eval_mean_loss1: 0.9176857930629753
[08.22.19|23:48:01] 	Eval_mean_loss_class: 0.9173347154097964
[08.22.19|23:48:01] 	Eval_mean_loss_recon: 0.03510775866867729
[08.22.19|23:48:01] 

[08.22.19|23:48:01] 	Top1: 75.68%
[08.22.19|23:48:01] 

[08.22.19|23:48:01] 	Top5: 95.04%
[08.22.19|23:48:01] Done.
[08.22.19|23:48:01] Training epoch: 45
[08.22.19|23:49:10] 	Iter 18800 Done. | loss1: 0.4744 | loss_class: 0.4739 | loss_recon: 0.0005 | lr: 0.100000
[08.22.19|23:54:46] 	Iter 18900 Done. | loss1: 0.7948 | loss_class: 0.7942 | loss_recon: 0.0006 | lr: 0.100000
[08.22.19|23:59:50] 	Iter 19000 Done. | loss1: 0.5653 | loss_class: 0.5647 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:04:51] 	Iter 19100 Done. | loss1: 0.5077 | loss_class: 0.5071 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:10:09] 	Iter 19200 Done. | loss1: 0.4763 | loss_class: 0.4756 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|00:15:30] 	Iter 19300 Done. | loss1: 0.5147 | loss_class: 0.5140 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|00:20:32] 	Iter 19400 Done. | loss1: 0.1150 | loss_class: 0.1144 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:25:49] 	Iter 19500 Done. | loss1: 0.5442 | loss_class: 0.5436 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:31:02] 	Iter 19600 Done. | loss1: 0.3115 | loss_class: 0.3109 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:36:14] 	Iter 19700 Done. | loss1: 0.2192 | loss_class: 0.2185 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:41:23] 	Iter 19800 Done. | loss1: 0.4314 | loss_class: 0.4307 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:46:34] 	Iter 19900 Done. | loss1: 0.4706 | loss_class: 0.4699 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|00:52:38] 	Iter 20000 Done. | loss1: 0.4353 | loss_class: 0.4347 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|00:54:34] 	mean_loss1: 0.43301417006435583
[08.23.19|00:54:34] 	mean_loss_class: 0.4323878695194523
[08.23.19|00:54:34] 	mean_loss_recon: 0.0006263006255685236
[08.23.19|00:54:34] Time consumption:
[08.23.19|00:54:34] Done.
[08.23.19|00:54:35] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch45_model1.pt.
[08.23.19|00:54:35] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch45_model2.pt.
[08.23.19|00:54:35] Training epoch: 46
[08.23.19|00:58:44] 	Iter 20100 Done. | loss1: 0.2839 | loss_class: 0.2833 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:04:57] 	Iter 20200 Done. | loss1: 0.0402 | loss_class: 0.0396 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:10:58] 	Iter 20300 Done. | loss1: 0.1413 | loss_class: 0.1406 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:16:39] 	Iter 20400 Done. | loss1: 0.3043 | loss_class: 0.3037 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:21:46] 	Iter 20500 Done. | loss1: 0.5846 | loss_class: 0.5840 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:27:01] 	Iter 20600 Done. | loss1: 0.4213 | loss_class: 0.4207 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:32:19] 	Iter 20700 Done. | loss1: 0.3831 | loss_class: 0.3825 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:37:33] 	Iter 20800 Done. | loss1: 0.5157 | loss_class: 0.5150 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:42:40] 	Iter 20900 Done. | loss1: 0.2806 | loss_class: 0.2799 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|01:47:50] 	Iter 21000 Done. | loss1: 0.7850 | loss_class: 0.7844 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|01:52:59] 	Iter 21100 Done. | loss1: 0.3258 | loss_class: 0.3252 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|01:58:18] 	Iter 21200 Done. | loss1: 0.3558 | loss_class: 0.3552 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|02:02:56] 	mean_loss1: 0.42839093866963357
[08.23.19|02:02:56] 	mean_loss_class: 0.4277629568256414
[08.23.19|02:02:56] 	mean_loss_recon: 0.0006279822168187403
[08.23.19|02:02:56] Time consumption:
[08.23.19|02:02:56] Done.
[08.23.19|02:02:56] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch46_model1.pt.
[08.23.19|02:02:56] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch46_model2.pt.
[08.23.19|02:02:56] Training epoch: 47
[08.23.19|02:03:55] 	Iter 21300 Done. | loss1: 0.2446 | loss_class: 0.2440 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|02:09:17] 	Iter 21400 Done. | loss1: 0.6456 | loss_class: 0.6450 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|02:14:33] 	Iter 21500 Done. | loss1: 0.2611 | loss_class: 0.2604 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|02:19:56] 	Iter 21600 Done. | loss1: 0.3187 | loss_class: 0.3180 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|02:25:01] 	Iter 21700 Done. | loss1: 0.3991 | loss_class: 0.3984 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|02:30:33] 	Iter 21800 Done. | loss1: 0.3658 | loss_class: 0.3652 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|02:35:54] 	Iter 21900 Done. | loss1: 0.3235 | loss_class: 0.3229 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|02:41:09] 	Iter 22000 Done. | loss1: 0.5480 | loss_class: 0.5474 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|02:46:32] 	Iter 22100 Done. | loss1: 0.2422 | loss_class: 0.2416 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|02:51:47] 	Iter 22200 Done. | loss1: 0.3378 | loss_class: 0.3372 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|02:57:04] 	Iter 22300 Done. | loss1: 0.4828 | loss_class: 0.4821 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:02:25] 	Iter 22400 Done. | loss1: 0.3995 | loss_class: 0.3988 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|03:07:40] 	Iter 22500 Done. | loss1: 0.4542 | loss_class: 0.4536 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:09:39] 	mean_loss1: 0.42370079479778344
[08.23.19|03:09:39] 	mean_loss_class: 0.4230721803209462
[08.23.19|03:09:39] 	mean_loss_recon: 0.0006286146506048239
[08.23.19|03:09:39] Time consumption:
[08.23.19|03:09:39] Done.
[08.23.19|03:09:39] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch47_model1.pt.
[08.23.19|03:09:39] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch47_model2.pt.
[08.23.19|03:09:39] Training epoch: 48
[08.23.19|03:12:57] 	Iter 22600 Done. | loss1: 0.1389 | loss_class: 0.1382 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|03:17:49] 	Iter 22700 Done. | loss1: 0.5475 | loss_class: 0.5469 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:23:00] 	Iter 22800 Done. | loss1: 0.8069 | loss_class: 0.8063 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:28:17] 	Iter 22900 Done. | loss1: 0.5130 | loss_class: 0.5124 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:33:33] 	Iter 23000 Done. | loss1: 0.7364 | loss_class: 0.7358 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:38:50] 	Iter 23100 Done. | loss1: 0.3702 | loss_class: 0.3695 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|03:44:01] 	Iter 23200 Done. | loss1: 0.4049 | loss_class: 0.4043 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:49:02] 	Iter 23300 Done. | loss1: 0.4432 | loss_class: 0.4425 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|03:54:20] 	Iter 23400 Done. | loss1: 0.3555 | loss_class: 0.3548 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|03:59:17] 	Iter 23500 Done. | loss1: 0.5687 | loss_class: 0.5681 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|04:04:22] 	Iter 23600 Done. | loss1: 0.1719 | loss_class: 0.1713 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|04:09:23] 	Iter 23700 Done. | loss1: 0.2304 | loss_class: 0.2298 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|04:13:37] 	mean_loss1: 0.4260772639742722
[08.23.19|04:13:37] 	mean_loss_class: 0.4254479779007907
[08.23.19|04:13:37] 	mean_loss_recon: 0.000629286181729156
[08.23.19|04:13:37] Time consumption:
[08.23.19|04:13:37] Done.
[08.23.19|04:13:37] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch48_model1.pt.
[08.23.19|04:13:37] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch48_model2.pt.
[08.23.19|04:13:37] Training epoch: 49
[08.23.19|04:14:17] 	Iter 23800 Done. | loss1: 0.4738 | loss_class: 0.4732 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|04:19:26] 	Iter 23900 Done. | loss1: 0.2680 | loss_class: 0.2672 | loss_recon: 0.0008 | lr: 0.100000
[08.23.19|04:24:28] 	Iter 24000 Done. | loss1: 0.4606 | loss_class: 0.4600 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|04:29:37] 	Iter 24100 Done. | loss1: 0.5366 | loss_class: 0.5360 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|04:34:34] 	Iter 24200 Done. | loss1: 0.5482 | loss_class: 0.5475 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|04:39:50] 	Iter 24300 Done. | loss1: 0.6035 | loss_class: 0.6028 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|04:44:58] 	Iter 24400 Done. | loss1: 0.3417 | loss_class: 0.3410 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|04:50:02] 	Iter 24500 Done. | loss1: 0.3170 | loss_class: 0.3164 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|04:55:21] 	Iter 24600 Done. | loss1: 0.5653 | loss_class: 0.5647 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|05:00:17] 	Iter 24700 Done. | loss1: 0.5488 | loss_class: 0.5481 | loss_recon: 0.0007 | lr: 0.100000
[08.23.19|05:05:13] 	Iter 24800 Done. | loss1: 0.3975 | loss_class: 0.3968 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|05:10:29] 	Iter 24900 Done. | loss1: 0.6023 | loss_class: 0.6017 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|05:15:42] 	Iter 25000 Done. | loss1: 0.5863 | loss_class: 0.5857 | loss_recon: 0.0006 | lr: 0.100000
[08.23.19|05:17:40] 	mean_loss1: 0.40761511536023487
[08.23.19|05:17:40] 	mean_loss_class: 0.4069855551059825
[08.23.19|05:17:40] 	mean_loss_recon: 0.0006295603704147827
[08.23.19|05:17:40] Time consumption:
[08.23.19|05:17:40] Done.
[08.23.19|05:17:41] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch49_model1.pt.
[08.23.19|05:17:41] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch49_model2.pt.
[08.23.19|05:17:41] Eval epoch: 49
[08.23.19|05:39:52] 	Eval_mean_loss1: 1.0895249555104
[08.23.19|05:39:52] 	Eval_mean_loss_class: 1.0891546955288842
[08.23.19|05:39:52] 	Eval_mean_loss_recon: 0.03702598733307664
[08.23.19|05:39:52] 

[08.23.19|05:39:52] 	Top1: 73.79%
[08.23.19|05:39:52] 

[08.23.19|05:39:52] 	Top5: 92.69%
[08.23.19|05:39:52] Done.
[08.23.19|05:39:52] Training epoch: 50
[08.23.19|05:42:58] 	Iter 25100 Done. | loss1: 0.2915 | loss_class: 0.2909 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|05:48:15] 	Iter 25200 Done. | loss1: 0.2047 | loss_class: 0.2041 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|05:53:28] 	Iter 25300 Done. | loss1: 0.1735 | loss_class: 0.1728 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|05:58:21] 	Iter 25400 Done. | loss1: 0.3400 | loss_class: 0.3395 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|06:03:35] 	Iter 25500 Done. | loss1: 0.1549 | loss_class: 0.1543 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|06:08:49] 	Iter 25600 Done. | loss1: 0.0933 | loss_class: 0.0926 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|06:13:43] 	Iter 25700 Done. | loss1: 0.3057 | loss_class: 0.3051 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|06:18:50] 	Iter 25800 Done. | loss1: 0.3495 | loss_class: 0.3488 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|06:24:43] 	Iter 25900 Done. | loss1: 0.1213 | loss_class: 0.1207 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|06:30:39] 	Iter 26000 Done. | loss1: 0.0998 | loss_class: 0.0992 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|06:36:35] 	Iter 26100 Done. | loss1: 0.1627 | loss_class: 0.1620 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|06:42:34] 	Iter 26200 Done. | loss1: 0.1173 | loss_class: 0.1167 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|06:47:41] 	mean_loss1: 0.21073008578020735
[08.23.19|06:47:41] 	mean_loss_class: 0.21010109278769157
[08.23.19|06:47:41] 	mean_loss_recon: 0.000628993067229851
[08.23.19|06:47:41] Time consumption:
[08.23.19|06:47:41] Done.
[08.23.19|06:47:41] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch50_model1.pt.
[08.23.19|06:47:41] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch50_model2.pt.

[08.23.19|07:50:26] Training epoch: 51
[08.23.19|07:50:42] 	Iter 0 Done. | loss1: 0.1866 | loss_class: 0.1860 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|07:53:36] 	Iter 100 Done. | loss1: 0.2072 | loss_class: 0.2066 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|07:56:31] 	Iter 200 Done. | loss1: 0.1366 | loss_class: 0.1360 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|07:59:31] 	Iter 300 Done. | loss1: 0.1067 | loss_class: 0.1060 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:02:27] 	Iter 400 Done. | loss1: 0.2303 | loss_class: 0.2297 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:05:23] 	Iter 500 Done. | loss1: 0.2341 | loss_class: 0.2334 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:08:16] 	Iter 600 Done. | loss1: 0.1190 | loss_class: 0.1184 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:11:10] 	Iter 700 Done. | loss1: 0.0576 | loss_class: 0.0570 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:14:05] 	Iter 800 Done. | loss1: 0.2970 | loss_class: 0.2963 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:17:01] 	Iter 900 Done. | loss1: 0.0833 | loss_class: 0.0827 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:19:51] 	Iter 1000 Done. | loss1: 0.1189 | loss_class: 0.1183 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:22:44] 	Iter 1100 Done. | loss1: 0.0658 | loss_class: 0.0652 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:25:36] 	Iter 1200 Done. | loss1: 0.2983 | loss_class: 0.2976 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:27:03] 	mean_loss1: 0.16046875633058338
[08.23.19|08:27:03] 	mean_loss_class: 0.15983741375775382
[08.23.19|08:27:03] 	mean_loss_recon: 0.0006313426982159146
[08.23.19|08:27:03] Time consumption:
[08.23.19|08:27:03] Done.
[08.23.19|08:27:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch51_model1.pt.
[08.23.19|08:27:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch51_model2.pt.
[08.23.19|08:27:03] Training epoch: 52
[08.23.19|08:28:29] 	Iter 1300 Done. | loss1: 0.0423 | loss_class: 0.0417 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:31:19] 	Iter 1400 Done. | loss1: 0.0777 | loss_class: 0.0771 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:34:06] 	Iter 1500 Done. | loss1: 0.0727 | loss_class: 0.0721 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:36:57] 	Iter 1600 Done. | loss1: 0.4156 | loss_class: 0.4149 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:39:48] 	Iter 1700 Done. | loss1: 0.2450 | loss_class: 0.2443 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:42:38] 	Iter 1800 Done. | loss1: 0.0369 | loss_class: 0.0362 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:45:25] 	Iter 1900 Done. | loss1: 0.1202 | loss_class: 0.1195 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:48:15] 	Iter 2000 Done. | loss1: 0.2013 | loss_class: 0.2007 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:51:04] 	Iter 2100 Done. | loss1: 0.1367 | loss_class: 0.1360 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:53:55] 	Iter 2200 Done. | loss1: 0.0549 | loss_class: 0.0543 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|08:56:45] 	Iter 2300 Done. | loss1: 0.2179 | loss_class: 0.2172 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|08:59:37] 	Iter 2400 Done. | loss1: 0.1742 | loss_class: 0.1736 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:02:28] 	Iter 2500 Done. | loss1: 0.0704 | loss_class: 0.0698 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:02:33] 	mean_loss1: 0.1414420169751389
[08.23.19|09:02:33] 	mean_loss_class: 0.14080979683980965
[08.23.19|09:02:33] 	mean_loss_recon: 0.0006322204030621738
[08.23.19|09:02:33] Time consumption:
[08.23.19|09:02:33] Done.
[08.23.19|09:02:33] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch52_model1.pt.
[08.23.19|09:02:33] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch52_model2.pt.
[08.23.19|09:02:33] Training epoch: 53
[08.23.19|09:05:23] 	Iter 2600 Done. | loss1: 0.1134 | loss_class: 0.1127 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:08:15] 	Iter 2700 Done. | loss1: 0.2520 | loss_class: 0.2514 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:11:05] 	Iter 2800 Done. | loss1: 0.0525 | loss_class: 0.0519 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:13:54] 	Iter 2900 Done. | loss1: 0.1023 | loss_class: 0.1017 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:16:41] 	Iter 3000 Done. | loss1: 0.1360 | loss_class: 0.1353 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|09:19:30] 	Iter 3100 Done. | loss1: 0.1056 | loss_class: 0.1050 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:22:19] 	Iter 3200 Done. | loss1: 0.0525 | loss_class: 0.0519 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:25:08] 	Iter 3300 Done. | loss1: 0.1922 | loss_class: 0.1916 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:27:57] 	Iter 3400 Done. | loss1: 0.1959 | loss_class: 0.1953 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:30:46] 	Iter 3500 Done. | loss1: 0.1724 | loss_class: 0.1717 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|09:33:35] 	Iter 3600 Done. | loss1: 0.1864 | loss_class: 0.1858 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:36:21] 	Iter 3700 Done. | loss1: 0.1225 | loss_class: 0.1219 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:37:54] 	mean_loss1: 0.12664548680855753
[08.23.19|09:37:54] 	mean_loss_class: 0.12601500640090663
[08.23.19|09:37:54] 	mean_loss_recon: 0.0006304805091739939
[08.23.19|09:37:54] Time consumption:
[08.23.19|09:37:54] Done.
[08.23.19|09:37:54] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch53_model1.pt.
[08.23.19|09:37:54] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch53_model2.pt.
[08.23.19|09:37:54] Training epoch: 54
[08.23.19|09:39:13] 	Iter 3800 Done. | loss1: 0.0982 | loss_class: 0.0975 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|09:41:59] 	Iter 3900 Done. | loss1: 0.1230 | loss_class: 0.1224 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|09:44:50] 	Iter 4000 Done. | loss1: 0.1120 | loss_class: 0.1113 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:47:40] 	Iter 4100 Done. | loss1: 0.1117 | loss_class: 0.1111 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:50:34] 	Iter 4200 Done. | loss1: 0.0204 | loss_class: 0.0198 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:53:30] 	Iter 4300 Done. | loss1: 0.0539 | loss_class: 0.0532 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|09:56:28] 	Iter 4400 Done. | loss1: 0.0736 | loss_class: 0.0730 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|09:59:25] 	Iter 4500 Done. | loss1: 0.1373 | loss_class: 0.1366 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:02:20] 	Iter 4600 Done. | loss1: 0.0661 | loss_class: 0.0655 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:05:17] 	Iter 4700 Done. | loss1: 0.0793 | loss_class: 0.0786 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|10:08:14] 	Iter 4800 Done. | loss1: 0.0913 | loss_class: 0.0906 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:11:06] 	Iter 4900 Done. | loss1: 0.0873 | loss_class: 0.0867 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:14:01] 	Iter 5000 Done. | loss1: 0.1142 | loss_class: 0.1135 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:14:13] 	mean_loss1: 0.11597468118821554
[08.23.19|10:14:13] 	mean_loss_class: 0.11534455049033172
[08.23.19|10:14:13] 	mean_loss_recon: 0.0006301306218456346
[08.23.19|10:14:13] Time consumption:
[08.23.19|10:14:13] Done.
[08.23.19|10:14:13] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch54_model1.pt.
[08.23.19|10:14:13] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch54_model2.pt.
[08.23.19|10:14:13] Eval epoch: 54
[08.23.19|10:24:30] 	Eval_mean_loss1: 0.677062765269201
[08.23.19|10:24:30] 	Eval_mean_loss_class: 0.6766993949810663
[08.23.19|10:24:30] 	Eval_mean_loss_recon: 0.0363369945097397
[08.23.19|10:24:30] 

[08.23.19|10:24:30] 	Top1: 82.88%
[08.23.19|10:24:30] 

[08.23.19|10:24:30] 	Top5: 96.71%
[08.23.19|10:24:30] Done.
[08.23.19|10:24:30] Training epoch: 55
[08.23.19|10:27:15] 	Iter 5100 Done. | loss1: 0.0338 | loss_class: 0.0330 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|10:30:09] 	Iter 5200 Done. | loss1: 0.0236 | loss_class: 0.0229 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|10:33:03] 	Iter 5300 Done. | loss1: 0.1320 | loss_class: 0.1314 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:36:00] 	Iter 5400 Done. | loss1: 0.1928 | loss_class: 0.1922 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|10:38:56] 	Iter 5500 Done. | loss1: 0.4446 | loss_class: 0.4441 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:41:53] 	Iter 5600 Done. | loss1: 0.1129 | loss_class: 0.1123 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:44:50] 	Iter 5700 Done. | loss1: 0.1087 | loss_class: 0.1081 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:47:44] 	Iter 5800 Done. | loss1: 0.1206 | loss_class: 0.1199 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|10:50:38] 	Iter 5900 Done. | loss1: 0.0538 | loss_class: 0.0531 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|10:53:34] 	Iter 6000 Done. | loss1: 0.2031 | loss_class: 0.2025 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:56:32] 	Iter 6100 Done. | loss1: 0.1135 | loss_class: 0.1129 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|10:59:28] 	Iter 6200 Done. | loss1: 0.0310 | loss_class: 0.0303 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|11:01:12] 	mean_loss1: 0.10264617166840456
[08.23.19|11:01:12] 	mean_loss_class: 0.10201528178641019
[08.23.19|11:01:12] 	mean_loss_recon: 0.0006308899712436401
[08.23.19|11:01:12] Time consumption:
[08.23.19|11:01:13] Done.
[08.23.19|11:01:13] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch55_model1.pt.
[08.23.19|11:01:13] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch55_model2.pt.
[08.23.19|11:01:13] Training epoch: 56
[08.23.19|11:02:24] 	Iter 6300 Done. | loss1: 0.0823 | loss_class: 0.0817 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:05:18] 	Iter 6400 Done. | loss1: 0.1039 | loss_class: 0.1032 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:08:14] 	Iter 6500 Done. | loss1: 0.0156 | loss_class: 0.0149 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|11:11:10] 	Iter 6600 Done. | loss1: 0.0970 | loss_class: 0.0964 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:14:06] 	Iter 6700 Done. | loss1: 0.2943 | loss_class: 0.2937 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:17:00] 	Iter 6800 Done. | loss1: 0.0767 | loss_class: 0.0761 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:19:57] 	Iter 6900 Done. | loss1: 0.2177 | loss_class: 0.2171 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:22:54] 	Iter 7000 Done. | loss1: 0.0602 | loss_class: 0.0595 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|11:25:46] 	Iter 7100 Done. | loss1: 0.0280 | loss_class: 0.0274 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:28:46] 	Iter 7200 Done. | loss1: 0.0633 | loss_class: 0.0627 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|11:31:41] 	Iter 7300 Done. | loss1: 0.1436 | loss_class: 0.1430 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:34:38] 	Iter 7400 Done. | loss1: 0.1022 | loss_class: 0.1016 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:37:39] 	Iter 7500 Done. | loss1: 0.0438 | loss_class: 0.0431 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|11:37:58] 	mean_loss1: 0.09715702408886018
[08.23.19|11:37:58] 	mean_loss_class: 0.09652595993238516
[08.23.19|11:37:58] 	mean_loss_recon: 0.0006310643449711343
[08.23.19|11:37:58] Time consumption:
[08.23.19|11:37:58] Done.
[08.23.19|11:37:59] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch56_model1.pt.
[08.23.19|11:37:59] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch56_model2.pt.
[08.23.19|11:37:59] Training epoch: 57
[08.23.19|11:40:41] 	Iter 7600 Done. | loss1: 0.1217 | loss_class: 0.1211 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:43:41] 	Iter 7700 Done. | loss1: 0.1959 | loss_class: 0.1953 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:46:44] 	Iter 7800 Done. | loss1: 0.0577 | loss_class: 0.0571 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:49:43] 	Iter 7900 Done. | loss1: 0.0842 | loss_class: 0.0836 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:52:42] 	Iter 8000 Done. | loss1: 0.0336 | loss_class: 0.0331 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:55:42] 	Iter 8100 Done. | loss1: 0.1246 | loss_class: 0.1241 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|11:58:39] 	Iter 8200 Done. | loss1: 0.1881 | loss_class: 0.1875 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:01:39] 	Iter 8300 Done. | loss1: 0.2583 | loss_class: 0.2577 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|12:04:40] 	Iter 8400 Done. | loss1: 0.0476 | loss_class: 0.0470 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:07:41] 	Iter 8500 Done. | loss1: 0.0801 | loss_class: 0.0795 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:10:42] 	Iter 8600 Done. | loss1: 0.1313 | loss_class: 0.1307 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:13:45] 	Iter 8700 Done. | loss1: 0.0463 | loss_class: 0.0456 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:15:38] 	mean_loss1: 0.08947662060251668
[08.23.19|12:15:38] 	mean_loss_class: 0.08884542547285366
[08.23.19|12:15:38] 	mean_loss_recon: 0.0006311949889975996
[08.23.19|12:15:38] Time consumption:
[08.23.19|12:15:38] Done.
[08.23.19|12:15:38] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch57_model1.pt.
[08.23.19|12:15:38] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch57_model2.pt.
[08.23.19|12:15:38] Training epoch: 58
[08.23.19|12:16:45] 	Iter 8800 Done. | loss1: 0.0674 | loss_class: 0.0668 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:19:46] 	Iter 8900 Done. | loss1: 0.1649 | loss_class: 0.1643 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:22:46] 	Iter 9000 Done. | loss1: 0.0550 | loss_class: 0.0544 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:25:41] 	Iter 9100 Done. | loss1: 0.1382 | loss_class: 0.1375 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:28:37] 	Iter 9200 Done. | loss1: 0.1040 | loss_class: 0.1033 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:31:32] 	Iter 9300 Done. | loss1: 0.1968 | loss_class: 0.1961 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:34:31] 	Iter 9400 Done. | loss1: 0.0232 | loss_class: 0.0226 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:37:35] 	Iter 9500 Done. | loss1: 0.0196 | loss_class: 0.0189 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|12:40:31] 	Iter 9600 Done. | loss1: 0.0379 | loss_class: 0.0372 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|12:43:29] 	Iter 9700 Done. | loss1: 0.0421 | loss_class: 0.0415 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:46:32] 	Iter 9800 Done. | loss1: 0.0851 | loss_class: 0.0843 | loss_recon: 0.0008 | lr: 0.010000
[08.23.19|12:49:34] 	Iter 9900 Done. | loss1: 0.0151 | loss_class: 0.0145 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:52:32] 	Iter 10000 Done. | loss1: 0.0784 | loss_class: 0.0777 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|12:53:01] 	mean_loss1: 0.08023215666972695
[08.23.19|12:53:01] 	mean_loss_class: 0.07960063907594536
[08.23.19|12:53:01] 	mean_loss_recon: 0.0006315175393304696
[08.23.19|12:53:01] Time consumption:
[08.23.19|12:53:01] Done.
[08.23.19|12:53:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch58_model1.pt.
[08.23.19|12:53:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch58_model2.pt.
[08.23.19|12:53:01] Training epoch: 59
[08.23.19|12:55:38] 	Iter 10100 Done. | loss1: 0.0532 | loss_class: 0.0526 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|12:58:38] 	Iter 10200 Done. | loss1: 0.0643 | loss_class: 0.0636 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:01:39] 	Iter 10300 Done. | loss1: 0.0388 | loss_class: 0.0381 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|13:04:38] 	Iter 10400 Done. | loss1: 0.2787 | loss_class: 0.2780 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|13:07:38] 	Iter 10500 Done. | loss1: 0.0309 | loss_class: 0.0304 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:10:44] 	Iter 10600 Done. | loss1: 0.0137 | loss_class: 0.0131 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:13:44] 	Iter 10700 Done. | loss1: 0.0723 | loss_class: 0.0717 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|13:16:45] 	Iter 10800 Done. | loss1: 0.0714 | loss_class: 0.0708 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:19:47] 	Iter 10900 Done. | loss1: 0.1123 | loss_class: 0.1118 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:22:50] 	Iter 11000 Done. | loss1: 0.0783 | loss_class: 0.0777 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:25:56] 	Iter 11100 Done. | loss1: 0.0622 | loss_class: 0.0616 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:29:00] 	Iter 11200 Done. | loss1: 0.0948 | loss_class: 0.0942 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:31:01] 	mean_loss1: 0.0743308609794861
[08.23.19|13:31:01] 	mean_loss_class: 0.07369927483530471
[08.23.19|13:31:01] 	mean_loss_recon: 0.000631586176316483
[08.23.19|13:31:01] Time consumption:
[08.23.19|13:31:01] Done.
[08.23.19|13:31:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch59_model1.pt.
[08.23.19|13:31:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch59_model2.pt.
[08.23.19|13:31:01] Eval epoch: 59
[08.23.19|13:41:06] 	Eval_mean_loss1: 0.6969637448516811
[08.23.19|13:41:06] 	Eval_mean_loss_class: 0.6966150663504305
[08.23.19|13:41:06] 	Eval_mean_loss_recon: 0.03486787561731514
[08.23.19|13:41:06] 

[08.23.19|13:41:06] 	Top1: 83.65%
[08.23.19|13:41:06] 

[08.23.19|13:41:06] 	Top5: 96.74%
[08.23.19|13:41:06] Done.
[08.23.19|13:41:06] Training epoch: 60
[08.23.19|13:42:12] 	Iter 11300 Done. | loss1: 0.0402 | loss_class: 0.0396 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|13:45:14] 	Iter 11400 Done. | loss1: 0.0223 | loss_class: 0.0216 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|13:48:02] 	Iter 11500 Done. | loss1: 0.1407 | loss_class: 0.1401 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:51:00] 	Iter 11600 Done. | loss1: 0.0240 | loss_class: 0.0233 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|13:54:04] 	Iter 11700 Done. | loss1: 0.1671 | loss_class: 0.1664 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:57:00] 	Iter 11800 Done. | loss1: 0.0097 | loss_class: 0.0090 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|13:59:52] 	Iter 11900 Done. | loss1: 0.0370 | loss_class: 0.0364 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:02:41] 	Iter 12000 Done. | loss1: 0.0292 | loss_class: 0.0286 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:05:29] 	Iter 12100 Done. | loss1: 0.0592 | loss_class: 0.0586 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:08:21] 	Iter 12200 Done. | loss1: 0.0652 | loss_class: 0.0646 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:11:07] 	Iter 12300 Done. | loss1: 0.0994 | loss_class: 0.0987 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|14:13:51] 	Iter 12400 Done. | loss1: 0.0347 | loss_class: 0.0341 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:16:37] 	Iter 12500 Done. | loss1: 0.2523 | loss_class: 0.2516 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:17:09] 	mean_loss1: 0.07068319171711732
[08.23.19|14:17:09] 	mean_loss_class: 0.07005322377045696
[08.23.19|14:17:09] 	mean_loss_recon: 0.0006299679627279028
[08.23.19|14:17:09] Time consumption:
[08.23.19|14:17:09] Done.
[08.23.19|14:17:09] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch60_model1.pt.
[08.23.19|14:17:09] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch60_model2.pt.
[08.23.19|14:17:09] Training epoch: 61
[08.23.19|14:19:28] 	Iter 12600 Done. | loss1: 0.0279 | loss_class: 0.0273 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:22:12] 	Iter 12700 Done. | loss1: 0.0978 | loss_class: 0.0972 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:24:59] 	Iter 12800 Done. | loss1: 0.0116 | loss_class: 0.0110 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:27:45] 	Iter 12900 Done. | loss1: 0.0667 | loss_class: 0.0661 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:30:32] 	Iter 13000 Done. | loss1: 0.0643 | loss_class: 0.0637 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:33:29] 	Iter 13100 Done. | loss1: 0.0465 | loss_class: 0.0458 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|14:36:32] 	Iter 13200 Done. | loss1: 0.1043 | loss_class: 0.1037 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:39:39] 	Iter 13300 Done. | loss1: 0.0296 | loss_class: 0.0290 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:42:50] 	Iter 13400 Done. | loss1: 0.0256 | loss_class: 0.0249 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|14:45:53] 	Iter 13500 Done. | loss1: 0.0463 | loss_class: 0.0457 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:48:57] 	Iter 13600 Done. | loss1: 0.0892 | loss_class: 0.0885 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:51:58] 	Iter 13700 Done. | loss1: 0.0182 | loss_class: 0.0176 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|14:54:08] 	mean_loss1: 0.06491955612118865
[08.23.19|14:54:08] 	mean_loss_class: 0.06428893794790624
[08.23.19|14:54:08] 	mean_loss_recon: 0.0006306182323827054
[08.23.19|14:54:08] Time consumption:
[08.23.19|14:54:08] Done.
[08.23.19|14:54:08] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch61_model1.pt.
[08.23.19|14:54:08] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch61_model2.pt.
[08.23.19|14:54:08] Training epoch: 62
[08.23.19|14:55:04] 	Iter 13800 Done. | loss1: 0.0392 | loss_class: 0.0385 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|14:58:07] 	Iter 13900 Done. | loss1: 0.0335 | loss_class: 0.0329 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:01:13] 	Iter 14000 Done. | loss1: 0.0605 | loss_class: 0.0598 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:04:19] 	Iter 14100 Done. | loss1: 0.0222 | loss_class: 0.0215 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:07:17] 	Iter 14200 Done. | loss1: 0.0158 | loss_class: 0.0152 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:10:20] 	Iter 14300 Done. | loss1: 0.0781 | loss_class: 0.0775 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:13:23] 	Iter 14400 Done. | loss1: 0.0649 | loss_class: 0.0643 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:16:28] 	Iter 14500 Done. | loss1: 0.0054 | loss_class: 0.0047 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:19:30] 	Iter 14600 Done. | loss1: 0.1019 | loss_class: 0.1012 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:22:32] 	Iter 14700 Done. | loss1: 0.1245 | loss_class: 0.1239 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:25:36] 	Iter 14800 Done. | loss1: 0.0196 | loss_class: 0.0189 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:28:39] 	Iter 14900 Done. | loss1: 0.0390 | loss_class: 0.0384 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:31:47] 	Iter 15000 Done. | loss1: 0.0915 | loss_class: 0.0909 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:32:31] 	mean_loss1: 0.05859563236062329
[08.23.19|15:32:31] 	mean_loss_class: 0.05796415615862551
[08.23.19|15:32:31] 	mean_loss_recon: 0.0006314762405301341
[08.23.19|15:32:31] Time consumption:
[08.23.19|15:32:31] Done.
[08.23.19|15:32:31] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch62_model1.pt.
[08.23.19|15:32:31] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch62_model2.pt.
[08.23.19|15:32:31] Training epoch: 63
[08.23.19|15:34:51] 	Iter 15100 Done. | loss1: 0.0942 | loss_class: 0.0935 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:37:54] 	Iter 15200 Done. | loss1: 0.0152 | loss_class: 0.0145 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:40:51] 	Iter 15300 Done. | loss1: 0.0278 | loss_class: 0.0271 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:43:55] 	Iter 15400 Done. | loss1: 0.0696 | loss_class: 0.0690 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:47:03] 	Iter 15500 Done. | loss1: 0.0885 | loss_class: 0.0880 | loss_recon: 0.0005 | lr: 0.010000
[08.23.19|15:50:09] 	Iter 15600 Done. | loss1: 0.0089 | loss_class: 0.0082 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:53:11] 	Iter 15700 Done. | loss1: 0.0501 | loss_class: 0.0494 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|15:56:15] 	Iter 15800 Done. | loss1: 0.0341 | loss_class: 0.0335 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|15:59:17] 	Iter 15900 Done. | loss1: 0.0091 | loss_class: 0.0085 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|16:02:17] 	Iter 16000 Done. | loss1: 0.0751 | loss_class: 0.0744 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|16:05:22] 	Iter 16100 Done. | loss1: 0.0239 | loss_class: 0.0232 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|16:08:23] 	Iter 16200 Done. | loss1: 0.0450 | loss_class: 0.0444 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:10:38] 	mean_loss1: 0.05502481320400547
[08.23.19|16:10:38] 	mean_loss_class: 0.05439435006878056
[08.23.19|16:10:38] 	mean_loss_recon: 0.0006304630821648117
[08.23.19|16:10:38] Time consumption:
[08.23.19|16:10:38] Done.
[08.23.19|16:10:38] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch63_model1.pt.
[08.23.19|16:10:38] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch63_model2.pt.
[08.23.19|16:10:38] Training epoch: 64
[08.23.19|16:11:25] 	Iter 16300 Done. | loss1: 0.0216 | loss_class: 0.0210 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:14:31] 	Iter 16400 Done. | loss1: 0.0460 | loss_class: 0.0453 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:17:33] 	Iter 16500 Done. | loss1: 0.0338 | loss_class: 0.0332 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:20:33] 	Iter 16600 Done. | loss1: 0.0119 | loss_class: 0.0113 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:23:29] 	Iter 16700 Done. | loss1: 0.0212 | loss_class: 0.0205 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|16:26:31] 	Iter 16800 Done. | loss1: 0.0547 | loss_class: 0.0541 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:29:34] 	Iter 16900 Done. | loss1: 0.1141 | loss_class: 0.1135 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:32:36] 	Iter 17000 Done. | loss1: 0.0146 | loss_class: 0.0139 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|16:35:41] 	Iter 17100 Done. | loss1: 0.0483 | loss_class: 0.0476 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:38:40] 	Iter 17200 Done. | loss1: 0.0226 | loss_class: 0.0220 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:41:38] 	Iter 17300 Done. | loss1: 0.0887 | loss_class: 0.0881 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:44:41] 	Iter 17400 Done. | loss1: 0.0618 | loss_class: 0.0611 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:47:43] 	Iter 17500 Done. | loss1: 0.0352 | loss_class: 0.0347 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|16:48:32] 	mean_loss1: 0.05261949970633886
[08.23.19|16:48:32] 	mean_loss_class: 0.051990237771369775
[08.23.19|16:48:32] 	mean_loss_recon: 0.000629261890961863
[08.23.19|16:48:32] Time consumption:
[08.23.19|16:48:32] Done.
[08.23.19|16:48:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch64_model1.pt.
[08.23.19|16:48:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch64_model2.pt.
[08.23.19|16:48:32] Eval epoch: 64
[08.23.19|16:58:45] 	Eval_mean_loss1: 0.734617418407412
[08.23.19|16:58:45] 	Eval_mean_loss_class: 0.734247146881828
[08.23.19|16:58:45] 	Eval_mean_loss_recon: 0.03702713013446146
[08.23.19|16:58:45] 

[08.23.19|16:58:45] 	Top1: 82.91%
[08.23.19|16:58:45] 

[08.23.19|16:58:45] 	Top5: 96.45%
[08.23.19|16:58:45] Done.
[08.23.19|16:58:45] Training epoch: 65
[08.23.19|17:01:01] 	Iter 17600 Done. | loss1: 0.0518 | loss_class: 0.0511 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|17:04:04] 	Iter 17700 Done. | loss1: 0.0556 | loss_class: 0.0551 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:07:04] 	Iter 17800 Done. | loss1: 0.0396 | loss_class: 0.0390 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:09:59] 	Iter 17900 Done. | loss1: 0.0231 | loss_class: 0.0225 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:12:51] 	Iter 18000 Done. | loss1: 0.0376 | loss_class: 0.0369 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|17:15:41] 	Iter 18100 Done. | loss1: 0.0183 | loss_class: 0.0177 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:18:32] 	Iter 18200 Done. | loss1: 0.0448 | loss_class: 0.0442 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:21:18] 	Iter 18300 Done. | loss1: 0.0517 | loss_class: 0.0511 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:24:08] 	Iter 18400 Done. | loss1: 0.0263 | loss_class: 0.0256 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|17:26:57] 	Iter 18500 Done. | loss1: 0.0832 | loss_class: 0.0826 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:29:45] 	Iter 18600 Done. | loss1: 0.0619 | loss_class: 0.0613 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|17:32:35] 	Iter 18700 Done. | loss1: 0.0321 | loss_class: 0.0315 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:34:50] 	mean_loss1: 0.04952738362590607
[08.23.19|17:34:50] 	mean_loss_class: 0.04889606365475792
[08.23.19|17:34:50] 	mean_loss_recon: 0.0006313200344066747
[08.23.19|17:34:50] Time consumption:
[08.23.19|17:34:50] Done.
[08.23.19|17:34:50] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch65_model1.pt.
[08.23.19|17:34:50] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch65_model2.pt.
[08.23.19|17:34:50] Training epoch: 66
[08.23.19|17:35:25] 	Iter 18800 Done. | loss1: 0.0525 | loss_class: 0.0519 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:38:14] 	Iter 18900 Done. | loss1: 0.0239 | loss_class: 0.0234 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:41:00] 	Iter 19000 Done. | loss1: 0.0298 | loss_class: 0.0292 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:43:50] 	Iter 19100 Done. | loss1: 0.0810 | loss_class: 0.0804 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:46:39] 	Iter 19200 Done. | loss1: 0.0676 | loss_class: 0.0668 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|17:49:29] 	Iter 19300 Done. | loss1: 0.0538 | loss_class: 0.0531 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|17:52:18] 	Iter 19400 Done. | loss1: 0.0825 | loss_class: 0.0818 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|17:55:08] 	Iter 19500 Done. | loss1: 0.0238 | loss_class: 0.0232 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|17:57:55] 	Iter 19600 Done. | loss1: 0.0091 | loss_class: 0.0085 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:00:46] 	Iter 19700 Done. | loss1: 0.0079 | loss_class: 0.0073 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:03:34] 	Iter 19800 Done. | loss1: 0.0238 | loss_class: 0.0232 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:06:20] 	Iter 19900 Done. | loss1: 0.0108 | loss_class: 0.0102 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:09:16] 	Iter 20000 Done. | loss1: 0.0294 | loss_class: 0.0289 | loss_recon: 0.0005 | lr: 0.010000
[08.23.19|18:10:12] 	mean_loss1: 0.04482914278649698
[08.23.19|18:10:12] 	mean_loss_class: 0.044198469190409005
[08.23.19|18:10:12] 	mean_loss_recon: 0.0006306736664876295
[08.23.19|18:10:12] Time consumption:
[08.23.19|18:10:12] Done.
[08.23.19|18:10:12] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch66_model1.pt.
[08.23.19|18:10:12] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch66_model2.pt.
[08.23.19|18:10:12] Training epoch: 67
[08.23.19|18:12:22] 	Iter 20100 Done. | loss1: 0.0242 | loss_class: 0.0236 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:15:23] 	Iter 20200 Done. | loss1: 0.0814 | loss_class: 0.0808 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:18:23] 	Iter 20300 Done. | loss1: 0.0168 | loss_class: 0.0161 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:21:26] 	Iter 20400 Done. | loss1: 0.0108 | loss_class: 0.0102 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:24:32] 	Iter 20500 Done. | loss1: 0.0630 | loss_class: 0.0624 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:27:32] 	Iter 20600 Done. | loss1: 0.0129 | loss_class: 0.0123 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:30:34] 	Iter 20700 Done. | loss1: 0.0816 | loss_class: 0.0810 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:33:36] 	Iter 20800 Done. | loss1: 0.0499 | loss_class: 0.0492 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:36:41] 	Iter 20900 Done. | loss1: 0.0581 | loss_class: 0.0575 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:39:43] 	Iter 21000 Done. | loss1: 0.0682 | loss_class: 0.0676 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:42:45] 	Iter 21100 Done. | loss1: 0.0404 | loss_class: 0.0397 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:45:46] 	Iter 21200 Done. | loss1: 0.0223 | loss_class: 0.0217 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|18:48:15] 	mean_loss1: 0.04366519666327455
[08.23.19|18:48:15] 	mean_loss_class: 0.043035256774566426
[08.23.19|18:48:15] 	mean_loss_recon: 0.0006299398980213525
[08.23.19|18:48:15] Time consumption:
[08.23.19|18:48:15] Done.
[08.23.19|18:48:15] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch67_model1.pt.
[08.23.19|18:48:15] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch67_model2.pt.
[08.23.19|18:48:15] Training epoch: 68
[08.23.19|18:48:49] 	Iter 21300 Done. | loss1: 0.0085 | loss_class: 0.0078 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:51:46] 	Iter 21400 Done. | loss1: 0.0138 | loss_class: 0.0132 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:54:46] 	Iter 21500 Done. | loss1: 0.0108 | loss_class: 0.0102 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|18:57:43] 	Iter 21600 Done. | loss1: 0.0478 | loss_class: 0.0472 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:00:47] 	Iter 21700 Done. | loss1: 0.0234 | loss_class: 0.0228 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:03:42] 	Iter 21800 Done. | loss1: 0.1079 | loss_class: 0.1072 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|19:06:45] 	Iter 21900 Done. | loss1: 0.1734 | loss_class: 0.1728 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:09:45] 	Iter 22000 Done. | loss1: 0.0710 | loss_class: 0.0704 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:12:51] 	Iter 22100 Done. | loss1: 0.0257 | loss_class: 0.0251 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:15:54] 	Iter 22200 Done. | loss1: 0.0813 | loss_class: 0.0807 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:19:01] 	Iter 22300 Done. | loss1: 0.0130 | loss_class: 0.0124 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:22:06] 	Iter 22400 Done. | loss1: 0.0266 | loss_class: 0.0260 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:25:09] 	Iter 22500 Done. | loss1: 0.0285 | loss_class: 0.0279 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:26:14] 	mean_loss1: 0.04168572952894988
[08.23.19|19:26:14] 	mean_loss_class: 0.041054837298564635
[08.23.19|19:26:14] 	mean_loss_recon: 0.0006308922632790793
[08.23.19|19:26:14] Time consumption:
[08.23.19|19:26:14] Done.
[08.23.19|19:26:14] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch68_model1.pt.
[08.23.19|19:26:14] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch68_model2.pt.
[08.23.19|19:26:14] Training epoch: 69
[08.23.19|19:28:15] 	Iter 22600 Done. | loss1: 0.0140 | loss_class: 0.0134 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:31:24] 	Iter 22700 Done. | loss1: 0.0365 | loss_class: 0.0359 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:34:27] 	Iter 22800 Done. | loss1: 0.0362 | loss_class: 0.0355 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|19:37:29] 	Iter 22900 Done. | loss1: 0.0423 | loss_class: 0.0417 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:40:37] 	Iter 23000 Done. | loss1: 0.0209 | loss_class: 0.0202 | loss_recon: 0.0007 | lr: 0.010000
[08.23.19|19:43:40] 	Iter 23100 Done. | loss1: 0.0719 | loss_class: 0.0713 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:46:47] 	Iter 23200 Done. | loss1: 0.0169 | loss_class: 0.0163 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:49:50] 	Iter 23300 Done. | loss1: 0.0346 | loss_class: 0.0339 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:52:55] 	Iter 23400 Done. | loss1: 0.0294 | loss_class: 0.0287 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:56:00] 	Iter 23500 Done. | loss1: 0.0143 | loss_class: 0.0137 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|19:59:08] 	Iter 23600 Done. | loss1: 0.0069 | loss_class: 0.0063 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|20:02:15] 	Iter 23700 Done. | loss1: 0.0229 | loss_class: 0.0223 | loss_recon: 0.0006 | lr: 0.010000
[08.23.19|20:04:52] 	mean_loss1: 0.04045061824769645
[08.23.19|20:04:52] 	mean_loss_class: 0.03981928764797819
[08.23.19|20:04:52] 	mean_loss_recon: 0.0006313305551680132
[08.23.19|20:04:52] Time consumption:
[08.23.19|20:04:52] Done.
[08.23.19|20:04:52] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch69_model1.pt.
[08.23.19|20:04:52] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch69_model2.pt.
[08.23.19|20:04:52] Eval epoch: 69
[08.23.19|20:15:21] 	Eval_mean_loss1: 0.7307908888761849
[08.23.19|20:15:21] 	Eval_mean_loss_class: 0.7304362745002605
[08.23.19|20:15:21] 	Eval_mean_loss_recon: 0.03546147128971395
[08.23.19|20:15:21] 

[08.23.19|20:15:21] 	Top1: 83.71%
[08.23.19|20:15:21] 

[08.23.19|20:15:21] 	Top5: 96.60%
[08.23.19|20:15:21] Done.
[08.23.19|20:15:21] Training epoch: 70
[08.23.19|20:15:45] 	Iter 23800 Done. | loss1: 0.0468 | loss_class: 0.0460 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|20:18:31] 	Iter 23900 Done. | loss1: 0.0111 | loss_class: 0.0105 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:21:23] 	Iter 24000 Done. | loss1: 0.0328 | loss_class: 0.0322 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:24:10] 	Iter 24100 Done. | loss1: 0.0299 | loss_class: 0.0293 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|20:26:58] 	Iter 24200 Done. | loss1: 0.0077 | loss_class: 0.0071 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:29:48] 	Iter 24300 Done. | loss1: 0.0083 | loss_class: 0.0076 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|20:32:40] 	Iter 24400 Done. | loss1: 0.0329 | loss_class: 0.0323 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:35:46] 	Iter 24500 Done. | loss1: 0.0178 | loss_class: 0.0172 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:38:54] 	Iter 24600 Done. | loss1: 0.0354 | loss_class: 0.0348 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:41:56] 	Iter 24700 Done. | loss1: 0.0194 | loss_class: 0.0188 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:44:57] 	Iter 24800 Done. | loss1: 0.0193 | loss_class: 0.0186 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|20:48:01] 	Iter 24900 Done. | loss1: 0.0273 | loss_class: 0.0266 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|20:51:06] 	Iter 25000 Done. | loss1: 0.0323 | loss_class: 0.0317 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:52:20] 	mean_loss1: 0.028558466404032246
[08.23.19|20:52:20] 	mean_loss_class: 0.027927915407969548
[08.23.19|20:52:20] 	mean_loss_recon: 0.0006305510217187028
[08.23.19|20:52:20] Time consumption:
[08.23.19|20:52:20] Done.
[08.23.19|20:52:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch70_model1.pt.
[08.23.19|20:52:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch70_model2.pt.
[08.23.19|20:52:20] Training epoch: 71
[08.23.19|20:54:13] 	Iter 25100 Done. | loss1: 0.0142 | loss_class: 0.0136 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|20:57:16] 	Iter 25200 Done. | loss1: 0.0289 | loss_class: 0.0283 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:00:21] 	Iter 25300 Done. | loss1: 0.0152 | loss_class: 0.0144 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:03:25] 	Iter 25400 Done. | loss1: 0.0410 | loss_class: 0.0404 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:06:25] 	Iter 25500 Done. | loss1: 0.0078 | loss_class: 0.0071 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:09:27] 	Iter 25600 Done. | loss1: 0.0055 | loss_class: 0.0048 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:12:29] 	Iter 25700 Done. | loss1: 0.0193 | loss_class: 0.0186 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:15:38] 	Iter 25800 Done. | loss1: 0.0325 | loss_class: 0.0319 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:18:43] 	Iter 25900 Done. | loss1: 0.0554 | loss_class: 0.0548 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:21:48] 	Iter 26000 Done. | loss1: 0.0063 | loss_class: 0.0057 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:24:50] 	Iter 26100 Done. | loss1: 0.0054 | loss_class: 0.0047 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:27:52] 	Iter 26200 Done. | loss1: 0.0029 | loss_class: 0.0023 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:30:39] 	mean_loss1: 0.02524346201148735
[08.23.19|21:30:39] 	mean_loss_class: 0.02461262444218698
[08.23.19|21:30:39] 	mean_loss_recon: 0.0006308375897641761
[08.23.19|21:30:39] Time consumption:
[08.23.19|21:30:39] Done.
[08.23.19|21:30:39] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch71_model1.pt.
[08.23.19|21:30:39] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch71_model2.pt.
[08.23.19|21:30:39] Training epoch: 72
[08.23.19|21:30:57] 	Iter 26300 Done. | loss1: 0.0119 | loss_class: 0.0113 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:33:57] 	Iter 26400 Done. | loss1: 0.0071 | loss_class: 0.0066 | loss_recon: 0.0005 | lr: 0.001000
[08.23.19|21:37:01] 	Iter 26500 Done. | loss1: 0.0038 | loss_class: 0.0032 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:40:07] 	Iter 26600 Done. | loss1: 0.0271 | loss_class: 0.0264 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:43:11] 	Iter 26700 Done. | loss1: 0.0318 | loss_class: 0.0311 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:46:12] 	Iter 26800 Done. | loss1: 0.0221 | loss_class: 0.0214 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:49:16] 	Iter 26900 Done. | loss1: 0.0328 | loss_class: 0.0322 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:52:19] 	Iter 27000 Done. | loss1: 0.0181 | loss_class: 0.0174 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|21:55:21] 	Iter 27100 Done. | loss1: 0.0185 | loss_class: 0.0179 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|21:58:27] 	Iter 27200 Done. | loss1: 0.0106 | loss_class: 0.0099 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:01:31] 	Iter 27300 Done. | loss1: 0.0148 | loss_class: 0.0142 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|22:04:36] 	Iter 27400 Done. | loss1: 0.0515 | loss_class: 0.0509 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:07:44] 	Iter 27500 Done. | loss1: 0.0170 | loss_class: 0.0164 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:09:03] 	mean_loss1: 0.02324310881078255
[08.23.19|22:09:03] 	mean_loss_class: 0.02261221753403592
[08.23.19|22:09:03] 	mean_loss_recon: 0.0006308912947928658
[08.23.19|22:09:03] Time consumption:
[08.23.19|22:09:03] Done.
[08.23.19|22:09:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch72_model1.pt.
[08.23.19|22:09:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch72_model2.pt.
[08.23.19|22:09:03] Training epoch: 73
[08.23.19|22:10:50] 	Iter 27600 Done. | loss1: 0.0247 | loss_class: 0.0241 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:13:52] 	Iter 27700 Done. | loss1: 0.0159 | loss_class: 0.0153 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:16:54] 	Iter 27800 Done. | loss1: 0.0189 | loss_class: 0.0183 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:19:57] 	Iter 27900 Done. | loss1: 0.0254 | loss_class: 0.0248 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:22:57] 	Iter 28000 Done. | loss1: 0.0098 | loss_class: 0.0091 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|22:25:58] 	Iter 28100 Done. | loss1: 0.0264 | loss_class: 0.0258 | loss_recon: 0.0005 | lr: 0.001000
[08.23.19|22:29:04] 	Iter 28200 Done. | loss1: 0.0396 | loss_class: 0.0389 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:32:11] 	Iter 28300 Done. | loss1: 0.0147 | loss_class: 0.0141 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:35:16] 	Iter 28400 Done. | loss1: 0.0274 | loss_class: 0.0268 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:38:21] 	Iter 28500 Done. | loss1: 0.0232 | loss_class: 0.0226 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:41:27] 	Iter 28600 Done. | loss1: 0.0152 | loss_class: 0.0145 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|22:44:30] 	Iter 28700 Done. | loss1: 0.0077 | loss_class: 0.0071 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:47:26] 	mean_loss1: 0.022879419651569817
[08.23.19|22:47:26] 	mean_loss_class: 0.02224796212400301
[08.23.19|22:47:26] 	mean_loss_recon: 0.0006314575771530405
[08.23.19|22:47:26] Time consumption:
[08.23.19|22:47:26] Done.
[08.23.19|22:47:26] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch73_model1.pt.
[08.23.19|22:47:26] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch73_model2.pt.
[08.23.19|22:47:26] Training epoch: 74
[08.23.19|22:47:37] 	Iter 28800 Done. | loss1: 0.0077 | loss_class: 0.0071 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:50:40] 	Iter 28900 Done. | loss1: 0.0210 | loss_class: 0.0203 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:53:47] 	Iter 29000 Done. | loss1: 0.0420 | loss_class: 0.0413 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|22:56:54] 	Iter 29100 Done. | loss1: 0.0438 | loss_class: 0.0432 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|22:59:53] 	Iter 29200 Done. | loss1: 0.0105 | loss_class: 0.0098 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|23:02:54] 	Iter 29300 Done. | loss1: 0.0083 | loss_class: 0.0077 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:05:55] 	Iter 29400 Done. | loss1: 0.0361 | loss_class: 0.0354 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|23:08:59] 	Iter 29500 Done. | loss1: 0.0212 | loss_class: 0.0205 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|23:12:00] 	Iter 29600 Done. | loss1: 0.0106 | loss_class: 0.0100 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:15:04] 	Iter 29700 Done. | loss1: 0.0069 | loss_class: 0.0063 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:18:02] 	Iter 29800 Done. | loss1: 0.0075 | loss_class: 0.0068 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|23:21:02] 	Iter 29900 Done. | loss1: 0.0299 | loss_class: 0.0292 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|23:24:03] 	Iter 30000 Done. | loss1: 0.0095 | loss_class: 0.0088 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:25:29] 	mean_loss1: 0.02284676324149903
[08.23.19|23:25:29] 	mean_loss_class: 0.022215845033574027
[08.23.19|23:25:29] 	mean_loss_recon: 0.0006309182560160614
[08.23.19|23:25:29] Time consumption:
[08.23.19|23:25:29] Done.
[08.23.19|23:25:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch74_model1.pt.
[08.23.19|23:25:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch74_model2.pt.
[08.23.19|23:25:30] Eval epoch: 74
[08.23.19|23:35:40] 	Eval_mean_loss1: 0.7317138067338356
[08.23.19|23:35:40] 	Eval_mean_loss_class: 0.7313494940014021
[08.23.19|23:35:40] 	Eval_mean_loss_recon: 0.03643129734582333
[08.23.19|23:35:40] 

[08.23.19|23:35:40] 	Top1: 83.91%
[08.23.19|23:35:40] 

[08.23.19|23:35:40] 	Top5: 96.69%
[08.23.19|23:35:40] Done.
[08.23.19|23:35:40] Training epoch: 75
[08.23.19|23:37:18] 	Iter 30100 Done. | loss1: 0.0105 | loss_class: 0.0098 | loss_recon: 0.0007 | lr: 0.001000
[08.23.19|23:40:24] 	Iter 30200 Done. | loss1: 0.0658 | loss_class: 0.0652 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:43:27] 	Iter 30300 Done. | loss1: 0.0101 | loss_class: 0.0096 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:46:32] 	Iter 30400 Done. | loss1: 0.0145 | loss_class: 0.0139 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:49:39] 	Iter 30500 Done. | loss1: 0.0348 | loss_class: 0.0341 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:52:41] 	Iter 30600 Done. | loss1: 0.0151 | loss_class: 0.0145 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:55:42] 	Iter 30700 Done. | loss1: 0.0257 | loss_class: 0.0251 | loss_recon: 0.0006 | lr: 0.001000
[08.23.19|23:58:44] 	Iter 30800 Done. | loss1: 0.0062 | loss_class: 0.0056 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:01:52] 	Iter 30900 Done. | loss1: 0.0157 | loss_class: 0.0150 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|00:04:56] 	Iter 31000 Done. | loss1: 0.0398 | loss_class: 0.0392 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:08:04] 	Iter 31100 Done. | loss1: 0.0053 | loss_class: 0.0046 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|00:11:03] 	Iter 31200 Done. | loss1: 0.0169 | loss_class: 0.0163 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:14:03] 	mean_loss1: 0.02192756400024072
[08.24.19|00:14:03] 	mean_loss_class: 0.02129686788652842
[08.24.19|00:14:03] 	mean_loss_recon: 0.0006306961264175634
[08.24.19|00:14:03] Time consumption:
[08.24.19|00:14:03] Done.
[08.24.19|00:14:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch75_model1.pt.
[08.24.19|00:14:03] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch75_model2.pt.
[08.24.19|00:14:03] Training epoch: 76
[08.24.19|00:14:20] 	Iter 31300 Done. | loss1: 0.0177 | loss_class: 0.0171 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:17:17] 	Iter 31400 Done. | loss1: 0.0126 | loss_class: 0.0120 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:20:22] 	Iter 31500 Done. | loss1: 0.0136 | loss_class: 0.0129 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|00:23:22] 	Iter 31600 Done. | loss1: 0.0338 | loss_class: 0.0332 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:26:25] 	Iter 31700 Done. | loss1: 0.0352 | loss_class: 0.0346 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:29:26] 	Iter 31800 Done. | loss1: 0.0068 | loss_class: 0.0062 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:32:32] 	Iter 31900 Done. | loss1: 0.0097 | loss_class: 0.0091 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:35:33] 	Iter 32000 Done. | loss1: 0.0494 | loss_class: 0.0487 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|00:38:38] 	Iter 32100 Done. | loss1: 0.0042 | loss_class: 0.0037 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:41:42] 	Iter 32200 Done. | loss1: 0.0257 | loss_class: 0.0251 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:44:46] 	Iter 32300 Done. | loss1: 0.0854 | loss_class: 0.0847 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|00:47:52] 	Iter 32400 Done. | loss1: 0.0092 | loss_class: 0.0086 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:50:57] 	Iter 32500 Done. | loss1: 0.0565 | loss_class: 0.0559 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:52:34] 	mean_loss1: 0.02147257566870824
[08.24.19|00:52:34] 	mean_loss_class: 0.020841502754118876
[08.24.19|00:52:34] 	mean_loss_recon: 0.0006310729369723474
[08.24.19|00:52:34] Time consumption:
[08.24.19|00:52:34] Done.
[08.24.19|00:52:34] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch76_model1.pt.
[08.24.19|00:52:34] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch76_model2.pt.
[08.24.19|00:52:34] Training epoch: 77
[08.24.19|00:54:06] 	Iter 32600 Done. | loss1: 0.0180 | loss_class: 0.0174 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|00:57:08] 	Iter 32700 Done. | loss1: 0.0313 | loss_class: 0.0307 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:00:12] 	Iter 32800 Done. | loss1: 0.0043 | loss_class: 0.0038 | loss_recon: 0.0005 | lr: 0.001000
[08.24.19|01:03:13] 	Iter 32900 Done. | loss1: 0.0128 | loss_class: 0.0122 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:06:13] 	Iter 33000 Done. | loss1: 0.0154 | loss_class: 0.0148 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|01:09:14] 	Iter 33100 Done. | loss1: 0.0124 | loss_class: 0.0117 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|01:12:16] 	Iter 33200 Done. | loss1: 0.0513 | loss_class: 0.0507 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:15:17] 	Iter 33300 Done. | loss1: 0.0347 | loss_class: 0.0341 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:18:23] 	Iter 33400 Done. | loss1: 0.0155 | loss_class: 0.0149 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|01:21:26] 	Iter 33500 Done. | loss1: 0.0232 | loss_class: 0.0226 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:24:28] 	Iter 33600 Done. | loss1: 0.0267 | loss_class: 0.0261 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:27:29] 	Iter 33700 Done. | loss1: 0.0224 | loss_class: 0.0218 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|01:30:37] 	Iter 33800 Done. | loss1: 0.0190 | loss_class: 0.0184 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:30:43] 	mean_loss1: 0.0213499705434759
[08.24.19|01:30:43] 	mean_loss_class: 0.020718303196632062
[08.24.19|01:30:43] 	mean_loss_recon: 0.0006316673566703313
[08.24.19|01:30:43] Time consumption:
[08.24.19|01:30:43] Done.
[08.24.19|01:30:43] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch77_model1.pt.
[08.24.19|01:30:43] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch77_model2.pt.
[08.24.19|01:30:43] Training epoch: 78
[08.24.19|01:33:44] 	Iter 33900 Done. | loss1: 0.0190 | loss_class: 0.0184 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:36:45] 	Iter 34000 Done. | loss1: 0.0083 | loss_class: 0.0077 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:39:48] 	Iter 34100 Done. | loss1: 0.0137 | loss_class: 0.0131 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:42:54] 	Iter 34200 Done. | loss1: 0.0121 | loss_class: 0.0114 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|01:45:58] 	Iter 34300 Done. | loss1: 0.0253 | loss_class: 0.0246 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|01:49:02] 	Iter 34400 Done. | loss1: 0.0362 | loss_class: 0.0356 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:52:08] 	Iter 34500 Done. | loss1: 0.0140 | loss_class: 0.0134 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:55:12] 	Iter 34600 Done. | loss1: 0.0128 | loss_class: 0.0122 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|01:58:22] 	Iter 34700 Done. | loss1: 0.0234 | loss_class: 0.0227 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:01:28] 	Iter 34800 Done. | loss1: 0.0334 | loss_class: 0.0327 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|02:04:37] 	Iter 34900 Done. | loss1: 0.0163 | loss_class: 0.0157 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:07:45] 	Iter 35000 Done. | loss1: 0.0356 | loss_class: 0.0350 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:09:25] 	mean_loss1: 0.021022797460829953
[08.24.19|02:09:25] 	mean_loss_class: 0.020392120759279583
[08.24.19|02:09:25] 	mean_loss_recon: 0.0006306767228621836
[08.24.19|02:09:25] Time consumption:
[08.24.19|02:09:25] Done.
[08.24.19|02:09:25] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch78_model1.pt.
[08.24.19|02:09:25] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch78_model2.pt.
[08.24.19|02:09:25] Training epoch: 79
[08.24.19|02:10:49] 	Iter 35100 Done. | loss1: 0.0807 | loss_class: 0.0800 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|02:13:59] 	Iter 35200 Done. | loss1: 0.0345 | loss_class: 0.0339 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:17:01] 	Iter 35300 Done. | loss1: 0.0235 | loss_class: 0.0229 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:20:05] 	Iter 35400 Done. | loss1: 0.0190 | loss_class: 0.0183 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:23:11] 	Iter 35500 Done. | loss1: 0.0564 | loss_class: 0.0558 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:26:13] 	Iter 35600 Done. | loss1: 0.0082 | loss_class: 0.0076 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:29:19] 	Iter 35700 Done. | loss1: 0.0071 | loss_class: 0.0065 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:32:22] 	Iter 35800 Done. | loss1: 0.0274 | loss_class: 0.0268 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:35:26] 	Iter 35900 Done. | loss1: 0.0272 | loss_class: 0.0265 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:38:29] 	Iter 36000 Done. | loss1: 0.0128 | loss_class: 0.0121 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|02:41:35] 	Iter 36100 Done. | loss1: 0.0197 | loss_class: 0.0191 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|02:44:36] 	Iter 36200 Done. | loss1: 0.0212 | loss_class: 0.0206 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|02:47:42] 	Iter 36300 Done. | loss1: 0.0095 | loss_class: 0.0089 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|02:47:56] 	mean_loss1: 0.020373700543294865
[08.24.19|02:47:56] 	mean_loss_class: 0.019743854310899117
[08.24.19|02:47:56] 	mean_loss_recon: 0.0006298462547564182
[08.24.19|02:47:56] Time consumption:
[08.24.19|02:47:56] Done.
[08.24.19|02:47:56] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch79_model1.pt.
[08.24.19|02:47:56] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch79_model2.pt.
[08.24.19|02:47:56] Eval epoch: 79
[08.24.19|02:58:06] 	Eval_mean_loss1: 0.6993044058886148
[08.24.19|02:58:06] 	Eval_mean_loss_class: 0.6989305790174435
[08.24.19|02:58:06] 	Eval_mean_loss_recon: 0.03738276516051255
[08.24.19|02:58:06] 

[08.24.19|02:58:06] 	Top1: 84.52%
[08.24.19|02:58:07] 

[08.24.19|02:58:07] 	Top5: 96.83%
[08.24.19|02:58:07] Done.
[08.24.19|02:58:07] Training epoch: 80
[08.24.19|03:00:59] 	Iter 36400 Done. | loss1: 0.0527 | loss_class: 0.0521 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:04:02] 	Iter 36500 Done. | loss1: 0.0164 | loss_class: 0.0157 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:07:05] 	Iter 36600 Done. | loss1: 0.0181 | loss_class: 0.0175 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:10:11] 	Iter 36700 Done. | loss1: 0.0497 | loss_class: 0.0489 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|03:13:18] 	Iter 36800 Done. | loss1: 0.0412 | loss_class: 0.0407 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:16:17] 	Iter 36900 Done. | loss1: 0.0215 | loss_class: 0.0208 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|03:19:22] 	Iter 37000 Done. | loss1: 0.0197 | loss_class: 0.0190 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|03:22:29] 	Iter 37100 Done. | loss1: 0.0696 | loss_class: 0.0690 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:25:34] 	Iter 37200 Done. | loss1: 0.0099 | loss_class: 0.0093 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:28:36] 	Iter 37300 Done. | loss1: 0.0159 | loss_class: 0.0154 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:31:40] 	Iter 37400 Done. | loss1: 0.0075 | loss_class: 0.0069 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:34:48] 	Iter 37500 Done. | loss1: 0.0177 | loss_class: 0.0170 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:36:37] 	mean_loss1: 0.020640909345597386
[08.24.19|03:36:37] 	mean_loss_class: 0.020009638616642633
[08.24.19|03:36:37] 	mean_loss_recon: 0.0006312707371819323
[08.24.19|03:36:37] Time consumption:
[08.24.19|03:36:37] Done.
[08.24.19|03:36:37] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch80_model1.pt.
[08.24.19|03:36:37] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch80_model2.pt.
[08.24.19|03:36:37] Training epoch: 81
[08.24.19|03:37:56] 	Iter 37600 Done. | loss1: 0.0315 | loss_class: 0.0309 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:41:01] 	Iter 37700 Done. | loss1: 0.0061 | loss_class: 0.0055 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:44:08] 	Iter 37800 Done. | loss1: 0.0047 | loss_class: 0.0041 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:47:18] 	Iter 37900 Done. | loss1: 0.0222 | loss_class: 0.0216 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:50:21] 	Iter 38000 Done. | loss1: 0.0303 | loss_class: 0.0297 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:53:25] 	Iter 38100 Done. | loss1: 0.0105 | loss_class: 0.0098 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|03:56:32] 	Iter 38200 Done. | loss1: 0.0040 | loss_class: 0.0033 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|03:59:37] 	Iter 38300 Done. | loss1: 0.0160 | loss_class: 0.0153 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|04:02:39] 	Iter 38400 Done. | loss1: 0.0209 | loss_class: 0.0203 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:05:44] 	Iter 38500 Done. | loss1: 0.0086 | loss_class: 0.0079 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|04:08:50] 	Iter 38600 Done. | loss1: 0.0456 | loss_class: 0.0450 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:11:52] 	Iter 38700 Done. | loss1: 0.0151 | loss_class: 0.0145 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:14:57] 	Iter 38800 Done. | loss1: 0.0102 | loss_class: 0.0096 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:15:18] 	mean_loss1: 0.019913272760152378
[08.24.19|04:15:18] 	mean_loss_class: 0.019282423638212032
[08.24.19|04:15:18] 	mean_loss_recon: 0.000630849123376008
[08.24.19|04:15:18] Time consumption:
[08.24.19|04:15:18] Done.
[08.24.19|04:15:18] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch81_model1.pt.
[08.24.19|04:15:18] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch81_model2.pt.
[08.24.19|04:15:18] Training epoch: 82
[08.24.19|04:18:02] 	Iter 38900 Done. | loss1: 0.0365 | loss_class: 0.0358 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:21:07] 	Iter 39000 Done. | loss1: 0.0276 | loss_class: 0.0269 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:24:14] 	Iter 39100 Done. | loss1: 0.0089 | loss_class: 0.0083 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:27:23] 	Iter 39200 Done. | loss1: 0.0136 | loss_class: 0.0129 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|04:30:29] 	Iter 39300 Done. | loss1: 0.0176 | loss_class: 0.0170 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:33:31] 	Iter 39400 Done. | loss1: 0.0077 | loss_class: 0.0071 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:36:34] 	Iter 39500 Done. | loss1: 0.0171 | loss_class: 0.0164 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|04:39:37] 	Iter 39600 Done. | loss1: 0.0166 | loss_class: 0.0159 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|04:42:37] 	Iter 39700 Done. | loss1: 0.0413 | loss_class: 0.0407 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:45:39] 	Iter 39800 Done. | loss1: 0.0045 | loss_class: 0.0039 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:48:43] 	Iter 39900 Done. | loss1: 0.0089 | loss_class: 0.0083 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:51:44] 	Iter 40000 Done. | loss1: 0.0060 | loss_class: 0.0054 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|04:53:40] 	mean_loss1: 0.019778766795976486
[08.24.19|04:53:40] 	mean_loss_class: 0.019148153547471323
[08.24.19|04:53:40] 	mean_loss_recon: 0.000630613271646892
[08.24.19|04:53:40] Time consumption:
[08.24.19|04:53:40] Done.
[08.24.19|04:53:40] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch82_model1.pt.
[08.24.19|04:53:40] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch82_model2.pt.
[08.24.19|04:53:40] Training epoch: 83
[08.24.19|04:54:51] 	Iter 40100 Done. | loss1: 0.0379 | loss_class: 0.0372 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|04:57:53] 	Iter 40200 Done. | loss1: 0.0035 | loss_class: 0.0028 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:00:59] 	Iter 40300 Done. | loss1: 0.0385 | loss_class: 0.0379 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|05:04:05] 	Iter 40400 Done. | loss1: 0.0042 | loss_class: 0.0035 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|05:07:11] 	Iter 40500 Done. | loss1: 0.0169 | loss_class: 0.0162 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|05:10:14] 	Iter 40600 Done. | loss1: 0.0271 | loss_class: 0.0264 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|05:13:16] 	Iter 40700 Done. | loss1: 0.0044 | loss_class: 0.0038 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|05:16:20] 	Iter 40800 Done. | loss1: 0.0410 | loss_class: 0.0404 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:19:28] 	Iter 40900 Done. | loss1: 0.0322 | loss_class: 0.0316 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:22:31] 	Iter 41000 Done. | loss1: 0.0250 | loss_class: 0.0243 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|05:25:33] 	Iter 41100 Done. | loss1: 0.0326 | loss_class: 0.0320 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:28:33] 	Iter 41200 Done. | loss1: 0.0290 | loss_class: 0.0284 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:31:37] 	Iter 41300 Done. | loss1: 0.0062 | loss_class: 0.0055 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|05:32:05] 	mean_loss1: 0.01933175181622614
[08.24.19|05:32:05] 	mean_loss_class: 0.018700586727109197
[08.24.19|05:32:05] 	mean_loss_recon: 0.0006311650702450128
[08.24.19|05:32:05] Time consumption:
[08.24.19|05:32:05] Done.
[08.24.19|05:32:05] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch83_model1.pt.
[08.24.19|05:32:05] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch83_model2.pt.
[08.24.19|05:32:05] Training epoch: 84
[08.24.19|05:34:41] 	Iter 41400 Done. | loss1: 0.0426 | loss_class: 0.0420 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:37:40] 	Iter 41500 Done. | loss1: 0.0139 | loss_class: 0.0133 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:40:44] 	Iter 41600 Done. | loss1: 0.0397 | loss_class: 0.0391 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:43:46] 	Iter 41700 Done. | loss1: 0.0037 | loss_class: 0.0031 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:46:49] 	Iter 41800 Done. | loss1: 0.0089 | loss_class: 0.0083 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:49:58] 	Iter 41900 Done. | loss1: 0.0062 | loss_class: 0.0056 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:53:05] 	Iter 42000 Done. | loss1: 0.0236 | loss_class: 0.0230 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:56:08] 	Iter 42100 Done. | loss1: 0.0138 | loss_class: 0.0133 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|05:59:18] 	Iter 42200 Done. | loss1: 0.0207 | loss_class: 0.0199 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:02:22] 	Iter 42300 Done. | loss1: 0.0642 | loss_class: 0.0636 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:05:23] 	Iter 42400 Done. | loss1: 0.0134 | loss_class: 0.0127 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:08:28] 	Iter 42500 Done. | loss1: 0.0099 | loss_class: 0.0092 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:10:30] 	mean_loss1: 0.019366072722154255
[08.24.19|06:10:30] 	mean_loss_class: 0.01873472673943439
[08.24.19|06:10:30] 	mean_loss_recon: 0.0006313460160749028
[08.24.19|06:10:30] Time consumption:
[08.24.19|06:10:30] Done.
[08.24.19|06:10:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch84_model1.pt.
[08.24.19|06:10:30] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch84_model2.pt.
[08.24.19|06:10:30] Eval epoch: 84
[08.24.19|06:20:56] 	Eval_mean_loss1: 0.7240837022460015
[08.24.19|06:20:56] 	Eval_mean_loss_class: 0.7237057685671562
[08.24.19|06:20:56] 	Eval_mean_loss_recon: 0.03779326674578957
[08.24.19|06:20:56] 

[08.24.19|06:20:56] 	Top1: 84.16%
[08.24.19|06:20:57] 

[08.24.19|06:20:57] 	Top5: 96.83%
[08.24.19|06:20:57] Done.
[08.24.19|06:20:57] Training epoch: 85
[08.24.19|06:21:53] 	Iter 42600 Done. | loss1: 0.0305 | loss_class: 0.0298 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:24:41] 	Iter 42700 Done. | loss1: 0.0101 | loss_class: 0.0094 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:27:33] 	Iter 42800 Done. | loss1: 0.0217 | loss_class: 0.0211 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:30:25] 	Iter 42900 Done. | loss1: 0.0121 | loss_class: 0.0114 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:33:11] 	Iter 43000 Done. | loss1: 0.0072 | loss_class: 0.0065 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:35:57] 	Iter 43100 Done. | loss1: 0.0216 | loss_class: 0.0209 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:38:45] 	Iter 43200 Done. | loss1: 0.0185 | loss_class: 0.0178 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:41:35] 	Iter 43300 Done. | loss1: 0.0296 | loss_class: 0.0290 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:44:34] 	Iter 43400 Done. | loss1: 0.0070 | loss_class: 0.0064 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:47:38] 	Iter 43500 Done. | loss1: 0.0210 | loss_class: 0.0203 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:50:46] 	Iter 43600 Done. | loss1: 0.0059 | loss_class: 0.0053 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|06:53:49] 	Iter 43700 Done. | loss1: 0.0111 | loss_class: 0.0105 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:56:52] 	Iter 43800 Done. | loss1: 0.0076 | loss_class: 0.0069 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|06:57:28] 	mean_loss1: 0.019676676034345662
[08.24.19|06:57:28] 	mean_loss_class: 0.019046335144878957
[08.24.19|06:57:28] 	mean_loss_recon: 0.0006303409096627189
[08.24.19|06:57:28] Time consumption:
[08.24.19|06:57:28] Done.
[08.24.19|06:57:28] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch85_model1.pt.
[08.24.19|06:57:28] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch85_model2.pt.
[08.24.19|06:57:28] Training epoch: 86
[08.24.19|07:00:04] 	Iter 43900 Done. | loss1: 0.0059 | loss_class: 0.0052 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:03:11] 	Iter 44000 Done. | loss1: 0.0386 | loss_class: 0.0380 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:06:14] 	Iter 44100 Done. | loss1: 0.0378 | loss_class: 0.0372 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:09:25] 	Iter 44200 Done. | loss1: 0.0363 | loss_class: 0.0357 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:12:30] 	Iter 44300 Done. | loss1: 0.0456 | loss_class: 0.0449 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|07:15:41] 	Iter 44400 Done. | loss1: 0.0056 | loss_class: 0.0050 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:18:44] 	Iter 44500 Done. | loss1: 0.0299 | loss_class: 0.0293 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:21:47] 	Iter 44600 Done. | loss1: 0.0082 | loss_class: 0.0076 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:24:55] 	Iter 44700 Done. | loss1: 0.0184 | loss_class: 0.0177 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|07:27:57] 	Iter 44800 Done. | loss1: 0.0131 | loss_class: 0.0124 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|07:31:00] 	Iter 44900 Done. | loss1: 0.0114 | loss_class: 0.0108 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|07:34:05] 	Iter 45000 Done. | loss1: 0.0125 | loss_class: 0.0118 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|07:36:16] 	mean_loss1: 0.018565642515594623
[08.24.19|07:36:16] 	mean_loss_class: 0.017934853990618792
[08.24.19|07:36:16] 	mean_loss_recon: 0.000630788541497133
[08.24.19|07:36:16] Time consumption:
[08.24.19|07:36:16] Done.
[08.24.19|07:36:16] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch86_model1.pt.
[08.24.19|07:36:16] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch86_model2.pt.

[08.24.19|13:19:45] Training epoch: 87
[08.24.19|13:20:02] 	Iter 0 Done. | loss1: 0.0137 | loss_class: 0.0131 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|13:22:58] 	Iter 100 Done. | loss1: 0.0044 | loss_class: 0.0038 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|13:27:41] 	Iter 200 Done. | loss1: 0.0094 | loss_class: 0.0087 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|13:33:19] 	Iter 300 Done. | loss1: 0.0184 | loss_class: 0.0178 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|13:38:47] 	Iter 400 Done. | loss1: 0.0109 | loss_class: 0.0104 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|13:44:14] 	Iter 500 Done. | loss1: 0.0026 | loss_class: 0.0020 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|13:49:38] 	Iter 600 Done. | loss1: 0.0080 | loss_class: 0.0074 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|13:55:18] 	Iter 700 Done. | loss1: 0.0118 | loss_class: 0.0112 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:01:00] 	Iter 800 Done. | loss1: 0.1027 | loss_class: 0.1020 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:06:27] 	Iter 900 Done. | loss1: 0.0116 | loss_class: 0.0110 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:12:00] 	Iter 1000 Done. | loss1: 0.0200 | loss_class: 0.0194 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|14:17:37] 	Iter 1100 Done. | loss1: 0.0127 | loss_class: 0.0121 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:23:09] 	Iter 1200 Done. | loss1: 0.0333 | loss_class: 0.0326 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|14:25:56] 	mean_loss1: 0.018808909991648963
[08.24.19|14:25:56] 	mean_loss_class: 0.018178675996181302
[08.24.19|14:25:56] 	mean_loss_recon: 0.00063023404006998
[08.24.19|14:25:56] Time consumption:
[08.24.19|14:25:56] Done.
[08.24.19|14:25:56] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch87_model1.pt.
[08.24.19|14:25:56] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch87_model2.pt.
[08.24.19|14:25:56] Training epoch: 88
[08.24.19|14:28:41] 	Iter 1300 Done. | loss1: 0.0048 | loss_class: 0.0042 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:34:13] 	Iter 1400 Done. | loss1: 0.0098 | loss_class: 0.0092 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:39:43] 	Iter 1500 Done. | loss1: 0.0039 | loss_class: 0.0033 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:45:04] 	Iter 1600 Done. | loss1: 0.0062 | loss_class: 0.0056 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:50:26] 	Iter 1700 Done. | loss1: 0.0113 | loss_class: 0.0107 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|14:55:38] 	Iter 1800 Done. | loss1: 0.0123 | loss_class: 0.0117 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|15:01:09] 	Iter 1900 Done. | loss1: 0.0188 | loss_class: 0.0181 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|15:06:28] 	Iter 2000 Done. | loss1: 0.0106 | loss_class: 0.0100 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|15:11:53] 	Iter 2100 Done. | loss1: 0.0715 | loss_class: 0.0710 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|15:17:29] 	Iter 2200 Done. | loss1: 0.0174 | loss_class: 0.0167 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|15:22:58] 	Iter 2300 Done. | loss1: 0.0088 | loss_class: 0.0081 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|15:28:20] 	Iter 2400 Done. | loss1: 0.0120 | loss_class: 0.0114 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|15:33:52] 	Iter 2500 Done. | loss1: 0.0089 | loss_class: 0.0083 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|15:34:01] 	mean_loss1: 0.017640083978311887
[08.24.19|15:34:01] 	mean_loss_class: 0.017008170229605973
[08.24.19|15:34:01] 	mean_loss_recon: 0.0006319137694486699
[08.24.19|15:34:01] Time consumption:
[08.24.19|15:34:01] Done.
[08.24.19|15:34:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch88_model1.pt.
[08.24.19|15:34:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch88_model2.pt.
[08.24.19|15:34:01] Training epoch: 89
[08.24.19|15:39:25] 	Iter 2600 Done. | loss1: 0.0160 | loss_class: 0.0154 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|15:44:44] 	Iter 2700 Done. | loss1: 0.0228 | loss_class: 0.0222 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|15:49:55] 	Iter 2800 Done. | loss1: 0.0034 | loss_class: 0.0027 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|15:55:12] 	Iter 2900 Done. | loss1: 0.0035 | loss_class: 0.0029 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|16:00:37] 	Iter 3000 Done. | loss1: 0.0061 | loss_class: 0.0055 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|16:05:50] 	Iter 3100 Done. | loss1: 0.0094 | loss_class: 0.0088 | loss_recon: 0.0005 | lr: 0.001000
[08.24.19|16:11:12] 	Iter 3200 Done. | loss1: 0.0100 | loss_class: 0.0094 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|16:16:32] 	Iter 3300 Done. | loss1: 0.0483 | loss_class: 0.0477 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|16:21:47] 	Iter 3400 Done. | loss1: 0.0055 | loss_class: 0.0048 | loss_recon: 0.0007 | lr: 0.001000
[08.24.19|16:27:21] 	Iter 3500 Done. | loss1: 0.0064 | loss_class: 0.0059 | loss_recon: 0.0005 | lr: 0.001000
[08.24.19|16:32:45] 	Iter 3600 Done. | loss1: 0.0338 | loss_class: 0.0332 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|16:38:09] 	Iter 3700 Done. | loss1: 0.0081 | loss_class: 0.0075 | loss_recon: 0.0006 | lr: 0.001000
[08.24.19|16:41:00] 	mean_loss1: 0.018477063332967007
[08.24.19|16:41:00] 	mean_loss_class: 0.01784624095065906
[08.24.19|16:41:00] 	mean_loss_recon: 0.0006308223961141353
[08.24.19|16:41:00] Time consumption:
[08.24.19|16:41:00] Done.
[08.24.19|16:41:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch89_model1.pt.
[08.24.19|16:41:01] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch89_model2.pt.
[08.24.19|16:41:01] Eval epoch: 89
[08.24.19|17:03:54] 	Eval_mean_loss1: 0.764529374695217
[08.24.19|17:03:54] 	Eval_mean_loss_class: 0.7641435918549813
[08.24.19|17:03:54] 	Eval_mean_loss_recon: 0.03857825961426016
[08.24.19|17:03:54] 

[08.24.19|17:03:54] 	Top1: 83.60%
[08.24.19|17:03:54] 

[08.24.19|17:03:54] 	Top5: 96.60%
[08.24.19|17:03:54] Done.
[08.24.19|17:03:54] Training epoch: 90
[08.24.19|17:06:29] 	Iter 3800 Done. | loss1: 0.0066 | loss_class: 0.0060 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|17:11:57] 	Iter 3900 Done. | loss1: 0.0207 | loss_class: 0.0200 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|17:17:02] 	Iter 4000 Done. | loss1: 0.0241 | loss_class: 0.0234 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|17:22:07] 	Iter 4100 Done. | loss1: 0.0235 | loss_class: 0.0229 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|17:27:36] 	Iter 4200 Done. | loss1: 0.0054 | loss_class: 0.0048 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|17:33:09] 	Iter 4300 Done. | loss1: 0.0037 | loss_class: 0.0030 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|17:38:22] 	Iter 4400 Done. | loss1: 0.0085 | loss_class: 0.0079 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|17:43:36] 	Iter 4500 Done. | loss1: 0.0987 | loss_class: 0.0981 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|17:48:56] 	Iter 4600 Done. | loss1: 0.0272 | loss_class: 0.0266 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|17:54:17] 	Iter 4700 Done. | loss1: 0.0196 | loss_class: 0.0190 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|17:59:35] 	Iter 4800 Done. | loss1: 0.0069 | loss_class: 0.0061 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|18:04:29] 	Iter 4900 Done. | loss1: 0.0359 | loss_class: 0.0352 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|18:09:28] 	Iter 5000 Done. | loss1: 0.0127 | loss_class: 0.0121 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|18:09:48] 	mean_loss1: 0.01793436868991792
[08.24.19|18:09:48] 	mean_loss_class: 0.017304639096934193
[08.24.19|18:09:48] 	mean_loss_recon: 0.0006297296069907591
[08.24.19|18:09:48] Time consumption:
[08.24.19|18:09:48] Done.
[08.24.19|18:09:49] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch90_model1.pt.
[08.24.19|18:09:49] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch90_model2.pt.
[08.24.19|18:09:49] Training epoch: 91
[08.24.19|18:14:52] 	Iter 5100 Done. | loss1: 0.0069 | loss_class: 0.0063 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|18:19:50] 	Iter 5200 Done. | loss1: 0.0200 | loss_class: 0.0192 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|18:24:52] 	Iter 5300 Done. | loss1: 0.0127 | loss_class: 0.0121 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|18:29:50] 	Iter 5400 Done. | loss1: 0.0147 | loss_class: 0.0140 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|18:34:40] 	Iter 5500 Done. | loss1: 0.0089 | loss_class: 0.0083 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|18:39:45] 	Iter 5600 Done. | loss1: 0.0100 | loss_class: 0.0094 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|18:45:16] 	Iter 5700 Done. | loss1: 0.0161 | loss_class: 0.0155 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|18:50:44] 	Iter 5800 Done. | loss1: 0.0111 | loss_class: 0.0105 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|18:56:04] 	Iter 5900 Done. | loss1: 0.0044 | loss_class: 0.0038 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|19:01:16] 	Iter 6000 Done. | loss1: 0.0127 | loss_class: 0.0121 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:05:58] 	Iter 6100 Done. | loss1: 0.0076 | loss_class: 0.0070 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:10:47] 	Iter 6200 Done. | loss1: 0.0195 | loss_class: 0.0188 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|19:13:25] 	mean_loss1: 0.01775048834237511
[08.24.19|19:13:25] 	mean_loss_class: 0.017119636050999736
[08.24.19|19:13:25] 	mean_loss_recon: 0.0006308523024292515
[08.24.19|19:13:25] Time consumption:
[08.24.19|19:13:25] Done.
[08.24.19|19:13:25] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch91_model1.pt.
[08.24.19|19:13:25] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch91_model2.pt.
[08.24.19|19:13:25] Training epoch: 92
[08.24.19|19:15:23] 	Iter 6300 Done. | loss1: 0.0070 | loss_class: 0.0064 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|19:20:15] 	Iter 6400 Done. | loss1: 0.0162 | loss_class: 0.0156 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:25:05] 	Iter 6500 Done. | loss1: 0.0047 | loss_class: 0.0041 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:30:05] 	Iter 6600 Done. | loss1: 0.0157 | loss_class: 0.0150 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|19:35:05] 	Iter 6700 Done. | loss1: 0.0103 | loss_class: 0.0097 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:39:52] 	Iter 6800 Done. | loss1: 0.0042 | loss_class: 0.0035 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|19:44:48] 	Iter 6900 Done. | loss1: 0.0063 | loss_class: 0.0057 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:49:38] 	Iter 7000 Done. | loss1: 0.0157 | loss_class: 0.0151 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:54:38] 	Iter 7100 Done. | loss1: 0.0324 | loss_class: 0.0317 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|19:59:24] 	Iter 7200 Done. | loss1: 0.0107 | loss_class: 0.0102 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:04:24] 	Iter 7300 Done. | loss1: 0.0188 | loss_class: 0.0182 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:09:19] 	Iter 7400 Done. | loss1: 0.0187 | loss_class: 0.0181 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|20:14:19] 	Iter 7500 Done. | loss1: 0.0085 | loss_class: 0.0079 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:14:53] 	mean_loss1: 0.018572237546601818
[08.24.19|20:14:53] 	mean_loss_class: 0.01794120937157363
[08.24.19|20:14:53] 	mean_loss_recon: 0.0006310282098635221
[08.24.19|20:14:53] Time consumption:
[08.24.19|20:14:53] Done.
[08.24.19|20:14:53] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch92_model1.pt.
[08.24.19|20:14:53] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch92_model2.pt.
[08.24.19|20:14:53] Training epoch: 93
[08.24.19|20:19:14] 	Iter 7600 Done. | loss1: 0.0052 | loss_class: 0.0045 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|20:24:08] 	Iter 7700 Done. | loss1: 0.0088 | loss_class: 0.0081 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|20:29:05] 	Iter 7800 Done. | loss1: 0.0221 | loss_class: 0.0215 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:33:56] 	Iter 7900 Done. | loss1: 0.0128 | loss_class: 0.0123 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:38:49] 	Iter 8000 Done. | loss1: 0.0322 | loss_class: 0.0316 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:43:34] 	Iter 8100 Done. | loss1: 0.0077 | loss_class: 0.0071 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:48:25] 	Iter 8200 Done. | loss1: 0.0148 | loss_class: 0.0143 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:53:28] 	Iter 8300 Done. | loss1: 0.0225 | loss_class: 0.0219 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|20:58:14] 	Iter 8400 Done. | loss1: 0.0154 | loss_class: 0.0147 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|21:03:09] 	Iter 8500 Done. | loss1: 0.0197 | loss_class: 0.0191 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:08:02] 	Iter 8600 Done. | loss1: 0.0087 | loss_class: 0.0081 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:12:49] 	Iter 8700 Done. | loss1: 0.0149 | loss_class: 0.0143 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:15:44] 	mean_loss1: 0.01849418302057698
[08.24.19|21:15:44] 	mean_loss_class: 0.017862407704845023
[08.24.19|21:15:44] 	mean_loss_recon: 0.0006317753387621035
[08.24.19|21:15:44] Time consumption:
[08.24.19|21:15:44] Done.
[08.24.19|21:15:44] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch93_model1.pt.
[08.24.19|21:15:44] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch93_model2.pt.
[08.24.19|21:15:44] Training epoch: 94
[08.24.19|21:17:35] 	Iter 8800 Done. | loss1: 0.0215 | loss_class: 0.0209 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:22:31] 	Iter 8900 Done. | loss1: 0.0244 | loss_class: 0.0238 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:27:37] 	Iter 9000 Done. | loss1: 0.0049 | loss_class: 0.0043 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:32:40] 	Iter 9100 Done. | loss1: 0.0063 | loss_class: 0.0057 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:37:18] 	Iter 9200 Done. | loss1: 0.0173 | loss_class: 0.0166 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|21:42:15] 	Iter 9300 Done. | loss1: 0.0032 | loss_class: 0.0026 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:47:06] 	Iter 9400 Done. | loss1: 0.0209 | loss_class: 0.0203 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|21:52:04] 	Iter 9500 Done. | loss1: 0.0162 | loss_class: 0.0155 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|21:57:06] 	Iter 9600 Done. | loss1: 0.0071 | loss_class: 0.0065 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|22:01:52] 	Iter 9700 Done. | loss1: 0.0115 | loss_class: 0.0108 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|22:06:27] 	Iter 9800 Done. | loss1: 0.0292 | loss_class: 0.0286 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|22:11:21] 	Iter 9900 Done. | loss1: 0.0049 | loss_class: 0.0042 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|22:16:09] 	Iter 10000 Done. | loss1: 0.0213 | loss_class: 0.0206 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|22:16:52] 	mean_loss1: 0.01803515387417082
[08.24.19|22:16:52] 	mean_loss_class: 0.0174053883412109
[08.24.19|22:16:52] 	mean_loss_recon: 0.0006297655552090071
[08.24.19|22:16:52] Time consumption:
[08.24.19|22:16:52] Done.
[08.24.19|22:16:52] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch94_model1.pt.
[08.24.19|22:16:52] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch94_model2.pt.
[08.24.19|22:16:52] Eval epoch: 94
[08.24.19|22:36:29] 	Eval_mean_loss1: 0.754505624889952
[08.24.19|22:36:29] 	Eval_mean_loss_class: 0.7541238541007331
[08.24.19|22:36:29] 	Eval_mean_loss_recon: 0.03817705210846986
[08.24.19|22:36:29] 

[08.24.19|22:36:29] 	Top1: 83.81%
[08.24.19|22:36:29] 

[08.24.19|22:36:29] 	Top5: 96.72%
[08.24.19|22:36:29] Done.
[08.24.19|22:36:29] Training epoch: 95
[08.24.19|22:40:31] 	Iter 10100 Done. | loss1: 0.0166 | loss_class: 0.0159 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|22:44:54] 	Iter 10200 Done. | loss1: 0.0155 | loss_class: 0.0149 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|22:49:31] 	Iter 10300 Done. | loss1: 0.0096 | loss_class: 0.0090 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|22:54:11] 	Iter 10400 Done. | loss1: 0.0203 | loss_class: 0.0196 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|22:58:56] 	Iter 10500 Done. | loss1: 0.0254 | loss_class: 0.0248 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:03:51] 	Iter 10600 Done. | loss1: 0.0153 | loss_class: 0.0147 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:08:26] 	Iter 10700 Done. | loss1: 0.0216 | loss_class: 0.0209 | loss_recon: 0.0007 | lr: 0.000100
[08.24.19|23:13:05] 	Iter 10800 Done. | loss1: 0.0208 | loss_class: 0.0202 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:17:48] 	Iter 10900 Done. | loss1: 0.0154 | loss_class: 0.0148 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:22:26] 	Iter 11000 Done. | loss1: 0.0111 | loss_class: 0.0106 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:27:20] 	Iter 11100 Done. | loss1: 0.0226 | loss_class: 0.0220 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:32:04] 	Iter 11200 Done. | loss1: 0.0093 | loss_class: 0.0087 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:35:19] 	mean_loss1: 0.017904290884618645
[08.24.19|23:35:19] 	mean_loss_class: 0.01727201173099847
[08.24.19|23:35:19] 	mean_loss_recon: 0.0006322791432432187
[08.24.19|23:35:19] Time consumption:
[08.24.19|23:35:19] Done.
[08.24.19|23:35:19] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch95_model1.pt.
[08.24.19|23:35:19] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch95_model2.pt.
[08.24.19|23:35:19] Training epoch: 96
[08.24.19|23:36:51] 	Iter 11300 Done. | loss1: 0.0352 | loss_class: 0.0346 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:41:37] 	Iter 11400 Done. | loss1: 0.0302 | loss_class: 0.0296 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:46:35] 	Iter 11500 Done. | loss1: 0.0103 | loss_class: 0.0097 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:51:57] 	Iter 11600 Done. | loss1: 0.0112 | loss_class: 0.0106 | loss_recon: 0.0006 | lr: 0.000100
[08.24.19|23:57:17] 	Iter 11700 Done. | loss1: 0.0443 | loss_class: 0.0436 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|00:02:34] 	Iter 11800 Done. | loss1: 0.0314 | loss_class: 0.0309 | loss_recon: 0.0005 | lr: 0.000100
[08.25.19|00:07:39] 	Iter 11900 Done. | loss1: 0.0124 | loss_class: 0.0118 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|00:12:18] 	Iter 12000 Done. | loss1: 0.0100 | loss_class: 0.0093 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|00:16:50] 	Iter 12100 Done. | loss1: 0.0206 | loss_class: 0.0200 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|00:21:35] 	Iter 12200 Done. | loss1: 0.0039 | loss_class: 0.0032 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|00:26:06] 	Iter 12300 Done. | loss1: 0.0194 | loss_class: 0.0186 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|00:30:46] 	Iter 12400 Done. | loss1: 0.0158 | loss_class: 0.0151 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|00:35:35] 	Iter 12500 Done. | loss1: 0.0315 | loss_class: 0.0308 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|00:36:32] 	mean_loss1: 0.01756594943261286
[08.25.19|00:36:32] 	mean_loss_class: 0.016934679517635522
[08.25.19|00:36:32] 	mean_loss_recon: 0.0006312699146425952
[08.25.19|00:36:32] Time consumption:
[08.25.19|00:36:32] Done.
[08.25.19|00:36:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch96_model1.pt.
[08.25.19|00:36:32] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch96_model2.pt.
[08.25.19|00:36:32] Training epoch: 97
[08.25.19|00:40:24] 	Iter 12600 Done. | loss1: 0.0056 | loss_class: 0.0050 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|00:45:04] 	Iter 12700 Done. | loss1: 0.0074 | loss_class: 0.0067 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|00:49:57] 	Iter 12800 Done. | loss1: 0.0088 | loss_class: 0.0083 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|00:54:39] 	Iter 12900 Done. | loss1: 0.0082 | loss_class: 0.0075 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|00:59:34] 	Iter 13000 Done. | loss1: 0.0163 | loss_class: 0.0156 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|01:04:25] 	Iter 13100 Done. | loss1: 0.0398 | loss_class: 0.0392 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:09:05] 	Iter 13200 Done. | loss1: 0.0177 | loss_class: 0.0171 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:13:49] 	Iter 13300 Done. | loss1: 0.0279 | loss_class: 0.0272 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:18:41] 	Iter 13400 Done. | loss1: 0.0360 | loss_class: 0.0354 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:23:29] 	Iter 13500 Done. | loss1: 0.0222 | loss_class: 0.0216 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:28:06] 	Iter 13600 Done. | loss1: 0.0528 | loss_class: 0.0522 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:32:49] 	Iter 13700 Done. | loss1: 0.0061 | loss_class: 0.0055 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:36:20] 	mean_loss1: 0.017897379824879784
[08.25.19|01:36:20] 	mean_loss_class: 0.01726558684302976
[08.25.19|01:36:20] 	mean_loss_recon: 0.0006317929968166465
[08.25.19|01:36:20] Time consumption:
[08.25.19|01:36:20] Done.
[08.25.19|01:36:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch97_model1.pt.
[08.25.19|01:36:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch97_model2.pt.
[08.25.19|01:36:20] Training epoch: 98
[08.25.19|01:37:48] 	Iter 13800 Done. | loss1: 0.0139 | loss_class: 0.0134 | loss_recon: 0.0005 | lr: 0.000100
[08.25.19|01:42:37] 	Iter 13900 Done. | loss1: 0.0166 | loss_class: 0.0160 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:47:23] 	Iter 14000 Done. | loss1: 0.0067 | loss_class: 0.0060 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|01:52:05] 	Iter 14100 Done. | loss1: 0.0104 | loss_class: 0.0098 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|01:56:34] 	Iter 14200 Done. | loss1: 0.0051 | loss_class: 0.0045 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|02:01:20] 	Iter 14300 Done. | loss1: 0.0060 | loss_class: 0.0053 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|02:06:39] 	Iter 14400 Done. | loss1: 0.0307 | loss_class: 0.0300 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|02:12:10] 	Iter 14500 Done. | loss1: 0.0163 | loss_class: 0.0157 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|02:17:26] 	Iter 14600 Done. | loss1: 0.0383 | loss_class: 0.0376 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|02:22:48] 	Iter 14700 Done. | loss1: 0.0079 | loss_class: 0.0072 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|02:27:55] 	Iter 14800 Done. | loss1: 0.0134 | loss_class: 0.0127 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|02:33:12] 	Iter 14900 Done. | loss1: 0.0132 | loss_class: 0.0126 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|02:38:43] 	Iter 15000 Done. | loss1: 0.0196 | loss_class: 0.0189 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|02:39:55] 	mean_loss1: 0.017812713026850165
[08.25.19|02:39:55] 	mean_loss_class: 0.017180829549940248
[08.25.19|02:39:55] 	mean_loss_recon: 0.0006318835111947867
[08.25.19|02:39:55] Time consumption:
[08.25.19|02:39:55] Done.
[08.25.19|02:39:55] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch98_model1.pt.
[08.25.19|02:39:55] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch98_model2.pt.
[08.25.19|02:39:55] Training epoch: 99
[08.25.19|02:44:13] 	Iter 15100 Done. | loss1: 0.0126 | loss_class: 0.0120 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|02:49:32] 	Iter 15200 Done. | loss1: 0.0356 | loss_class: 0.0349 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|02:54:48] 	Iter 15300 Done. | loss1: 0.0299 | loss_class: 0.0293 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:00:06] 	Iter 15400 Done. | loss1: 0.0203 | loss_class: 0.0197 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:05:34] 	Iter 15500 Done. | loss1: 0.0107 | loss_class: 0.0101 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:10:53] 	Iter 15600 Done. | loss1: 0.0049 | loss_class: 0.0043 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:16:27] 	Iter 15700 Done. | loss1: 0.0299 | loss_class: 0.0293 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:21:50] 	Iter 15800 Done. | loss1: 0.0109 | loss_class: 0.0104 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:27:04] 	Iter 15900 Done. | loss1: 0.0076 | loss_class: 0.0070 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:32:33] 	Iter 16000 Done. | loss1: 0.0117 | loss_class: 0.0110 | loss_recon: 0.0007 | lr: 0.000100
[08.25.19|03:37:50] 	Iter 16100 Done. | loss1: 0.0076 | loss_class: 0.0070 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:43:08] 	Iter 16200 Done. | loss1: 0.0745 | loss_class: 0.0739 | loss_recon: 0.0006 | lr: 0.000100
[08.25.19|03:47:20] 	mean_loss1: 0.017594510608203204
[08.25.19|03:47:20] 	mean_loss_class: 0.016963782157903663
[08.25.19|03:47:20] 	mean_loss_recon: 0.0006307284683941272
[08.25.19|03:47:20] Time consumption:
[08.25.19|03:47:20] Done.
[08.25.19|03:47:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch99_model1.pt.
[08.25.19|03:47:20] The model has been saved as ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch99_model2.pt.
[08.25.19|03:47:20] Eval epoch: 99
[08.25.19|04:10:42] 	Eval_mean_loss1: 0.7329236375124648
[08.25.19|04:10:42] 	Eval_mean_loss_class: 0.7325314390003796
[08.25.19|04:10:42] 	Eval_mean_loss_recon: 0.03921979442671981
[08.25.19|04:10:42] 

[08.25.19|04:10:42] 	Top1: 84.15%
[08.25.19|04:10:42] 

[08.25.19|04:10:42] 	Top5: 96.77%
[08.25.19|04:10:42] Done.
[08.26.19|02:32:27] Load weights from ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch99_model1.pt.
[08.26.19|02:32:27] Load weights [A].
[08.26.19|02:32:27] Load weights [data_bn.weight].
[08.26.19|02:32:27] Load weights [data_bn.bias].
[08.26.19|02:32:27] Load weights [data_bn.running_mean].
[08.26.19|02:32:27] Load weights [data_bn.running_var].
[08.26.19|02:32:27] Load weights [data_bn.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_0.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_0.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_0.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_1.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_1.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_1.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_2.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_2.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_2.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_3.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_3.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_3.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_3.residual.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_3.residual.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_3.residual.1.weight].
[08.26.19|02:32:27] Load weights [class_layer_3.residual.1.bias].
[08.26.19|02:32:27] Load weights [class_layer_3.residual.1.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_3.residual.1.running_var].
[08.26.19|02:32:27] Load weights [class_layer_3.residual.1.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_4.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_4.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_4.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_5.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_5.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_5.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_6.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_6.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_6.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_6.residual.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_6.residual.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_6.residual.1.weight].
[08.26.19|02:32:27] Load weights [class_layer_6.residual.1.bias].
[08.26.19|02:32:27] Load weights [class_layer_6.residual.1.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_6.residual.1.running_var].
[08.26.19|02:32:27] Load weights [class_layer_6.residual.1.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_7.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_7.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_7.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_8.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [class_layer_8.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.0.weight].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.0.bias].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.2.weight].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.2.bias].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.3.weight].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.3.bias].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [class_layer_8.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_0.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [recon_layer_0.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.2.weight].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.2.bias].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.3.weight].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.3.bias].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_0.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_0.residual.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_0.residual.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_0.residual.1.weight].
[08.26.19|02:32:27] Load weights [recon_layer_0.residual.1.bias].
[08.26.19|02:32:27] Load weights [recon_layer_0.residual.1.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_0.residual.1.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_0.residual.1.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_1.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [recon_layer_1.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.2.weight].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.2.bias].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.3.weight].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.3.bias].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_1.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_1.residual.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_1.residual.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_1.residual.1.weight].
[08.26.19|02:32:27] Load weights [recon_layer_1.residual.1.bias].
[08.26.19|02:32:27] Load weights [recon_layer_1.residual.1.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_1.residual.1.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_1.residual.1.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_2.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [recon_layer_2.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.2.weight].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.2.bias].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.3.weight].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.3.bias].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_2.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_2.residual.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_2.residual.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_2.residual.1.weight].
[08.26.19|02:32:27] Load weights [recon_layer_2.residual.1.bias].
[08.26.19|02:32:27] Load weights [recon_layer_2.residual.1.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_2.residual.1.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_2.residual.1.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_3.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [recon_layer_3.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.2.weight].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.2.bias].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.3.weight].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.3.bias].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_3.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_3.residual.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_3.residual.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_3.residual.1.weight].
[08.26.19|02:32:27] Load weights [recon_layer_3.residual.1.bias].
[08.26.19|02:32:27] Load weights [recon_layer_3.residual.1.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_3.residual.1.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_3.residual.1.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_4.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [recon_layer_4.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.2.weight].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.2.bias].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.3.weight].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.3.bias].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_4.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_4.residual.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_4.residual.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_4.residual.1.weight].
[08.26.19|02:32:27] Load weights [recon_layer_4.residual.1.bias].
[08.26.19|02:32:27] Load weights [recon_layer_4.residual.1.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_4.residual.1.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_4.residual.1.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_5.gcn.conv.weight].
[08.26.19|02:32:27] Load weights [recon_layer_5.gcn.conv.bias].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.0.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.0.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.2.weight].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.2.bias].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.3.weight].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.3.bias].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.3.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.3.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_5.tcn.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_6.gcn_recon.deconv.weight].
[08.26.19|02:32:27] Load weights [recon_layer_6.gcn_recon.deconv.bias].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.0.weight].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.0.bias].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.0.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.0.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.0.num_batches_tracked].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.2.weight].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.2.bias].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.3.weight].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.3.bias].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.3.running_mean].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.3.running_var].
[08.26.19|02:32:27] Load weights [recon_layer_6.tcn_recon.3.num_batches_tracked].
[08.26.19|02:32:27] Load weights [edge_importance.0].
[08.26.19|02:32:27] Load weights [edge_importance.1].
[08.26.19|02:32:27] Load weights [edge_importance.2].
[08.26.19|02:32:27] Load weights [edge_importance.3].
[08.26.19|02:32:27] Load weights [edge_importance.4].
[08.26.19|02:32:27] Load weights [edge_importance.5].
[08.26.19|02:32:27] Load weights [edge_importance.6].
[08.26.19|02:32:27] Load weights [edge_importance.7].
[08.26.19|02:32:27] Load weights [edge_importance.8].
[08.26.19|02:32:27] Load weights [edge_importance_recon.0].
[08.26.19|02:32:27] Load weights [edge_importance_recon.1].
[08.26.19|02:32:27] Load weights [edge_importance_recon.2].
[08.26.19|02:32:27] Load weights [edge_importance_recon.3].
[08.26.19|02:32:27] Load weights [edge_importance_recon.4].
[08.26.19|02:32:27] Load weights [edge_importance_recon.5].
[08.26.19|02:32:27] Load weights [edge_importance_recon.6].
[08.26.19|02:32:27] Load weights [edge_importance_recon.7].
[08.26.19|02:32:27] Load weights [edge_importance_recon.8].
[08.26.19|02:32:27] Load weights [fcn.weight].
[08.26.19|02:32:27] Load weights [fcn.bias].
[08.26.19|02:32:27] Load weights from ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch99_model2.pt.
[08.26.19|02:32:27] Load weights [encoder.mlp1.fc1.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp1.fc1.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp1.fc2.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp1.fc2.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp1.bn.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp1.bn.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp1.bn.running_mean].
[08.26.19|02:32:27] Load weights [encoder.mlp1.bn.running_var].
[08.26.19|02:32:27] Load weights [encoder.mlp1.bn.num_batches_tracked].
[08.26.19|02:32:27] Load weights [encoder.mlp2.fc1.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp2.fc1.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp2.fc2.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp2.fc2.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp2.bn.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp2.bn.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp2.bn.running_mean].
[08.26.19|02:32:27] Load weights [encoder.mlp2.bn.running_var].
[08.26.19|02:32:27] Load weights [encoder.mlp2.bn.num_batches_tracked].
[08.26.19|02:32:27] Load weights [encoder.mlp3.fc1.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp3.fc1.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp3.fc2.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp3.fc2.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp3.bn.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp3.bn.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp3.bn.running_mean].
[08.26.19|02:32:27] Load weights [encoder.mlp3.bn.running_var].
[08.26.19|02:32:27] Load weights [encoder.mlp3.bn.num_batches_tracked].
[08.26.19|02:32:27] Load weights [encoder.mlp4.fc1.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp4.fc1.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp4.fc2.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp4.fc2.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp4.bn.weight].
[08.26.19|02:32:27] Load weights [encoder.mlp4.bn.bias].
[08.26.19|02:32:27] Load weights [encoder.mlp4.bn.running_mean].
[08.26.19|02:32:27] Load weights [encoder.mlp4.bn.running_var].
[08.26.19|02:32:27] Load weights [encoder.mlp4.bn.num_batches_tracked].
[08.26.19|02:32:27] Load weights [encoder.fc_out.weight].
[08.26.19|02:32:27] Load weights [encoder.fc_out.bias].
[08.26.19|02:32:27] Load weights [decoder.msg_fc1.0.weight].
[08.26.19|02:32:27] Load weights [decoder.msg_fc1.0.bias].
[08.26.19|02:32:27] Load weights [decoder.msg_fc1.1.weight].
[08.26.19|02:32:27] Load weights [decoder.msg_fc1.1.bias].
[08.26.19|02:32:27] Load weights [decoder.msg_fc1.2.weight].
[08.26.19|02:32:27] Load weights [decoder.msg_fc1.2.bias].
[08.26.19|02:32:27] Load weights [decoder.msg_fc2.0.weight].
[08.26.19|02:32:27] Load weights [decoder.msg_fc2.0.bias].
[08.26.19|02:32:27] Load weights [decoder.msg_fc2.1.weight].
[08.26.19|02:32:27] Load weights [decoder.msg_fc2.1.bias].
[08.26.19|02:32:27] Load weights [decoder.msg_fc2.2.weight].
[08.26.19|02:32:27] Load weights [decoder.msg_fc2.2.bias].
[08.26.19|02:32:27] Load weights [decoder.hidden_r.weight].
[08.26.19|02:32:27] Load weights [decoder.hidden_i.weight].
[08.26.19|02:32:27] Load weights [decoder.hidden_n.weight].
[08.26.19|02:32:27] Load weights [decoder.input_r.weight].
[08.26.19|02:32:27] Load weights [decoder.input_r.bias].
[08.26.19|02:32:27] Load weights [decoder.input_i.weight].
[08.26.19|02:32:27] Load weights [decoder.input_i.bias].
[08.26.19|02:32:27] Load weights [decoder.input_n.weight].
[08.26.19|02:32:27] Load weights [decoder.input_n.bias].
[08.26.19|02:32:27] Load weights [decoder.out_fc1.weight].
[08.26.19|02:32:27] Load weights [decoder.out_fc1.bias].
[08.26.19|02:32:27] Load weights [decoder.out_fc2.weight].
[08.26.19|02:32:27] Load weights [decoder.out_fc2.bias].
[08.26.19|02:32:27] Load weights [decoder.out_fc3.weight].
[08.26.19|02:32:27] Load weights [decoder.out_fc3.bias].
[08.26.19|02:32:28] Parameters:
{'work_dir': './work_dir/recognition/ntu-xsub/AS_GCN', 'config': 'config/as_gcn/ntu-xsub/test.yaml', 'phase': 'test', 'save_result': False, 'start_epoch': 0, 'num_epoch': 80, 'use_gpu': True, 'device': [0, 1, 2, 3], 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'save_log': True, 'print_log': True, 'pavi_log': False, 'feeder': 'feeder.feeder.Feeder', 'num_worker': 4, 'train_feeder_args': {'data_path': './data/nturgb_d/xsub/train_data_joint_pad.npy', 'label_path': './data/nturgb_d/xsub/train_label.pkl', 'random_move': True, 'repeat_pad': True, 'down_sample': True, 'debug': False}, 'test_feeder_args': {'data_path': './data/nturgb_d/xsub/val_data_joint_pad.npy', 'label_path': './data/nturgb_d/xsub/val_label.pkl', 'random_move': False, 'repeat_pad': True, 'down_sample': True}, 'batch_size': 32, 'test_batch_size': 32, 'debug': False, 'model1': 'net.as_gcn.Model', 'model2': 'net.utils.adj_learn.AdjacencyLearn', 'model1_args': {'in_channels': 3, 'num_class': 60, 'dropout': 0.5, 'edge_importance_weighting': True, 'graph_args': {'layout': 'ntu-rgb+d', 'strategy': 'spatial', 'max_hop': 4}}, 'model2_args': {'n_in_enc': 150, 'n_hid_enc': 128, 'edge_types': 3, 'n_in_dec': 3, 'n_hid_dec': 128, 'node_num': 25}, 'weights1': './work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch99_model1.pt', 'weights2': './work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch99_model2.pt', 'ignore_weights': [], 'show_topk': [1, 5], 'base_lr1': 0.1, 'base_lr2': 0.0005, 'step': [], 'optimizer': 'SGD', 'nesterov': True, 'weight_decay': 0.0001, 'max_hop_dir': 'max_hop_4', 'lamda_act': 0.5, 'lamda_act_dir': 'lamda_05'}

[08.26.19|02:32:28] Model:   net.utils.adj_learn.AdjacencyLearn.
[08.26.19|02:32:28] Weights: ./work_dir/recognition/ntu-xsub/AS_GCN/max_hop_4/lamda_05/epoch99_model2.pt.
[08.26.19|02:32:28] Evaluation Start:
